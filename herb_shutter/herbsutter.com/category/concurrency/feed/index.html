<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>Concurrency &#8211; Sutter’s Mill</title>
	<atom:link href="https://herbsutter.com/category/concurrency/feed/" rel="self" type="application/rss+xml" />
	<link>https://herbsutter.com</link>
	<description>Herb Sutter on software development</description>
	<lastBuildDate>
	Fri, 23 Nov 2018 09:31:12 +0000	</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
<cloud domain='herbsutter.com' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<image>
		<url>https://secure.gravatar.com/blavatar/4554b8d24c7f200dc5e2e1b18db1893f?s=96&#038;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</url>
		<title>Concurrency &#8211; Sutter’s Mill</title>
		<link>https://herbsutter.com</link>
	</image>
	<atom:link rel="search" type="application/opensearchdescription+xml" href="https://herbsutter.com/osd.xml" title="Sutter’s Mill" />
	<atom:link rel='hub' href='https://herbsutter.com/?pushpress=hub'/>
	<item>
		<title>Reader Q&#038;A: Book recommendations</title>
		<link>https://herbsutter.com/2013/12/05/reader-qa-book-recommendations/</link>
				<comments>https://herbsutter.com/2013/12/05/reader-qa-book-recommendations/#comments</comments>
				<pubDate>Thu, 05 Dec 2013 23:31:01 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=2367</guid>
				<description><![CDATA[Vigen Isayan emailed me today to ask: What book(s) you would recommend for learning 1. design patterns, and 2. concurrency programming. Off the top of my head: 1. For Design Patterns, the greatest is still the original &#8220;Gang of Four&#8221; Design Patterns book. The design patterns are mostly universal, and the implementations happen to focus on [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Vigen Isayan emailed me today to ask:</p>
<blockquote><p>What book(s) you would recommend for learning</p>
<p>1. design patterns, and</p>
<p>2. concurrency programming.</p></blockquote>
<p>Off the top of my head:</p>
<p>1. For Design Patterns, the greatest is still the original <a href="http://en.wikipedia.org/wiki/Design_Patterns">&#8220;Gang of Four&#8221; Design Patterns book</a>. The design patterns are mostly universal, and the implementations happen to focus on OO techniques (dynamic run-time virtual dispatch etc.) but you can also express many of the patterns using generic programming (static compile-time templates etc.) – for example <a href="http://www.drdobbs.com/cpp/generalizing-observer/184403873?queryText=sutter%2B%2522generalizing%2Bobserver%2522">Observer</a> becomes really simple. The book is almost two decades old, has inspired huge numbers of follow-on patterns books, and there&#8217;s still none better of its kind that I know of.</p>
<p>2. For concurrency (and parallelism), check out my <a href="https://herbsutter.com/2010/09/24/effective-concurrency-know-when-to-use-an-active-object-instead-of-a-mutex/">33 articles on Effective Concurrency</a>. I hope to assemble them into a book in the near future. In the meantime they’re all out there online freely available.</p>
<p>If you have additional recommendations, please post them in the comments. Thanks.</p>
<h3>On a personal note</h3>
<p>Speaking of the Gang of Four, here&#8217;s a personal story I don&#8217;t know if I&#8217;ve shared on the blog before:</p>
<p>At the time it first came out, I was working in downtown Toronto. We had a really excellent local bookstore that specialized in programming books and magazines (alas, it&#8217;s long gone now). On lunch breaks, I would go there to browse and get new books to absorb. Note that this was before I was a published author myself, and I had no idea about major new books coming out, so I had no warning of what was about to happen.</p>
<p>On one day that at first seemed like any other, at lunchtime I was browsing the shelves as usual, and I saw copies of a white and blue hardcover book I&#8217;d never seen before. Curious, I picked up a copy. It had an unusual title, <em>Design Patterns</em>. I had never heard of the book or its authors before, knew nothing about it at all, and so was quite unsuspecting when I opened it and something happened that I had never experienced before and haven&#8217;t experienced since (so far):</p>
<p>I opened that book for the first time, stood there paging through it for less than five minutes, <em>and knew immediately and profoundly that I was holding a classic in my hands</em>. The realization was so unexpected and surprising, it hit me almost physically. At first sight, it was as easy to recognize this book as an important leap forward as the first you see an airplane flying in the sky. Scales fell from my eyes: Cataloguing OO design problems and their known solutions! Imagine!</p>
<p>I had already learned a few of the patterns on my own here and there, some through hard work and experience, others by combining ideas from various articles, many by working with experienced colleagues. But suddenly I found myself standing there in the bookstore aisle just absorbing one problem and solution after another after another, and feeling my understanding begin expanding. Even the patterns I sort of knew about were explained with concise clarity: Motivation, the problem <em>and the specific constraints on the solution</em> which are so important because they affect the design. Known solutions. Variations with tradeoffs.</p>
<p>Bliss! No, more than bliss &#8212; treasure.</p>
<p>This must be what explorers and hunters feel like when one day unexpectedly they discover an unopened and unransacked tomb of a young Egyptian Pharaoh, a sunken treasure galleon filled with precious cargo and artifacts, or a cave near the West Bank containing well-preserved two-thousand-year-old scrolls of important literature.</p>
<p>And <em>Design Patterns</em> was language-agnostic, to boot.</p>
<p>Nineteen years later, it&#8217;s still at the top of my list of design books to recommend.</p>
<p>Disclaimer: Something this profound inspires a whole new subculture. Later &#8220;pattern&#8221; wannabe books often went way, way, <em>way</em> overboard, some of them almost to the border of quasi-mysticism. Ignore most (not all, but most) of the follow-on pattern books. Only a few are worth your time; read the reviews carefully first.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2013/12/05/reader-qa-book-recommendations/feed/</wfw:commentRss>
		<slash:comments>8</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Reader Q&#038;A: Acquire/release and sequential consistency</title>
		<link>https://herbsutter.com/2013/10/28/reader-qa-acquirerelease-and-sequential-consistency/</link>
				<comments>https://herbsutter.com/2013/10/28/reader-qa-acquirerelease-and-sequential-consistency/#comments</comments>
				<pubDate>Mon, 28 Oct 2013 17:03:08 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=2346</guid>
				<description><![CDATA[Reader Ernie Cohen emailed me this morning to ask a question about one slide in my atomic&#60;&#62; Weapons talk from last year&#8217;s C++ and Beyond: In your atomic weapons talk (part 1) (updated 2/15/2013) ,page 18, titled &#8220;Sc &#62; Acq/Rel Alone: Some examples&#8221;, the first example listed &#8220;transitivity/causality&#8221;: T0: g = 1; x = 1; [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Reader Ernie Cohen emailed me this morning to ask a question about one slide in my <a href="https://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/">atomic&lt;&gt; Weapons talk</a> from last year&#8217;s <em>C++ and Beyond</em>:</p>
<blockquote><p>In your atomic weapons talk (part 1) (updated 2/15/2013) ,page 18, titled &#8220;Sc &gt; Acq/Rel Alone: Some examples&#8221;, the first example listed &#8220;transitivity/causality&#8221;:<!--?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /--></p>
<p>T0: g = 1; x = 1;</p>
<p>T1: if (x == 1) y = 1;</p>
<p>T2: if (y == 1) assert(g == 1);</p>
<p>I understood you to mean that the assertion might fail if the loads were simple C++11 acquires and the stores were simple C++ releases. But this works just fine with the weaker memory order; the operations in each thread are related by sequenced-before, the communications between the threads create happens-before, and without consumes happens-before is transitive, so there is a happens-before edge from g = 1 to the assertion. Am I missing something?</p></blockquote>
<p>[Note: g is an ordinary variable, x and y are std::atomic, and all initially zero as usual.] The motivation behind this example, and the other example on the same slide, was to show that when we specified the C++ memory model and atomics, we had to consider more than individual acquire-release pairs in isolation, but also provide additional guarantees to ensure that the whole program was sequentially consistent (SC).</p>
<p>In the above example, yes, we guarantee that the assertion cannot fail with C++ acquire and release semantics, and making sure the memory model required this transitivity is exactly one of the two key points of this example. As you point out, it requires getting the &#8220;right&#8221; answer when combining sequenced-before and happens-before.</p>
<p>The second point illustrated here is that it was essential to support cases where the programmer could depend on reasoning based on tests of whether <i>a particular write</i> was read and then making SC assumptions based on the outcome of the test, otherwise the whole program wouldn&#8217;t be SC.</p>
<p>For completeness, the other example on the slide showed an additional case where individual pairwise acquire/release alone was insufficient to guarantee SC outcomes unless we added requirements. Here is the example, with x and y std::atomic and initially zero:</p>
<p>T1: x = 1;</p>
<p>T2: y = 1;</p>
<p>T3: if( x == 1 &amp;&amp; y == 0 ) print( &#8220;x first&#8221; );</p>
<p>T4: if( y == 1 &amp;&amp; x == 0 ) print( &#8220;y first&#8221; );</p>
<p>This illustrates the total store order requirement: It must be impossible to print both messages, else the result wouldn&#8217;t be SC.</p>
<p>Note that in most cases using (non-SC) memory_order_acquire and memory_order_release explicitly happens to give you SC results, except when they don&#8217;t (e.g., Dekker&#8217;s fails, and I think the second example above fails as well). And of course other relaxed atomics can allow non-SC results at the drop of a hat.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2013/10/28/reader-qa-acquirerelease-and-sequential-consistency/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>atomic Weapons: The C++ Memory Model and Modern Hardware</title>
		<link>https://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/</link>
				<comments>https://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/#comments</comments>
				<pubDate>Mon, 11 Feb 2013 18:31:42 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=1784</guid>
				<description><![CDATA[[ETA: Updated OneDrive slides link] Most of the talks I gave at C++ and Beyond 2012 last summer are already online at Channel 9. Here are two more. This is a two-part talk that covers the C++ memory model, how locks and atomics and fences interact and map to hardware, and more. Even though we&#8217;re [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>[ETA: Updated OneDrive <a href="https://1drv.ms/b/s!Aq0V7yDPsIZOgcI0y2P8R-VifbnTtw">slides link</a>]</p>
<p><img src="https://herbsutter.files.wordpress.com/2013/02/021113_1851_atomicweapo1.png?w=500" alt="" align="right" />Most of the talks I gave at <a href="http://cppandbeyond.com"><em>C++ and Beyond 2012</em></a> last summer are already online at Channel 9. Here are two more.</p>
<p>This is a two-part talk that covers the C++ memory model, how locks and atomics and fences interact and map to hardware, and more. Even though we&#8217;re talking about C++, much of this is also applicable to Java and .NET which have similar memory models, but not all the features of C++ (such as relaxed atomics).</p>
<p>Note: This is about the basic structure and tools, not how to write lock-free algorithms using atomics. That next-level topic may be on deck for this year&#8217;s <a href="http://cppandbeyond.com/2013/02/11/cb-2013-dates-finalized-december-9-12-2013/"><em>C++ and Beyond</em> in December</a>, we&#8217;ll see…</p>
<h2>atomic&lt;&gt; Weapons: The C++ Memory Model and Modern Hardware</h2>
<ul style="margin-left:72pt;">
<li><a href="http://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-1-of-2"><span style="background-color:yellow;"><strong>Part 1:</strong></span> Optimizations, races, and the memory model; acquire and release ordering; mutexes vs. atomics vs. fences</a></li>
<li><a href="http://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Herb-Sutter-atomic-Weapons-2-of-2"><span style="background-color:yellow;"><strong>Part 2:</strong></span> Restrictions on compilers and hardware (incl. common bugs); code generation and performance on x86/x64, IA64, POWER, ARM, and more; relaxed atomics; volatile</a></li>
</ul>
<p>This session in one word: <em><strong>Deep.</strong><br />
</em></p>
<p style="margin-left:36pt;">It&#8217;s a session that includes topics I&#8217;ve publicly said for years is Stuff You Shouldn&#8217;t Need To Know and I Just Won&#8217;t Teach, but it&#8217;s becoming achingly clear that people do need to know about it. Achingly, heartbreakingly clear, because some hardware incents you to pull out the big guns to achieve top performance, and C++ programmers just are so addicted to full performance that they&#8217;ll reach for the big red levers with the flashing warning lights. Since we can&#8217;t keep people from pulling the big red levers, we&#8217;d better document the A to Z of what the levers actually do, so that people don&#8217;t <a href="http://en.wikipedia.org/wiki/Scram"><em>SCRAM</em></a> unless they really, really, really meant to.<em><br />
</em></p>
<p style="margin-left:36pt;"><strong>Topics Covered:</strong></p>
<ul style="margin-left:72pt;">
<li><strong>The facts: </strong>The C++11 memory model and what it requires you to do to make sure your code is correct and stays correct. We&#8217;ll include clear answers to several FAQs: &#8220;how do the compiler and hardware cooperate to remember how to respect these rules?&#8221;, &#8220;what is a race condition?&#8221;, and the ageless one-hand-clapping question &#8220;how is a race condition like a debugger?&#8221;</li>
<li><strong>The tools:</strong> The deep interrelationships and fundamental tradeoffs among mutexes, atomics, and fences/barriers. I&#8217;ll try to convince you why standalone memory barriers are bad, and why barriers should always be associated with a specific load or store.</li>
<li><strong>The unspeakables: </strong>I&#8217;ll grudgingly and reluctantly talk about the Thing I Said I&#8217;d Never Teach That Programmers Should Never Need To Now: relaxed atomics. Don&#8217;t use them! If you can avoid it. But here&#8217;s what you need to know, even though it would be nice if you didn&#8217;t need to know it.</li>
<li><strong>The rapidly-changing hardware reality: </strong>How locks and atomics map to hardware instructions on ARM and x86/x64, and throw in POWER and Itanium for good measure – and I&#8217;ll cover how and why the answers are actually different last year and this year, and how they will likely be different again a few years from now. We&#8217;ll cover how the latest CPU and GPU hardware memory models are rapidly evolving, and how this directly affects C++ programmers.</li>
</ul>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/feed/</wfw:commentRss>
		<slash:comments>16</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>

		<media:content url="https://herbsutter.files.wordpress.com/2013/02/021113_1851_atomicweapo1.png" medium="image" />
	</item>
		<item>
		<title>&#8220;256 cores by 2013&#8221;?</title>
		<link>https://herbsutter.com/2012/11/30/256-cores-by-2013/</link>
				<comments>https://herbsutter.com/2012/11/30/256-cores-by-2013/#comments</comments>
				<pubDate>Sat, 01 Dec 2012 02:12:29 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1679</guid>
				<description><![CDATA[I just saw a tweet that’s worth commenting on: Almost right, and we have already reached that. I said something similar to the above, but with two important differences: I said hardware “threads,” not only hardware “cores” – it was about the amount of hardware parallelism available on a mainstream system. What I gave was [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>I just saw a tweet that’s worth commenting on:</p>
<p><a href="https://herbsutter.files.wordpress.com/2012/11/image3.png"><img title="image" style="border-top:0;border-right:0;background-image:none;border-bottom:0;float:none;padding-top:0;padding-left:0;margin:0 auto 10px;border-left:0;display:block;padding-right:0;" border="0" alt="image" src="https://herbsutter.files.wordpress.com/2012/11/image_thumb.png?w=513&#038;h=146" width="513" height="146" /></a></p>
<p>Almost right, and we have already reached that.</p>
<p>I said something similar to the above, but with two important differences:</p>
<ol>
<li>I said hardware “threads,” not only hardware “cores” – it was about the <strong>amount of hardware parallelism </strong>available on a mainstream system. </li>
<li>What I gave was a min/max <strong>range estimate of roughly 16 to 256 (the latter being threads)</strong> under different sets of assumptions. </li>
</ol>
<p>So: Was I was right about 2013 estimates?</p>
<p>Yes, pretty much, and in fact we already reached or exceeded that in 2011 and 2012:</p>
<ul>
<li>Lower estimate line: In 2011 and 2012 parts, Intel Core i7 Sandy Bridge and Ivy Bridge are delivering almost the expected lower baseline, and offering 8-way and 12-way parallelism = 4-6 cores x 2 hardware threads per core. </li>
<li>Upper estimate line: In 2012, as mentioned in the article (which called it Larrabee, now known as MIC or Xeon Phi) is delivering 200-way to 256-way parallelism = 50-64 cores x 4 hardware threads per core. Also, in 2011 and 2012, GPUs have since emerged into more mainstream use for computation (GPGPU), and likewise offer massive compute parallelism, such as 1,536-way parallelism on a machine having a single NVidia Tesla card. </li>
</ul>
<p>Yes, mainstream machines do in fact have examples of both ends of the “16 to 256 way parallelism” range. And beyond the upper end of the range, in fact, for those with higher-end graphics cards.</p>
<p>For more on these various kinds of compute cores and threads, see also my article <strong><a href="https://herbsutter.com/welcome-to-the-jungle/">Welcome to the Jungle</a></strong>.</p>
<p>&#160;</p>
<p>Longer answer follows:</p>
<p>Here’s the main part from article, <a href="http://www.drdobbs.com/parallel/design-for-manycore-systems/219200099?pgno=3"><strong>“Design for Manycore Systems”</strong></a> (August 11, 2009). Remember this was written over three years ago – in the Time Before iPad, when Android was under a year old:</p>
<blockquote>
<h3><font style="font-weight:normal;">How Much Scalability Does Your Application Need?</font></h3>
<p>So how much parallel scalability should you aim to support in the application you‘re working on today, assuming that it&#8217;s compute-bound already or you can add killer features that are compute-bound and also amenable to parallel execution? The answer is that <strong>you want to match your application&#8217;s scalability to the amount of hardware parallelism in the target hardware that will be available during your application&#8217;s expected production or shelf lifetime. As shown in Figure 4, that equates to the number of hardware threads you expect to have on your end users&#8217; machines.</strong> </p>
<p align="center"><img src="https://i0.wp.com/twimgs.com/ddj/images/article/2009/0908/090811ec_f4.gif" /></p>
<p align="center"><b>Figure 4</b>: How much concurrency does your program need in order to exploit given hardware? </p>
<p>Let&#8217;s say that YourCurrentApplication 1.0 will ship next year (mid-2010), and you expect that it&#8217;ll be another 18 months until you ship the 2.0 release (early 2012) and probably another 18 months after that before most users will have upgraded (mid-2013). Then you&#8217;d be interested in judging what will be the likely mainstream hardware target up to mid-2013. </p>
<p><strong>If we stick with &quot;just more of the same&quot;</strong> as in Figure 2&#8217;s extrapolation, we&#8217;d expect aggressive early hardware adopters to be running 16-core machines (possibly double that if they&#8217;re aggressive enough to run dual-CPU workstations with two sockets), and <strong>we&#8217;d likely expect most general mainstream users to have 4-, 8- or maybe a smattering of 16-core machines</strong> (accounting for the time for new chips to be adopted in the marketplace). <em><font color="#c0504d">[[Note: I often get lazy and say “core” to mean all hardware parallelism. In context above and below, it’s clear we’re talking about “cores and threads.”]]</font></em></p>
<p>But what if the gating factor, parallel-ready software, goes away? Then CPU vendors would be free to take advantage of <strong>options like the one-time 16-fold hardware parallelism jump</strong> illustrated in Figure 3, and we get an envelope like that shown in Figure 5. </p>
<p><img style="float:none;margin-left:auto;display:block;margin-right:auto;" src="https://i2.wp.com/twimgs.com/ddj/images/article/2009/0908/090811ec_f5.gif" /></p>
<p align="center"><b>Figure 5</b>: Extrapolation of “more of the same big cores” and “possible one-time switch to 4x smaller cores plus 4x threads per core” (not counting some transistors being used for other things like on-chip GPUs). </p>
</blockquote>
<p>First, let’s look at the lower baseline, ‘most general mainstream users to have [4-16 way parallelism] machines in 2013’? So where are were in 2012 today for mainstream CPU hardware parallelism? Well, Intel Core i7 (e.g., Sandy Bridge, Ivy Bridge) are typically in the 4 to 6 core range – which, <strong>with hyperthreading == hardware threads, means 8 to 12 hardware threads</strong>.</p>
<p>Second, what about the higher potential line for 2013? As noted above:</p>
<ul>
<li>Intel’s Xeon Phi (then Larrabee) is now delivering 50-64 cores x 4 threads = 200 to 256-way parallelism. That’s no surprise, because this article’s upper line was based on exactly the Larrabee data point (see quote below). </li>
<li>GPUs already blow the 256 upper bound away – any machine with a two-year-old Tesla has 1,536-way parallelism for programs (including mainstream programs like DVD encoders) that can harness the GPU. </li>
</ul>
<p>So not only did we already reach the 2013 upper line early, in 2012, but we already exceeded it for applications that can harness the GPU for computation.</p>
<p>As I said in the article:</p>
<blockquote>
<p>I don&#8217;t believe either the bottom line or the top line is the exact truth, but as long as sufficient parallel-capable software comes along, the truth will probably be somewhere in between, especially if we have processors that offer a mix of large- and small-core chips, or that use some chip real estate to bring GPUs or other devices on-die. That&#8217;s more hardware parallelism, and sooner, than most mainstream developers I&#8217;ve encountered expect. </p>
<p>Interestingly, though, we already noted two current examples: Sun&#8217;s Niagara, and Intel&#8217;s Larrabee, already provide double-digit parallelism in mainstream hardware via smaller cores with four or eight hardware threads each. <strong>&quot;Manycore&quot; chips, or perhaps more correctly &quot;manythread&quot; chips, are just waiting to enter the mainstream</strong>. Intel could have built a nice 100-core part in 2006. The gating factor is the software that can exploit the hardware parallelism; that is, the gating factor is you and me. </p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/11/30/256-cores-by-2013/feed/</wfw:commentRss>
		<slash:comments>8</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>

		<media:content url="https://herbsutter.files.wordpress.com/2012/11/image_thumb.png" medium="image">
			<media:title type="html">image</media:title>
		</media:content>

		<media:content url="http://twimgs.com/ddj/images/article/2009/0908/090811ec_f4.gif" medium="image" />

		<media:content url="http://twimgs.com/ddj/images/article/2009/0908/090811ec_f5.gif" medium="image" />
	</item>
		<item>
		<title>Reader Q&#038;A: How to write a CAS loop using std::atomics</title>
		<link>https://herbsutter.com/2012/08/31/reader-qa-how-to-write-a-cas-loop-using-stdatomics/</link>
				<comments>https://herbsutter.com/2012/08/31/reader-qa-how-to-write-a-cas-loop-using-stdatomics/#comments</comments>
				<pubDate>Sat, 01 Sep 2012 00:43:58 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1599</guid>
				<description><![CDATA[The following is not intended to be a complete treatise on atomics, but just an answer to a specific question. A colleague asked: How should one write the following “conditional interlocked” function in the new C++ atomic&#60;&#62; style? // if (*plValue &#62;= 0) *plValue += lAdd ; return the original value LONG MpInterlockedAddNonNegative(__inout LONG volatile* [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>The following is not intended to be a complete treatise on atomics, but just an answer to a specific question.</p>
<p>A colleague asked:</p>
<blockquote>
<p>How should one write the following “conditional interlocked” function in the new C++ atomic&lt;&gt; style?</p>
<pre class="brush: cpp; auto-links: true; collapse: false; first-line: 1; gutter: false; html-script: false; light: false; ruler: false; smart-tabs: true; tab-size: 4; toolbar: true;">// if (*plValue &gt;= 0) *plValue += lAdd  ; return the original value

LONG MpInterlockedAddNonNegative(__inout LONG volatile* plValue,  __in  LONG const  lAdd) 
{ 
    LONG lValue = 0; 
    for (;;)  {

        lValue = *plValue; // volatile plValue suppress compile optimizations in which</pre>
<p>&#160;</p>
<pre class="brush: cpp; auto-links: true; collapse: false; first-line: 1; gutter: false; html-script: false; light: false; ruler: false; smart-tabs: true; tab-size: 4; toolbar: true;">                           // lValue is optimized out hence MT correctness is broken

        if (lValue &lt; 0)   break;

        if (lValue == InterlockedCompareExchange(plValue, lValue + lAdd, lValue)) { 
            break; 
        } 
    }

    return lValue; 
}</pre>
</blockquote>
<p>Note: ISO C/C++ volatile is not for inter-thread communication,[*] but this is legacy code that predates std::atomics and was using a combination of platform-specific volatile semantics and Windows InterlockedXxx APIs.</p>
<p>The answer is to use a CAS loop (see code at top), which for std::atomics is spelled compare_exchange:</p>
<ul>
<li>Use compare_exchange_weak by default when looping on this which generally naturally tolerates spurious failures. </li>
<li>Use compare_exchange_strong for single tests when you generally don’t want spurious failures. </li>
<li>Usage note: In the code at top we save an explicit reload from ‘a’ in the loop because compare_exchange helpfully (or “helpfully” – this took me a while to discover and remember) stores the actual value in the ‘expected’ value slot on failure. This actually makes loops simpler, though some of us are still have different feelings on different days about whether this subtlety was a good idea… anyway, it’s in the standard. </li>
</ul>
<p>For the std::atomic version, roughly (compiling in my head), and generalizing to any numeric type just because I’m in the habit, and renaming for symmetry with atomic&lt;T&gt;::fetch_add(), I think this is what you want:</p>
<pre class="brush: cpp; auto-links: true; collapse: false; first-line: 1; gutter: false; html-script: false; light: false; ruler: false; smart-tabs: true; tab-size: 4; toolbar: true;">template&lt;typename T&gt;
T fetch_add_if_nonnegative( std::atomic&lt;T&gt;&amp; a,  T val ) {
    T old = a;
    while( old &gt;= 0 &amp;&amp; !a.compare_exchange_weak( old, old+val ) )
        { }
    return old;
}</pre>
<p>Because the only test in your loop was to break on negative values, it naturally migrated into the loop condition. If you want to do more work, then follow the general pattern which is the following (pasting from the standard, 29.6.5/23 – and note that the explicit “.load()” is unnecessary but some people including the author of this clause of the standard prefer to be pedantically explicit :) ):</p>
<blockquote>
<p>[ <em>Example: </em>the expected use of the compare-and-exchange operations is as follows.</p>
<p>The compare-and-exchange operations will update expected when another iteration of the loop is needed.</p>
<p>expected = current.load();</p>
<p>do {</p>
<p>desired = function(expected);</p>
<p>} while (!current.compare_exchange_weak(expected, desired));</p>
<p><em>—end example </em>]</p>
</blockquote>
<p>So the direct implementation of your function in the general pattern would be:</p>
<pre class="brush: cpp; auto-links: true; collapse: false; first-line: 1; gutter: false; html-script: false; light: false; ruler: false; smart-tabs: true; tab-size: 4; toolbar: true;">T old = a; 
do { 
    if( old &lt; 0 ) break; 
} while(!a.compare_exchange_weak( old, old+val ) )</pre>
<p>
  <br />but since that easily moves into the loop test I just did this instead in the code at top:</p>
<p></p>
<pre class="brush: cpp; auto-links: true; collapse: false; first-line: 1; gutter: false; html-script: false; light: false; ruler: false; smart-tabs: true; tab-size: 4; toolbar: true;">T old = a; 
while( old &gt;= 0 &amp;&amp; !a.compare_exchange_weak( old, old+val ) ) 
    { }</pre>
<p>and hoping that no one will discover and point out that I’ve somehow written a subtle bug by trying to make the code cuter just before leaving for a holiday weekend.</p>
<p>&#160;</p>
<p>[*] Here’s the difference between <strong>ISO C/C++ volatile vs. std::atomic&lt;T&gt;/atomic_T:</strong> ISO C/C++ volatile is intended to be used only for things like hardware access and setjmp/longjmp safety, to express that the variable is in storage that is not guaranteed to follow the C++11 memory model (e.g., the compiler can’t make any assumptions about it). It has nothing to do with inter-thread communication – the proper tool for that is std::atomic&lt;T&gt; which for C compatibility can also be spelled atomic_T (note that in Java and C# this is called volatile which adds to the confusion). For more, see my article <a href="https://herbsutter.com/2009/01/12/effective-concurrency-volatile-vs-volatile/">“volatile vs. volatile”</a> and Hans Boehm’s ISO C++ paper <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2016.html">“Should volatile Acquire Atomicity and Thread Visibility Semantics?”</a>.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/08/31/reader-qa-how-to-write-a-cas-loop-using-stdatomics/feed/</wfw:commentRss>
		<slash:comments>13</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>C&#038;B Panel: Alexandrescu, Meyers, Sutter on Static If, C++11, and Metaprogramming</title>
		<link>https://herbsutter.com/2012/08/21/cb-panel/</link>
				<comments>https://herbsutter.com/2012/08/21/cb-panel/#comments</comments>
				<pubDate>Tue, 21 Aug 2012 15:10:26 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=1596</guid>
				<description><![CDATA[The first panel from C++ and Beyond 2012 is now available on Channel 9: On Static If, C++11 in 2012, Modern Libraries, and Metaprogramming Andrei Alexandrescu, Scott Meyers, Herb Sutter Channel 9 was invited to this year&#8217;s C++ and Beyond to film some sessions (that will appear on C9 over the coming months!)&#8230; At the [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Alexandrescu-Meyers-Sutter-On-Static-If-C11-in-2012-Modern-Libraries-and-Metaprogramming"><img data-attachment-id="1597" data-permalink="https://herbsutter.com/2012/08/21/cb-panel/cnb2012-panel/" data-orig-file="https://herbsutter.files.wordpress.com/2012/08/cnb2012-panel.png?w=500" data-orig-size="431,288" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="C&amp;amp;B 2012 Panel" data-image-description="" data-medium-file="https://herbsutter.files.wordpress.com/2012/08/cnb2012-panel.png?w=500?w=300" data-large-file="https://herbsutter.files.wordpress.com/2012/08/cnb2012-panel.png?w=500?w=431" class="alignright size-full wp-image-1597" title="C&amp;B 2012 Panel" src="https://herbsutter.files.wordpress.com/2012/08/cnb2012-panel.png?w=500" alt="" srcset="https://herbsutter.files.wordpress.com/2012/08/cnb2012-panel.png 431w, https://herbsutter.files.wordpress.com/2012/08/cnb2012-panel.png?w=150 150w, https://herbsutter.files.wordpress.com/2012/08/cnb2012-panel.png?w=300 300w" sizes="(max-width: 431px) 100vw, 431px"   /></a>The first panel from C++ and Beyond 2012 is now available on Channel 9:</p>
<blockquote><p><a href="http://s151836.gridserver.com/?URL=http%3A%2F%2Fchannel9.msdn.com%2FShows%2FGoing%2BDeep%2FAlexandrescu-Meyers-Sutter-On-Static-If-C11-in-2012-Modern-Libraries-and-Metaprogramming">On Static If, C++11 in 2012, Modern Libraries, and Metaprogramming</a></p>
<h4>Andrei Alexandrescu, Scott Meyers, Herb Sutter</h4>
<p>Channel 9 was invited to this year&#8217;s <a href="http://s151836.gridserver.com/?URL=http%3A%2F%2Fcppandbeyond.com%2F">C++ and Beyond</a> to film some sessions (that will appear on C9 over the coming months!)&#8230;</p>
<p>At the end of day 2, Andrei, Herb and Scott graciously agreed to spend some time discussing various modern C++ topics and, even better, <a href="http://s151836.gridserver.com/?URL=http%3A%2F%2Fchannel9.msdn.com%2FForums%2FTechOff%2FAndrei-Herb-and-Scott-Got-C11-Questions">answering questions from the community</a>. In fact, the questions from Niners (and <a href="http://s151836.gridserver.com/?URL=http%3A%2F%2Fwww.reddit.com%2Fr%2Fcpp%2Fcomments%2Fxknfr%2Fandrei_herb_and_scott_got_c11_questions%2F">a conversation on reddit/r/cpp</a>) drove the conversation.</p>
<p>Here&#8217;s what happened&#8230;</p>
<p><a href="http://s151836.gridserver.com/?URL=http%3A%2F%2Fchannel9.msdn.com%2FShows%2FGoing%2BDeep%2FAlexandrescu-Meyers-Sutter-On-Static-If-C11-in-2012-Modern-Libraries-and-Metaprogramming">[more]</a></p></blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/08/21/cb-panel/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>

		<media:content url="https://herbsutter.files.wordpress.com/2012/08/cnb2012-panel.png" medium="image">
			<media:title type="html">C&#038;B 2012 Panel</media:title>
		</media:content>
	</item>
		<item>
		<title>&#8220;Strong&#8221; and &#8220;weak&#8221; hardware memory models</title>
		<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/</link>
				<comments>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comments</comments>
				<pubDate>Thu, 02 Aug 2012 11:26:37 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C# / .NET]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Java]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590</guid>
				<description><![CDATA[In Welcome to the Jungle, I predicted that “weak” hardware memory models will disappear. This is true, and it’s happening before our eyes: x86 has always been considered a “strong” hardware memory model that supports sequentially consistent atomics efficiently. The other major architecture, ARM, recently announced that they are now adding strong memory ordering in [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>In <a href="https://herbsutter.com/welcome-to-the-jungle/">Welcome to the Jungle</a>, I predicted that “weak” hardware memory models will disappear. This is true, and it’s happening before our eyes:</p>
<ul>
<li>x86 has always been considered a “strong” hardware memory model that supports sequentially consistent atomics efficiently.</li>
<li>The other major architecture, ARM, recently announced that they are now adding strong memory ordering in ARMv8 with the new sequentially consistent <em>ldra </em>and <em>strl </em>instructions, as I predicted they would. (Actually, Hans Boehm and I influenced ARM in this direction, so it was an ever-so-slightly disingenuous prediction&#8230;)</li>
</ul>
<p>However, at least two people have been confused by what I meant by “weak” hardware memory models, so let me clarify what “weak” means – it means something different for hardware memory models and software memory models, so perhaps those aren’t the clearest terms to use.</p>
<p>By &#8220;weak <strong><em>(hardware)</em></strong> memory model&#8221; CPUs I mean specifically ones that do not natively support efficient sequentially consistent (SC) atomics, because on the <strong><em>software</em></strong> side programming languages have converged on &#8220;sequential consistency for data-race-free programs&#8221; (SC-DRF, roughly aka DRF0 or RCsc) as the default (C11, C++11) or only (Java 5+) supported software memory model for software. POWER and ARMv7 notoriously do not support SC atomics efficiently.</p>
<p>Hardware that supports only hardware memory models weaker than SC-DRF, <em>meaning that they do not support SC-DRF efficiently</em>, are permanently disadvantaged and will either become stronger or atrophy. As I mentioned specifically in the article, the two main current hardware architectures with what I called &#8220;weak&#8221; memory models were current ARM (ARMv7) and POWER:</p>
<ul>
<li>ARM recently announced ARMv8 which, as I predicted, is upgrading to SC acquire/release by adding new SC acquire/release instructions ldra and strl that are mandatory in both 32-bit and 64-bit mode. In fact, this is something of an industry first &#8212; ARMv8 is the first major CPU architecture to support SC acquire/release instructions directly like this. (Note: That’s for CPUs, but the roadmap for ARM GPUs is similar. ARM GPUs currently have a stronger memory model, namely fully SC; ARM has announced their GPU future roadmap has the GPUs fully coherent with the CPUs, and will likely add “SC load acquire” and “SC store release” to GPUs as well.)</li>
<li>It remains to be seen whether POWER will adapt similarly, or die out.</li>
</ul>
<p>Note that I&#8217;ve seen some people call x86 &#8220;weak&#8221;, but x86 has always been the poster child for a <strong><em>strong (hardware) </em></strong>memory model in all of our <strong><em>software</em></strong> memory model discussions for Java, C, and C++ during the 2000s. Therefore perhaps &#8220;weak&#8221; and &#8220;strong&#8221; are not useful terms if they mean different things to some people, and I&#8217;ve updated the WttJ text to make this clearer.</p>
<p>I will be discussing this in detail in my <a href="https://herbsutter.com/2012/06/29/cb-session-atomic-weapons-the-c11-memory-model-and-modern-hardware/">atomic&lt;&gt; Weapons</a> talk at C&amp;B next week, which I hope to make freely available online in the near future (as I do most of my talks). I’ll post a link on this blog when I can make it available online.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/feed/</wfw:commentRss>
		<slash:comments>10</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Talk Video: Welcome to the Jungle (60 min version + Q&#038;A)</title>
		<link>https://herbsutter.com/2012/06/21/talk-video-welcome-to-the-jungle-60-min-version-qa/</link>
				<comments>https://herbsutter.com/2012/06/21/talk-video-welcome-to-the-jungle-60-min-version-qa/#comments</comments>
				<pubDate>Thu, 21 Jun 2012 20:40:10 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1572</guid>
				<description><![CDATA[While visiting Facebook earlier this month, I gave a shorter version of my “Welcome to the Jungle” talk, based on the eponymous WttJ article. They made a nice recording and it’s now available online here: Facebook Engineering Title: Herb Sutter: Welcome to the Jungle In the twilight of Moore&#8217;s Law, the transitions to multicore processors, [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><a href="https://www.facebook.com/photo.php?v=10151029515183109"><img title="image" style="background-image:none;float:right;padding-top:0;padding-left:0;margin:10px 0 10px 10px;display:inline;padding-right:0;border-width:0;" border="0" alt="image" align="right" src="https://herbsutter.files.wordpress.com/2012/06/image.png?w=324&#038;h=174" width="324" height="174" /></a>While visiting Facebook earlier this month, I gave a shorter version of my “Welcome to the Jungle” talk, based on the <a href="https://herbsutter.com/welcome-to-the-jungle/">eponymous WttJ article</a>. They made a nice recording and it’s now available online here:</p>
<blockquote>
<p><strong>Facebook Engineering</strong></p>
<p><a href="https://www.facebook.com/photo.php?v=10151029515183109"><strong>Title: Herb Sutter: Welcome to the Jungle</strong></a></p>
<p>In the twilight of Moore&#8217;s Law, the transitions to multicore processors, GPU computing, and HaaS cloud computing are not separate trends, but aspects of a single trend—mainstream computers from desktops to &#8216;smartphones&#8217; are being permanently transformed into heterogeneous supercomputer clusters. Henceforth, a single compute-intensive application will need to harness different kinds of cores, in immense numbers, to get its job done. &#8212; The free lunch is over. Now welcome to the hardware jungle.</p>
</blockquote>
<p>The <a href="https://developers.facebook.com/attachment/Welcome_to_the_Jungle_-_FB-pdf/">slides are available here</a>. (There doesn’t seem to be a link to the slides on the page itself as I write this.)</p>
<p>For those interested in a longer version, in April I gave a 105-minute + Q&amp;A version of this talk in Kansas City at Perceptive, also <a href="https://herbsutter.com/2012/04/23/talk-video-welcome-to-the-jungle/">available online where I posted before</a>.</p>
<h3>A word about “cluster in a box”</h3>
<p>I should have remembered that describing a PC as a “heterogeneous cluster in a box” is a big red button for people, in particular because “cluster” implies “parts can fail and program should continue.” So in the Q&amp;A, one commenter made the point that I should have mentioned reliability is an issue.</p>
<p>As I answered there, I half agree – it’s true but it’s only half the story, and it doesn’t affect the programming model (see more below). One of the slides I omitted to shorten this version of the talk highlighted that there are actually two issues when you go from “Disjoint (tightly coupled)” to “Disjoint (loosely coupled)”: <strong>reliability</strong> <em>and </em><strong>latency</strong>, and both are important. (I also mentioned this in the <a href="https://herbsutter.com/welcome-to-the-jungle/">original WttJ article</a> this is based on; just search for “reliability.”)</p>
<p>Even after the talk, I still got strong resistance along the lines that, ‘no, you obviously don’t get it, latency isn’t a significant issue at all, reliability is the central issue and it kills your argument because it makes the model fundamentally different.’ Paraphrasing subsequent email:</p>
<blockquote>
<p>‘A fundamental difference between distributed computing and single-box multiprocessing is that in the former case you don&#8217;t know whether a failure was a communication failure (i.e. the task was completed but communication failed) or a genuine failure to carry the task. (Hence all complicated two-phase commit protocols etc.) In contrast, in a single-box scenario you can know the box you&#8217;re on is working.’</p>
</blockquote>
<p>Let me respond further to this here, because clearly these guys know more about distributed systems than I do and I’m always happy to be educated, but I also think we have a disconnect on three things asserted above: It is not my understanding that reliability is more important than latency, or that apps have to distinguish comms failures from app exceptions, or that N-phase commit enters the picture.</p>
<p>First, I don’t agree with the assertion that reliability alone is what’s important, or that it’s more important than latency, for the following reason:</p>
<ul>
<li><strong>You can build reliable transports on top of unreliable ones.</strong> You do it through techniques like sequencing, redundancy, and retry. A classic example is <a href="http://en.wikipedia.org/wiki/Transmission_Control_Protocol">TCP</a>, which delivers reliable communications over notoriously- and deliberately-unreliable IP which can drop and reorder packets as network nodes and communications paths keep madly appearing and reappearing like a herd of crazed Cheshire cats. We can and do build secure reliable global banking systems on that.</li>
<li><strong>Once you do that, you have turned a reliability issue into a performance (specifically latency) issue.</strong> Both reliability and latency are key issues when moving to loosely-coupled systems, but because you can turn the first into the second, it’s latency that is actually the more fundamental and important one – and the only one the developer needs to deal with.</li>
</ul>
<p>For example, to use compute clouds like Azure and AWS, you usually start with two basic pieces:</p>
<ul>
<li>the queue(s), which you use to push the work items out/around and results back/around; and </li>
<li>an elastic set of compute nodes, each of which pulls work items from the queue and processes them.</li>
</ul>
<p>What happens when you encounter a reliability problem? A node can pull a work item but fail to complete it, for example if the node crashes or the system encounters a partial network outage or other communication problem.</p>
<p>Many modern systems already automatically recover and have another node re-pull the same work item to make sure each work item gets done even in the face of partial failures. From the app&#8217;s point of view, such <strong>failures just manifest as degraded performance (higher latency or time-to-solution) and therefore mainly affect the granularity of parallel work items</strong> – they have to be big enough to be worth sending elsewhere and so minimum size is directly proportional to latency so that the overheads do not dominate. They do not manifest as app-visible failures.</p>
<p>Yes, the elastic cloud implementation has to deal with things like network failures and retries. But no, this isn’t your problem; it’s not supposed to be your job to implement the elastic cloud, it’s supposed to be your job just to implement each node’s local logic and to create whatever queues you want and push your work item data into them.</p>
<p>Aside: Of course, as with any retry-based model, you have to make sure that a partly-executed work item doesn’t expose any partial side effects it shouldn’t, and normally you prevent that by doing the work in a transaction and rolling it back on failure, or in the extreme (not generally recommended but sometimes okay) resorting to compensating writes to back out partial work. </p>
<p>That covers everything except the comment about two-phase commit: Citing that struck me as odd because I haven’t heard much us of that kind of coupled approach in years. Perhaps I’m misinformed, but my impression of 2- or N-phase commit protocols was that they have some serious problems: </p>
<ul>
<li>They are inherently nonscalable. </li>
<li>They increase rather than decrease interdependencies in the system – even with heroic efforts like majority voting and such schemes that try to allow for subsets of nodes being unavailable, which always seemed fragile to me. </li>
<li>Also, I seem to remember that NPC is a blocking protocol, which if so is inherently anti-concurrency. One of the big realizations in modern mainstream concurrency in the past few years is that Blocking Is Nearly Always Evil. (I’m looking at you, <em>future.get()</em>, and this is why the committee is now considering adding the nonblocking <em>future.then()</em> as well.)</li>
</ul>
<p>So my impression is that these were primarily of historical interest – if they are still current in modern datacenters, I would appreciate learning more about it and seeing if I’m overly jaded about N-phase commit.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/06/21/talk-video-welcome-to-the-jungle-60-min-version-qa/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>

		<media:content url="https://herbsutter.files.wordpress.com/2012/06/image.png" medium="image">
			<media:title type="html">image</media:title>
		</media:content>
	</item>
		<item>
		<title>Facebook Folly &#8211; OSS C++ Libraries</title>
		<link>https://herbsutter.com/2012/06/02/facebook-folly-oss-c-libraries/</link>
				<comments>https://herbsutter.com/2012/06/02/facebook-folly-oss-c-libraries/#comments</comments>
				<pubDate>Sun, 03 Jun 2012 04:57:24 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1537</guid>
				<description><![CDATA[I’ve been beating the drum this year (see the last section of the talk) that the biggest problem facing C++ today is the lack of a large set of de jure and de facto standard libraries. My team at Microsoft just recently announced Casablanca, a cloud-oriented C++ library and that we intend to open source, [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>I’ve been <a href="http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/C-11-VC-11-and-Beyond">beating the drum this year</a> (see the last section of the talk) that the biggest problem facing C++ today is the lack of a large set of <em>de jure</em> and <em>de facto</em> standard libraries. My team at Microsoft just recently announced <strong><a href="https://herbsutter.com/2012/04/30/c-libraries-casablanca/">Casablanca</a></strong>, a cloud-oriented C++ library and that we intend to open source, and we’re making other even bigger efforts that I hope will bear fruit and I’ll be able to share soon. But it can’t be just one company – many companies have already shared great open libraries on the past, but still more of us have to step up.</p>
<p>In that vein, I was extremely happy to see another effort come to fruition today. A few hours ago I was at Facebook to speak at their C++ day, and I got to be in the room when Andrei Alexandrescu dropped his arm to officially launch <strong><a href="https://www.facebook.com/notes/facebook-engineering/folly-the-facebook-open-source-library/10150864656793920">Folly</a></strong>:</p>
<blockquote>
<h4><font size="3"><a href="https://www.facebook.com/notes/facebook-engineering/folly-the-facebook-open-source-library/10150864656793920">Folly: The Facebook Open Source Library</a></font></h4>
<p>by <a href="http://www.facebook.com/delong.j">Jordan DeLong</a> on Saturday, June 2, 2012 at 2:59pm ·</p>
<p>Facebook is built on open source from top to bottom, and could not exist without it. As engineers here, we use, contribute to, and release a lot of open source software, including pieces of our core infrastructure such as <a href="https://github.com/facebook/hiphop-php">HipHop</a> and <a href="http://thrift.apache.org/">Thrift</a>.</p>
<p>But in our C++ services code, one clear bottleneck to releasing more work has been that any open sourced project needed to break dependencies on unreleased internal library code. To help solve that problem, today we open sourced an initial release of Folly, a collection of reusable C++ library artifacts developed and used at Facebook. This announcement was made at our C++ conference at Facebook in Menlo Park, CA.</p>
<p>Our primary aim with this &#8216;foolishness&#8217; is to create a solution that allows us to continue open sourcing parts of our stack without resorting to reinventing some of our internal wheels. And because Folly&#8217;s components typically perform significantly faster than counterparts available elsewhere, are easy to use, and complement existing libraries, we think C++ developers might find parts of this library interesting in their own right.</p>
</blockquote>
<p>Andrei announced that Folly stood for the <strong><font color="#0000ff">F</font></strong>acebook <strong><font color="#0000ff">O</font></strong>pen <strong><font color="#0000ff">Ll</font></strong>ibrar<strong><font color="#0000ff">y</font></strong>. He claimed it was a Welsh name, which is even funnier when said by a charming Romanian man.</p>
<p>Microsoft, and I personally, would like to congratulate Facebook on this release! Getting more high-quality open C++ libraries is a Good Thing, and I think it is safe to say that Casablanca and Folly are just the beginning. There’s a lot more coming&#160; across our industry this year. Stay tuned.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/06/02/facebook-folly-oss-c-libraries/feed/</wfw:commentRss>
		<slash:comments>12</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Two Sessions: C++ Concurrency and Parallelism &#8211; 2012 State of the Art (and Standard)</title>
		<link>https://herbsutter.com/2012/05/28/two-sessions-c-concurrency-and-parallelism-2012-state-of-the-art-and-standard/</link>
				<comments>https://herbsutter.com/2012/05/28/two-sessions-c-concurrency-and-parallelism-2012-state-of-the-art-and-standard/#comments</comments>
				<pubDate>Tue, 29 May 2012 00:09:27 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Effective Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1531</guid>
				<description><![CDATA[It’s time for, not one, but two brand-new, up-to-date talks on the state of the art of concurrency and parallelism in C++. I’m going to put them together especially and only for C++ and Beyond 2012, and I’ll be giving them nowhere else this year: C++ Concurrency – 2012 State of the Art (and Standard) [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>It’s time for, not one, but two brand-new, up-to-date talks on the state of the art of concurrency and parallelism in C++. I’m going to put them together <strong>especially and only for <em><a href="http://cppandbeyond.com/">C++ and Beyond 2012</a></em></strong>, and I’ll be giving them nowhere else this year:</p>
<ul>
<li><strong><font size="3">C++ Concurrency – 2012 State of the Art (and Standard)</font></strong> </li>
<li><strong><font size="3">C++ Parallelism – 2012 State of the Art (and Standard)</font></strong> </li>
</ul>
<p>And there’s a lot to tell. 2012 has already been a busy year for the pushing the boundaries of both “shipping-and-practical” and “proto-standard” concurrency and parallelism in C++:</p>
<ul>
<li><strong>In February</strong>, the <a href="https://herbsutter.com/2012/03/08/trip-report-february-2012-c-standards-meeting/">spring ISO C++ standards meeting</a> saw record attendance at 73 experts (normal is 50-55), and spent the full week primarily on new language and library proposals, with notable emphasis on the area of concurrency and parallelism. There was so much interest that I formed four Study Groups and appointed chairs: the largest on concurrency and parallelism (SG1, Hans Boehm), and three others on modules (SG2, Doug Gregor), filesystem (SG3, Beman Dawes), and networking (SG4, Kyle Kloepper). </li>
<li><strong>Three weeks ago</strong>, we hosted another three-day face-to-face meeting for SG1 and SG4 – and at nearly 40 people the SG1 attendance rivaled that of a normal full ISO C++ meeting, with a who’s-who of the world’s concurrency and parallelism experts in attendance and <a href="https://herbsutter.com/2012/04/06/we-want-await-a-c-talk-thats-applicable-to-c/">further proposal presentations</a> from companies like IBM, Intel, and Microsoft. There was so much interest that I had to form a new Study Group 5 for Transactional Memory (SG5), and appointed Michael Wong of IBM as chair. </li>
<li>Over the summer, we’ll all be working on updated proposals for the October ISO C++ meeting in Portland. </li>
</ul>
<p>Things are heating up, and we’re narrowing down which areas to focus on.</p>
<p>I’ve spoken and written on these topics before. Here’s what’s different about these talks:</p>
<ul>
<li><strong>Brand new: </strong>This material goes beyond what I’ve written and taught about before in my <em>Effective Concurrency</em> articles and courses. </li>
<li><strong>Cutting-edge current:</strong> It covers the best-practices state of the art <strong>techniques</strong> and <strong>shipping tools</strong>, and what parts of that are standardized <strong>in C++11 already</strong> (the answer to that one may surprise you!) and what’s en route to <strong>near-term standardization</strong> and why, with coverage of the latest discussions. </li>
<li><strong>Mainstream hardware – many kinds of parallelism:</strong> What’s the relationship among <strong>multi-core</strong> CPUs, <strong>hardware threads</strong>, SIMD <strong>vector units</strong> (Intel <a href="http://en.wikipedia.org/wiki/Streaming_SIMD_Extensions">SSE</a> and <a href="http://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX</a>, ARM <a href="http://www.arm.com/products/processors/technologies/neon.php">Neon</a>), and <strong>GPGPU </strong>(general-purpose computation on GPUs, which I covered at <em>C++ and Beyond 2011</em>)? Which are most interesting, what technologies are available now, and what’s being considered for near-term standardization? </li>
<li><strong>Blocking vs. non-blocking:</strong> What’s the difference between blocking and non-blocking styles, why on earth would you care, which kinds does C++11 support, and how are we looking at rounding it out in C++1<em>y</em>? </li>
<li><strong>Task and data parallelism:</strong> What’s the difference between task parallelism and data parallelism, which kind of of hardware does each allow you to exploit, and why? </li>
<li><strong>Work stealing: </strong>What’s the difference between thread pools and work stealing, what are the major flavors of work stealing, which of these (if any) does C++11 already support and is already shipping on some advanced commercial C++ compilers today (this answer will likely surprise you), and what needs to be done in the next round for a complete state-of-the-art parallelism story in C++1<em>y</em>? </li>
</ul>
<p>The answers all matter to you – even the ones not yet in the C++ standard – because they are real, available in shipping products, and affect how you design your software today.</p>
<p>This will be a broad and deep dive. At C++ and Beyond 2011, the <em>attendees</em> (audience!) included some of the world’s leading experts on parallelism and compilers. At these sessions of C&amp;B 2012, I expect anyone who wasn’t personally at the SG1 meeting this month, even world-class experts, will learn something new in these talks. I certainly did, and that’s why I’m motivated to turn the information into talks and share. This isn’t just cool stuff – it’s important and useful in production code today.</p>
<p>I hope to see many of you at C&amp;B 2012. I’m excited about these topics, and about Scott’s and Andrei’s new material – you just can’t get this stuff anywhere else.</p>
<p>Asheville is going to be blast. I can’t wait.</p>
<p>Herb</p>
<hr />
<p>P.S.: I haven’t seen this much attention and investment in C++ since last century – C++ conferences at record numbers, C++ compiler investments by the biggest companies in the industry (e.g., Clang), and much more that we’ve seen already…</p>
<p>… and a little bird tells me there’s a lot more major C++ news coming this year. Stay tuned, and fasten your seat belts. 2012 ain’t done yet, not by a long shot, and I’ll be able to say more about C++ as a whole (besides the specific topics mentioned above) for the first time at C&amp;B in August. I hope to see you there.</p>
<p>FYI, C&amp;B is already over 60% full, and early bird registration ends this Friday, June 1 – so <a href="http://cppandbeyond2012.eventbrite.com/">register today</a>.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/05/28/two-sessions-c-concurrency-and-parallelism-2012-state-of-the-art-and-standard/feed/</wfw:commentRss>
		<slash:comments>9</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>C++ Libraries: Casablanca</title>
		<link>https://herbsutter.com/2012/04/30/c-libraries-casablanca/</link>
				<comments>https://herbsutter.com/2012/04/30/c-libraries-casablanca/#comments</comments>
				<pubDate>Mon, 30 Apr 2012 23:19:59 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Microsoft]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1512</guid>
				<description><![CDATA[At GoingNative in February, I emphasized the need for more modern and portable C++ libraries, including for things like RESTful web/cloud services, HTTP, JSON, and more. The goal is to find or develop modern C++ libraries that leverage C++11 features, and then submit the best for standardization. Microsoft wants to do its part, and here’s [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><a href="http://msdn.microsoft.com/en-us/devlabs/casablanca"><img style="background-image:none;float:right;padding-top:0;padding-left:0;margin:10px 0 10px 10px;display:inline;padding-right:0;border:0;" title="image" src="https://herbsutter.files.wordpress.com/2012/04/image4.png?w=380&#038;h=230" alt="image" width="380" height="230" align="right" border="0" /></a>At <a href="http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/C-11-VC-11-and-Beyond">GoingNative in February</a>, I emphasized the need for more modern and portable C++ libraries, including for things like RESTful web/cloud services, HTTP, JSON, and more. The goal is to find or develop modern C++ libraries that leverage C++11 features, and then submit the best for standardization.</p>
<p>Microsoft wants to do its part, and here’s a step in that direction.</p>
<p>Today I’m pleased to see Soma’s post about <strong><a href="http://blogs.msdn.com/b/somasegar/archive/2012/04/30/devlabs-c-cloud-services-and-you.aspx">“C++, Cloud Services, and You”</a></strong> announcing the <a href="http://msdn.microsoft.com/en-us/devlabs/casablanca"><strong>DevLabs release of Casablanca</strong></a>, a set of C++ libraries for Visual C++ users that start to bring the same modern conveniences already enjoyed by .NET and Node.js and Erlang users also to C++ developers on our local and cloud platforms, including modern C++ libraries for REST, HTTP, and JSON. From Soma’s announcement, adding my own <strong>emphasis </strong>and minor code edits:</p>
<blockquote><p>Historically, we’ve lacked such simple tools for developers using C++.  While there are multiple relevant native networking APIs (e.g. WinINet, WinHTTP, IXMLHttpRequest2, HTTP Server API), these are not optimized from a productivity perspective for <strong>consuming and implementing RESTful cloud services using modern C++</strong>.  They don’t compose particularly well with code based on the standard C++ libraries, and they don’t <strong>take advantage of modern C++ language features and practices</strong> in their programming models.</p>
<p>This is where “Casablanca” comes in.  “Casablanca” is a set of libraries for C++ developers, taking advantage of some recent standard language features already available through Visual Studio.</p>
<p><strong>“Casablanca” aims to make it significantly easier for C++ coders to consume and implement RESTful services.  It builds on lessons from .NET, from Node.js, from Erlang, and from other influencers to create a modern model that is meant to be easy to program while still being scalable, composable, and flexible.</strong></p>
<p>As an example, here’s a snippet that uses the client HTTP library to search Bing for my name and output the results to the console:</p>
<pre>    http_client bing( L"http://www.bing.com/search" );

    bing.request( methods::GET, L"?q=S.Somasegar" )
        .then( []( http_response response ) {
            cout &lt;&lt; "HTML SOURCE:" &lt;&lt; endl &lt;&lt; response.to_string() &lt;&lt; endl; })
        .wait();</pre>
<p>and here’s a simple web listener hosted in a console application:</p>
<pre>    listener::create( argv[1], []( http_request req ) {
            req.reply( status_codes::OK, "Namaste!" ); })
        .listen( []{ fgetc( stdin ); } )
        .wait();</pre>
<p>For those of you looking to build Azure services in C++, “Casablanca” comes with a Visual Studio wizard to set up everything up correctly.  You can target both Web and Worker roles, and you can access Azure storage using the built-in C++ library bindings. […] Taking C++ to the cloud with “Casablanca” is another exciting step in that journey.</p></blockquote>
<p>Today’s Casablanca release is as a DevLabs project, to get usability feedback and to eventually support these features in the full Visual C++ product. If you’re interested in using C++ to consume and implement cloud services, and sharing what kind of support you want and whether you think Casablanca is on the right track, please let us know in the <a href="http://social.msdn.microsoft.com/Forums/en-US/casablanca/threads">forums</a>.</p>
<p>Looking beyond Visual C++, one piece of Casablanca is already being proposed for standardization, namely the “future.then” nonblocking continuations that are required to be able to write highly responsive composable libraries – you really want all async libraries to talk about their work using the same type, and std::future already gives half of what we need (blocking synchronization) and just needs the non-blocking part too. Also being proposed as an optional layer on top of “future.then” is an “await” style of language support to make the async operations as easy to express and use in C++ as in any of the best languages in the world.</p>
<p>Note that there are other C++ libraries too for several of these facilities. Repeating what I said at GoingNative, we (Microsoft) don’t care whose libraries get standardized – whether ones we contribute or someone else’s. We care most that <em>there be</em> standard C++ libraries for these modern uses, starting with the most basic “future.then” support, and to encourage all companies and groups who have libraries in these important spaces to contribute them and take the best and make them available to C++ developers on all platforms. This is a small step in that process.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/04/30/c-libraries-casablanca/feed/</wfw:commentRss>
		<slash:comments>12</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>

		<media:content url="https://herbsutter.files.wordpress.com/2012/04/image4.png" medium="image">
			<media:title type="html">image</media:title>
		</media:content>
	</item>
		<item>
		<title>Talk Video: Welcome to the Jungle</title>
		<link>https://herbsutter.com/2012/04/23/talk-video-welcome-to-the-jungle/</link>
				<comments>https://herbsutter.com/2012/04/23/talk-video-welcome-to-the-jungle/#comments</comments>
				<pubDate>Mon, 23 Apr 2012 15:31:58 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>
		<category><![CDATA[Web]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=1487</guid>
				<description><![CDATA[Last month in Kansas City I gave a talk on &#8220;Welcome to the Jungle,&#8221; based on my recent essay of the same name (sequel to &#8220;The Free Lunch Is Over&#8221;) concerning the turn to mainstream heterogeneous distributed computing and the end of Moore’s Law. Perceptive Software has now made the talk available online [EOA: the talk itself starts six [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Last month in Kansas City I gave a talk on &#8220;Welcome to the Jungle,&#8221; based on <a href="https://herbsutter.com/welcome-to-the-jungle/">my recent essay of the same name</a> (sequel to &#8220;The Free Lunch Is Over&#8221;) concerning the turn to mainstream heterogeneous distributed computing and the end of Moore’s Law.</p>
<p>Perceptive Software has now made the talk available online <em>[<strong>EOA</strong>: the talk itself starts six minutes in]</em>:</p>
<blockquote><p><strong><a href="http://shadow-technologies.tv/video/179">Welcome to the Jungle</a></strong></p>
<p>In the twilight of Moore’s Law, the transitions to multicore processors, GPU computing, and HaaS cloud computing are not separate trends, but aspects of a single trend – mainstream computers from desktops to ‘smartphones’ are being permanently transformed into heterogeneous supercomputer clusters. Henceforth, a single compute-intensive application will need to harness different kinds of cores, in immense numbers, to get its job done. – The free lunch is over. Now welcome to the hardware jungle.</p></blockquote>
<p>I hope you enjoy it.</p>
<p>Warning: It&#8217;s two hours (with Q&amp;A) because of the broad and deep material. There&#8217;s a nice pause point between major sections at the one-hour mark that makes it convenient to split it into two one-hour lunchtime brownbag viewings.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/04/23/talk-video-welcome-to-the-jungle/feed/</wfw:commentRss>
		<slash:comments>10</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>We want await! A C# talk that&#8217;s applicable to C++</title>
		<link>https://herbsutter.com/2012/04/06/we-want-await-a-c-talk-thats-applicable-to-c/</link>
				<comments>https://herbsutter.com/2012/04/06/we-want-await-a-c-talk-thats-applicable-to-c/#comments</comments>
				<pubDate>Sat, 07 Apr 2012 06:13:01 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C# / .NET]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Microsoft]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1450</guid>
				<description><![CDATA[A nice talk by Mads Torgersen just went live on Channel 9 about C#’s non-blocking Task&#60;T&#62;.ContinueWith() library feature and await language feature, which are a big hit in C# (and Visual Basic) for writing highly concurrent code that looks pretty much just like sequential code. Mads is one of the designers of await. If you’re [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>A <a href="http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2012/Language-Support-for-Asynchronous-Programming">nice talk by Mads Torgersen just went live on Channel 9</a> about C#’s non-blocking <em>Task&lt;T&gt;.ContinueWith()</em> library feature and <em>await</em> language feature, which are a big hit in C# (and Visual Basic) for writing highly concurrent code that looks pretty much just like sequential code. Mads is one of the designers of <em>await</em>.</p>
<p>If you’re a C++ programmer, you may be interested in this because I’ve worked to have these very features be offered as proposals for ISO C++, just with a few naming tweaks like renaming <em>Task&lt;T&gt;.ContinueWith()</em> to <em>std::future&lt;T&gt;::then()</em>. They were initially presented at the recent Kona meeting in February, and we’ll dig deeper next month at the special ISO C++ study group meeting on concurrency and parallelism.</p>
<p>Here’s the talk link and abstract:</p>
<blockquote>
<h3><a href="http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2012/Language-Support-for-Asynchronous-Programming">Language Support for Asynchronous Programming</a></h3>
<p><strong>Mads Torgersen</strong></p>
<p>Asynchronous programming is what the doctor usually orders for unresponsive client apps and for services with thread-scaling issues. This usually means a bleak departure from the imperative programming constructs we know and love into a spaghetti hell of callbacks and signups. C# and VB are putting an end to that, reinstating all your tried-and-true control structures on top of a future-based model of asynchrony.</p>
</blockquote>
<p>While we were chatting after the talk, I managed to gently twist Mads’ arm and he has graciously agreed to come to the May 7-9 ISO C++ parallelism study group special meeting to present this to the committee members in detail and answer questions about <em>await</em>’s design and C# users’ experience with it in production code, which will help the committee decide whether or not this is something they want to pursue for ISO C++.</p>
<p>I hope you enjoy the talk. While at Lang.NEXT, I also participated in a panel and gave a C++ talk but those sessions aren’t live yet; I’ll post links once they are.</p>
<p><strong></strong></p>
<p><strong>Trivia:</strong> If you noticed the Romanian accent in the first question from the audience, it’s because it came from Andrei Alexandrescu, who was sitting beside Walter Bright, both of whom were two of the other speakers at the conference. It was fun to be in a room full of language designers and implementers sharing notes about each other’s languages and experience.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/04/06/we-want-await-a-c-talk-thats-applicable-to-c/feed/</wfw:commentRss>
		<slash:comments>20</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>&#8220;Welcome to the Jungle&#8221; in Kansas City &#8211; March 20, 2012</title>
		<link>https://herbsutter.com/2012/03/06/welcome-to-the-jungle-in-kansas-city-march-20-2012/</link>
				<comments>https://herbsutter.com/2012/03/06/welcome-to-the-jungle-in-kansas-city-march-20-2012/#comments</comments>
				<pubDate>Tue, 06 Mar 2012 23:24:34 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1411</guid>
				<description><![CDATA[Thanks to Perceptive Software who are bringing me to Kansas City in two weeks to give a free talk on “Welcome to the Jungle.” The talk will be based on my recent essay of the same name (sequel to ”The Free Lunch Is Over”) concerning the turn to mainstream heterogeneous distributed computing and the end [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><a href="https://herbsutter.files.wordpress.com/2012/03/welcome.png"><img style="display:inline;float:right;margin:10px 0 10px 10px;" title="Welcome" alt="Welcome" align="right" src="https://herbsutter.files.wordpress.com/2012/03/welcome_thumb.png?w=288&#038;h=194" width="288" height="194" /></a>Thanks to <a href="http://www.perceptivesoftware.com/">Perceptive Software</a> who are bringing me to Kansas City in two weeks to give a <a href="http://www.perceptivesoftware.com/discover/herbsutter/">free talk on <strong>“Welcome to the Jungle.”</strong></a></p>
<p>The talk will be based on <a href="https://herbsutter.com/welcome-to-the-jungle/">my recent essay of the same name</a> (sequel to ”The Free Lunch Is Over”) concerning the turn to mainstream heterogeneous distributed computing and the end of Moore’s Law, with ample time for Q&amp;A and discussion.</p>
<p>Here are the coordinates:</p>
<blockquote>
<p><strong><a href="http://www.perceptivesoftware.com/discover/herbsutter/">Computing Trends with Herb Sutter: Welcome to the Jungle</a></strong></p>
<p><strong>When:</strong> Tuesday, March 20 at 1:00 – 3:00 P.M.</p>
<p><strong>Where: </strong><a href="http://binged.it/wYRLlS">Boulevard Brewery</a>, 2501 Southwest Blvd, Kansas City, MO, USA 64108</p>
<p><strong>Abstract:</strong> In the twilight of Moore’s Law, the transitions to multicore processors, GPU computing, and HaaS cloud computing are not separate trends, but aspects of a single trend – mainstream computers from desktops to ‘smartphones’ are being permanently transformed into heterogeneous supercomputer clusters. Henceforth, a single compute-intensive application will need to harness different kinds of cores, in immense numbers, to get its job done. – The free lunch is over. Now welcome to the hardware jungle.</p>
</blockquote>
<p>This is a free lecture; all are invited, but you should register to make sure you’ll have a seat. Note that this talk is live only and is not being recorded or webcast.</p>
<p>I look forward to meeting many of you there in person.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2012/03/06/welcome-to-the-jungle-in-kansas-city-march-20-2012/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>

		<media:content url="https://herbsutter.files.wordpress.com/2012/03/welcome_thumb.png" medium="image">
			<media:title type="html">Welcome</media:title>
		</media:content>
	</item>
		<item>
		<title>Welcome to the Jungle</title>
		<link>https://herbsutter.com/2011/12/29/welcome-to-the-jungle/</link>
				<comments>https://herbsutter.com/2011/12/29/welcome-to-the-jungle/#comments</comments>
				<pubDate>Fri, 30 Dec 2011 01:53:11 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Opinion & Editorial]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1271</guid>
				<description><![CDATA[With so much happening in the computing world, now seemed like the right time to write “Welcome to the Jungle” – a sequel to my earlier “The Free Lunch Is Over” essay. Here’s the introduction: &#160; Welcome to the Jungle In the twilight of Moore’s Law, the transitions to multicore processors, GPU computing, and HaaS [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>With so much happening in the computing world, now seemed like the right time to write <a href="https://herbsutter.com/welcome-to-the-jungle/"><strong>“Welcome to the Jungle”</strong></a><strong> </strong>– a sequel to my earlier “The Free Lunch Is Over” essay. Here’s the introduction:</p>
<p>&#160;</p>
<blockquote>
<h3><strong><a href="https://herbsutter.com/welcome-to-the-jungle/">Welcome to the Jungle</a></strong></h3>
<p align="center"><em>In the twilight of Moore’s Law, the transitions to multicore processors, GPU computing, and HaaS cloud computing are not separate trends, but aspects of a single trend – mainstream computers from desktops to ‘smartphones’ are being permanently transformed into heterogeneous supercomputer clusters. Henceforth, a single compute-intensive application will need to harness different kinds of cores, in immense numbers, to get its job done.</em></p>
<p align="center"><em>The free lunch is over. Now welcome to the hardware jungle.</em></p>
<p>&#160;</p>
<p>From 1975 to 2005, our industry accomplished a phenomenal mission: In 30 years, we put a personal computer on every desk, in every home, and in every pocket.</p>
<p>In 2005, however, mainstream computing hit a wall. In <a href="http://www.gotw.ca/publications/concurrency-ddj.htm"><strong>“The Free Lunch Is Over”</strong> (December 2004)</a>, I described the reasons for the then-upcoming industry transition from single-core to multi-core CPUs in mainstream machines, why it would require changes throughout the software stack from operating systems to languages to tools, and why it would permanently affect the way we as software developers have to write our code if we want our applications to continue exploiting Moore’s transistor dividend.</p>
<p>In 2005, our industry undertook a new mission: to put a personal parallel supercomputer on every desk, in every home, and in every pocket. 2011 was special: it’s the year that we completed the transition to parallel computing in all mainstream form factors, with the arrival of multicore tablets (e.g., iPad 2, Playbook, Kindle Fire, Nook Tablet) and smartphones (e.g., Galaxy S II, Droid X2, iPhone 4S). 2012 will see us continue to build out multicore with mainstream quad- and eight-core tablets (as Windows 8 brings a modern tablet experience to x86 as well as ARM), <a href="https://herbsutter.files.wordpress.com/2011/12/image_thumb99.png"><img style="background-image:none;padding-left:0;padding-right:0;display:inline;float:right;padding-top:0;border-width:0;margin:20px 0 0 10px;" title="image_thumb99" border="0" alt="image_thumb99" align="right" src="https://herbsutter.files.wordpress.com/2011/12/image_thumb99_thumb.png?w=480&#038;h=228" width="480" height="228" /></a>and the last single-core gaming console holdout will go multicore (as Nintendo’s Wii U replaces Wii).</p>
<p>This time it took us just six years to deliver mainstream parallel computing in all popular form factors. And we know the transition to multicore is permanent, because multicore delivers compute performance that single-core cannot and there will always be mainstream applications that run better on a multi-core machine. There’s no going back.</p>
<p>For the first time in the history of computing, mainstream hardware is no longer a single-processor von Neumann machine, and never will be again.</p>
<p><em>That was the first act.&#160; . . .</em></p>
</blockquote>
<p>&#160;</p>
<p>I hope you enjoy it.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2011/12/29/welcome-to-the-jungle/feed/</wfw:commentRss>
		<slash:comments>10</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>

		<media:content url="https://herbsutter.files.wordpress.com/2011/12/image_thumb99_thumb.png" medium="image">
			<media:title type="html">image_thumb99</media:title>
		</media:content>
	</item>
		<item>
		<title>Daniel Moth&#8217;s C++ AMP session is now online</title>
		<link>https://herbsutter.com/2011/06/19/c-amp-overview/</link>
				<comments>https://herbsutter.com/2011/06/19/c-amp-overview/#comments</comments>
				<pubDate>Mon, 20 Jun 2011 00:58:18 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Microsoft]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=597</guid>
				<description><![CDATA[In my keynote on Wednesday, I highlighted just the top two important features in the C++ AMP programming model. That afternoon, my coding colleague and demo demigod Daniel Moth gave a 45-minute session covering the entire C++ AMP programming model that walked through all the features with more examples. Daniel&#8217;s talk is now also online [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>In my keynote on Wednesday, I highlighted just the top two important features in the C++ AMP programming model. That afternoon, my coding colleague and demo demigod Daniel Moth gave a 45-minute session covering the entire C++ AMP programming model that walked through all the features with more examples. Daniel&#8217;s talk is now <a href="http://channel9.msdn.com/Events/AMD-Fusion-Developer-Summit/AMD-Fusion-Developer-Summit-11/DanielMothAMP">also online at Channel 9</a>. I hope you enjoy it.</p>
<p>Note: The <a href="http://ecn.channel9.msdn.com/content/DanielMoth_CppAMP_Intro.pdf">PDF slides</a> link is small but important &#8212; the screen isn&#8217;t easy to see in the video itself.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2011/06/19/c-amp-overview/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>C++ AMP keynote is online</title>
		<link>https://herbsutter.com/2011/06/16/c-amp-keynote/</link>
				<comments>https://herbsutter.com/2011/06/16/c-amp-keynote/#comments</comments>
				<pubDate>Fri, 17 Jun 2011 00:21:25 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Microsoft]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=593</guid>
				<description><![CDATA[Yesterday I had the privilege of talking about some of the work we&#8217;ve been doing to support massive parallelism on GPUs in the next version of Visual C++. The video of my talk announcing C++ AMP is now available on Channel 9. (Update: Here&#8217;s an alternate link; it seems to be posted twice.) The first 20 [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Yesterday I had the privilege of talking about some of the work we&#8217;ve been doing to support massive parallelism on GPUs in the next version of Visual C++. The video of my talk announcing C++ AMP <strong><a href="http://channel9.msdn.com/posts/AFDS-Keynote-Herb-Sutter-Heterogeneous-Computing-and-C-AMP">is now available on Channel 9</a></strong>. (Update: Here&#8217;s an <a href="http://channel9.msdn.com/Events/AMD-Fusion-Developer-Summit/AMD-Fusion-Developer-Summit-11/KEYNOTE">alternate link</a>; it seems to be posted twice.)</p>
<p>The first 20 minutes has nothing to do with C++ in particular or any platform in particular, but tries to make the case that the right way to view the &#8220;trends&#8221; of multicore computing, GPU computing, and cloud computing (HaaS) is that they are not three trends at all, but merely facets of the same single trend &#8212; heterogeneous parallel computing.</p>
<p>If they are, then one programming model should be able to address them all. We think we&#8217;ve found one.</p>
<p>The main reasons we decided to build a new model is that we believe there needs to be a single model that has all of the following attributes:</p>
<ul>
<li><strong>C++, not C:</strong> It should leverage C++&#8217;s power for strong abstraction without sacrificing performance, not just be a dialect of C.</li>
<li><strong>Mainstream:</strong> It should be programmable by millions of developers, not just by a priesthood. Litmus test: Is the Hello World parallel GPU program a page and half, or a couple of lines?</li>
<li><strong>Minimal:</strong> It adds just one general-purpose language extension that addresses not only the immediate problem (dealing with cores that can&#8217;t support full C++) but many others. With the right general-purpose extension, the rest can be done as just a library.</li>
<li><strong>Portable:</strong> It allows shipping a single EXE that can use any combination of GPU vendors&#8217; hardware. The initial implementation uses DirectCompute and supports all devices that are DX11 capable; DirectCompute is just an implementation detail of the first release, and the model can (and I expect will) be implemented to directly talk to any interesting hardware.</li>
<li><strong>General and future-proof:</strong> The initial release will focus on GPU computing, but it&#8217;s intended to enable people to write code for the GPU in a way that in the future we can recompile with few or no changes to spread across any and all accessible compute cores, including ones in the cloud.</li>
<li><strong>Open:</strong> I mentioned that Microsoft intends to make the C++ AMP specification open, and encourages its implementation on other C++ compilers for any hardware or OS target. AMD announced that they will implement C++ AMP in their FSA reference compiler. NVidia also announced support.</li>
</ul>
<p>We&#8217;re really excited about this, and I hope you find the information in the talk to be useful. A prerelease implementation in Visual C++ that runs on Windows will be available later this year. More to come&#8230;</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2011/06/16/c-amp-keynote/feed/</wfw:commentRss>
		<slash:comments>31</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>AFDS Keynote Live Stream</title>
		<link>https://herbsutter.com/2011/06/14/afds-live-tream/</link>
				<pubDate>Wed, 15 Jun 2011 00:10:31 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Microsoft]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=589</guid>
				<description><![CDATA[Just a reminder for those interested in using C++ to harness GPUs for fast code: My keynote at AMD Fusion Developer&#8217;s Conference will be webcast live. I&#8217;ll post another link when the recorded talk is available for on-demand viewing. The talk starts at 8:30am U.S. Pacific time tomorrow (Wed June 15). Today Jem Davies of ARM [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Just a reminder for those interested in using C++ to harness GPUs for fast code: My keynote at AMD Fusion Developer&#8217;s Conference will be <strong><a href="http://developer.amd.com/afds/pages/webcast.aspx">webcast live</a></strong>. I&#8217;ll post another link when the recorded talk is available for on-demand viewing.</p>
<p>The talk starts at 8:30am U.S. Pacific time tomorrow (Wed June 15).</p>
<p>Today Jem Davies of ARM also gave a keynote. He&#8217;s a great speaker with a great message; look for it when it becomes available on demand. Recommended viewing whether or not you target ARM processors.</p>
<p>&nbsp;</p>
]]></content:encoded>
									
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Interview on Channel 9</title>
		<link>https://herbsutter.com/2011/05/04/interview-on-channel-9-2/</link>
				<comments>https://herbsutter.com/2011/05/04/interview-on-channel-9-2/#comments</comments>
				<pubDate>Wed, 04 May 2011 23:33:09 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C# / .NET]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Microsoft]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=561</guid>
				<description><![CDATA[Channel 9 just posted a new interview with me about ISO C++0x, C++&#8217;s place in the modern world, and all things C++. The topics we talked about ranged pretty widely, as you can see from the questions below. Here&#8217;s the blurb as posted on Channel 9 with links to specific questions in the interview. Enjoy. Herb [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Channel 9 just posted a new <a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11">interview with me</a> about ISO C++0x, C++&#8217;s place in the modern world, and all things C++. The topics we talked about ranged pretty widely, as you can see from the questions below.</p>
<p>Here&#8217;s the blurb as posted on Channel 9 with links to specific questions in the interview. Enjoy.</p>
<p>Herb</p>
<blockquote><p>I was lucky enough to catch up with <a href="https://herbsutter.com/" target="_blank">Herb Sutter</a> not too long after the <a href="https://herbsutter.com/2011/03/25/we-have-fdis-trip-report-march-2011-c-standards-meeting/" target="_blank">FDIS announcement</a> (Final Draft International Standard is complete).</p>
<p>As usual when talking to Herb, the conversation is all about C++ (well, we <em>do</em> talk about C# for a little while, but in the context of C++. Why? Tune in&#8230;).</p>
<p>See below for the specific questions that were asked. You can simply click on a link to move directly to that point in the conversation. I do, however, strongly recommend that <em>you watch the entire thing</em>. I also recommend that you don&#8217;t get used to this level of categorization in my videos (it takes a fair amount of time to do this sort of thing, so enjoy the times when I actually do this, but don&#8217;t expect me to do this all of the time).</p>
<p>It&#8217;s always great to talk to Herb and get a glimpse of what goes on in the C++ Standards Committee (which Herb chairs). In this specific conversation, it&#8217;s uplifting to see how excited Herb is for the future of one of the world&#8217;s most capable and widely used general purpose programming languages. C++ is a modern programming language for power and performance, but it&#8217;s also a highly abstracted general purpose language for building user mode applications, mobile apps, etc. The amazing part is how C++ can provide rich general programming abstractions and also ensure that your code can run at machine speeds. We talk about this, of course.</p>
<p>Tune in. Learn. Go native!</p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=1m37s">1:37 -&gt; What were the goals of the C++0x standard, at a high level?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=2m40s">2:40 -&gt; Language and Library abstractions and performance (how high can you go and still be fast as possible?)&#8230;</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=5m23s">5:23 -&gt; C++ as an application development language (in addition to the traditional C++ is a systems programming language meme)&#8230;</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=7m17s">07:17 -&gt; C++0x or can we now call it C++11?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=9m21s">09:21 -&gt; Standards committees and real world user representation&#8230;</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=10m39s">10:39 -&gt; Who comes up with the new features that get standardized (or not&#8230;)?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=13m1s">13:01 -&gt; What were the goals of the C++0x standard (non-canned answer)?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=14m21s">14:21 -&gt; What does Bjarne mean by C++0x being a better C++ for novice programmers?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=15m51s">15:51 -&gt; Why can&#8217;t C++ look more like C#?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=18m50s">18:50 -&gt; At the end of the day, everything(in terms of programmer-controlled computing) boils down to memory, right?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=23m12s">23:12 -&gt; What are some of the most significant new features in C++0x?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=25m5s">25:05 -&gt; What can VC++ developers expect to see in terms of C++0x implementation in Visual C++ next?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=27m9s">27:09 -&gt; C++ and type safety&#8230;</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=29m5s">29:05 -&gt; C++0x and backwards compatibility: any big breaking changes?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=34m16s">34:16 -&gt; C++0x in the Standard Library&#8230;</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=37m1s">37:01 -&gt; Any thinking in the Committee about doing more frequent experimental releases C++?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=39m4s">39:04 -&gt; Are their features that didn&#8217;t make it into the standard that you really wanted to be standardized?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=41m45s">41:45 -&gt; Are you comfortable with C++&#8217;s current state? Is it modern enough?</a></p>
<p><a href="http://channel9.msdn.com/Shows/Going+Deep/Conversation-with-Herb-Sutter-Perspectives-on-Modern-C0x11#time=43m22s">43:22 -&gt; Conclusion (or Charles doesn&#8217;t end the conversation when his farewell begins &#8211; where does it go from there? )</a></p></blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2011/05/04/interview-on-channel-9-2/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Keynote at the AMD Fusion Developer Summit</title>
		<link>https://herbsutter.com/2011/04/06/fusion/</link>
				<comments>https://herbsutter.com/2011/04/06/fusion/#comments</comments>
				<pubDate>Wed, 06 Apr 2011 19:52:35 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Microsoft]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=542</guid>
				<description><![CDATA[In a couple of months, I&#8217;ll be giving a keynote at the AMD Fusion Developer&#8217;s Summit, which will be held on June 13-16, 2011, in Bellevue, WA, USA. Here&#8217;s my talk&#8217;s description as it appears on the conference website: AFDS Keynote: “Heterogeneous Parallelism at Microsoft” Herb Sutter, Microsoft Principal Architect, Native Languages Parallelism is not [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>In a couple of months, I&#8217;ll be giving a keynote at the <a href="http://developer.amd.com/afds/">AMD Fusion Developer&#8217;s Summit</a>, which will be held on June 13-16, 2011, in Bellevue, WA, USA.</p>
<p>Here&#8217;s my talk&#8217;s description as it <a href="http://developer.amd.com/afds/pages/keynote.aspx">appears</a> on the conference website:</p>
<blockquote><p><strong><a href="http://developer.amd.com/afds/pages/keynote.aspx">AFDS Keynote: “Heterogeneous Parallelism at Microsoft”</a></strong><br />
<em>Herb Sutter, Microsoft Principal Architect, Native Languages</em></p>
<p>Parallelism is not just in full bloom, but increasingly in full variety. We know that getting full computational performance out of most machines—nearly all desktops and laptops, most game consoles, and the newest smartphones—already means harnessing local parallel hardware, mainly in the form of multicore CPU processing. This is the commoditization of the supercomputer.</p>
<p>More and more, however, getting that full performance can also mean using gradually ever-more-heterogeneous processing, from local GPGPU and Accelerated Processing Unit (APU) flavors to “often-on” remote parallel computing power in the form of elastic compute clouds. This is the generalization of the heterogeneous cluster in all its NUMA glory, and it’s appearing at all scales from on-die to on-machine to on-cloud.</p>
<p>In this talk, Microsoft’s chief native languages architect shares a vision of what this will mean for native software on Microsoft platforms from servers to devices, and showcases upcoming innovations that bring access to increasingly heterogeneous compute resources — from vector units and multicore, to GPGPU and APU, to elastic cloud — directly into the world’s most popular native languages.</p></blockquote>
<p>If you&#8217;re interested in high performance code for <a href="http://en.wikipedia.org/wiki/GPGPU">GPUs</a>, <a href="http://sites.amd.com/us/fusion/apu/Pages/fusion.aspx">APUs</a>, and other high-performance <a href="http://en.wikipedia.org/wiki/Three-letter_acronym">TLAs</a>, I hope to see you there.</p>
<p>Note: This talk is related to, but different from, the <a href="http://cppandbeyond.com/2011/04/02/session-announcement-c-and-the-gpu-and-beyond/">GPU talk I&#8217;ll be presenting</a> in August at <em><a href="https://herbsutter.com/2011/04/05/c-and-beyond-2011/">C++ and Beyond 2011</a></em> (aka C&amp;B). You can expect the above keynote to be, well, keynote-y&#8230; oriented toward software product features and of course AMD&#8217;s hardware, with plenty of forward-looking industry vision style material. My <a href="http://cppandbeyond.com/2011/04/02/session-announcement-c-and-the-gpu-and-beyond/">August C&amp;B technical talk</a> will be just that, an in-depth performance-oriented and sometimes-gritty technical session that will also mention product-related and hardware-specific stuff but is primarily about heterogeneous hardware, with a more pragmatically focused forward-looking eye.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2011/04/06/fusion/feed/</wfw:commentRss>
		<slash:comments>7</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>C++ and Beyond 2011</title>
		<link>https://herbsutter.com/2011/04/05/c-and-beyond-2011/</link>
				<comments>https://herbsutter.com/2011/04/05/c-and-beyond-2011/#comments</comments>
				<pubDate>Wed, 06 Apr 2011 00:32:22 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=539</guid>
				<description><![CDATA[I&#8217;m very much looking forward to C++ and Beyond 2011 this August, again with Scott Meyers and Andrei Alexandrescu. All of my own talks will be brand-new material never given publicly before. This year&#8217;s program will be heavily oriented toward performance (first) and C++0x (second). There are two talks announced so far: Andrei will be giving [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><img class="alignright" title="Beautiful Banff" src="https://cppandbeyond.files.wordpress.com/2011/02/banffsprings.jpg?w=240&#038;h=165" alt="" width="240" height="165" />I&#8217;m very much looking forward to <strong><a href="http://cppandbeyond.com">C++ and Beyond 2011</a></strong> this August, again with Scott Meyers and Andrei Alexandrescu. All of my own talks will be brand-new material never given publicly before.</p>
<p>This year&#8217;s program will be heavily oriented toward performance (first) and C++0x (second). There are two talks announced so far:</p>
<ul>
<li>Andrei will be giving an in-depth talk on <strong><em><a href="http://cppandbeyond.com/2011/03/31/session-announcement-big/">&#8220;BIG: C++ Strategies, Data Structures, and Algorithms Aimed at Scalability.&#8221;</a></em></strong> Briefly, it&#8217;s about writing high-performance C++ code for  highly distributed architectures, focusing on translating C++&#8217;s strong modeling capabilities directly to great scaling and/or great savings, and finding the right but non-intuitive C++ techniques and data structures to get there.</li>
<li>I&#8217;ll be giving a brand-new talk on <strong><em><a href="http://cppandbeyond.com/2011/04/02/session-announcement-c-and-the-gpu-and-beyond/">&#8220;C++ and the GPU&#8230; and Beyond.&#8221;</a></em></strong> I&#8217;ll cover the state of the art for using C++ (not just C) for <a href="http://en.wikipedia.org/wiki/GPGPU">general-purpose computation on graphics processing units (GPGPU)</a>. The first half of the talk discusses the most important issues and techniques to consider when using GPUs for high-performance computation, especially where we have to change our traditional advice for doing the same computation on the CPU. The second half focuses on upcoming C++ language and library extensions that bring key abstractions for GPGPU — and in time considerably more — directly into C++.</li>
</ul>
<p>An announcement for a third (also performance-focused) talk should be posted within the week, with more to come as we continue to announce the talk schedule as it firms up.</p>
<p><a href="http://cppandbeyond2011.eventbrite.com/">Registration is now open.</a> I hope many of you will be able to make it.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2011/04/05/c-and-beyond-2011/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>

		<media:content url="http://cppandbeyond.files.wordpress.com/2011/02/banffsprings.jpg" medium="image">
			<media:title type="html">Beautiful Banff</media:title>
		</media:content>
	</item>
		<item>
		<title>Book on PPL is now available</title>
		<link>https://herbsutter.com/2011/03/24/book-on-ppl-is-now-available/</link>
				<comments>https://herbsutter.com/2011/03/24/book-on-ppl-is-now-available/#comments</comments>
				<pubDate>Thu, 24 Mar 2011 22:12:53 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Microsoft]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=524</guid>
				<description><![CDATA[For those of you who may be interested in concurrency and parallelism using Microsoft tools, there&#8217;s a new book now available on the Visual C++ 2010 Parallel Patterns Library (PPL). I hope you enjoy it. Normally I don&#8217;t write about other people&#8217;s platform-specific books, but I happened to be involved in the design of PPL, [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>For those of you who may be interested in concurrency and parallelism using Microsoft tools, there&#8217;s a <a href="http://blogs.msdn.com/b/vcblog/archive/2011/03/15/10139453.aspx">new book</a> now available on the Visual C++ 2010 Parallel Patterns Library (PPL). I hope you enjoy it.</p>
<p>Normally I don&#8217;t write about other people&#8217;s platform-specific books, but I happened to be involved in the design of PPL, thought the book was nicely done, and contributed a <a href="http://msdn.microsoft.com/en-us/library/gg663537.aspx">Foreword</a>. Here&#8217;s what I wrote to introduce the book:</p>
<blockquote><p>This timely book comes as we navigate a major turning point in our industry: parallel hardware + mobile devices = the pocket supercomputer as the mainstream platform for the next 20 years.</p>
<p>Parallel applications are increasingly needed to exploit all kinds of target hardware. As I write this, getting full computational performance out of most machines—nearly all desktops and laptops, most game consoles, and the newest smartphones—already means harnessing local parallel hardware, mainly in the form of multicore CPU processing; this is the commoditization of the supercomputer. Increasingly in the coming years, getting that full performance will also mean using gradually ever-more-heterogeneous processing, from local general-purpose computation on graphics processing units (GPGPU) flavors to harnessing &#8220;often-on&#8221; remote parallel computing power in the form of elastic compute clouds; this is the generalization of the heterogeneous cluster in all its NUMA glory, with instantiations ranging from on-die to on-machine to on-cloud, with early examples of each kind already available in the wild.</p>
<p>Starting now and for the foreseeable future, for compute-bound applications, &#8220;fast&#8221; will be synonymous not just with &#8220;parallel,&#8221; but with &#8220;<em>scalably</em> parallel.&#8221; Only scalably parallel applications that can be shipped with lots of latent concurrency beyond what can be exploited in this year’s mainstream machines will be able to enjoy the new Free Lunch of getting substantially faster when today’s binaries can be installed and blossom on tomorrow’s hardware that will have more parallelism.</p>
<p>Visual C++ 2010 with its Parallel Patterns Library (PPL), described in this book, helps enable applications to take the first steps down this new path as it continues to unfold. During the design of PPL, many people did a lot of heavy lifting. For my part, I was glad to be able to contribute the heavy emphasis on lambda functions as the key central language extension that enabled the rest of PPL to be built as Standard Template Library (STL)-like algorithms implemented as a normal library. We could instead have built a half-dozen new kinds of special-purpose parallel loops into the language itself (and almost did), but that would have been terribly invasive and non-general. Adding a single general-purpose language feature like lambdas that can be used everywhere, including with PPL but not limited to only that, is vastly superior to baking special cases into the language.</p>
<p>The good news is that, in large parts of the world, we have as an industry already achieved pervasive computing: the vision of putting a computer on every desk, in every living room, and in everyone’s pocket. But now we are in the process of delivering pervasive and even elastic supercomputing: putting a supercomputer on every desk, in every living room, and in everyone’s pocket, with both local and non-local resources. In 1984, when I was just finishing high school, the world’s fastest computer was a Cray X-MP with four processors, 128MB of RAM, and peak performance of 942MFLOPS—or, put another way, a fraction of the parallelism, memory, and computational power of a 2005 vintage Xbox, never mind modern &#8220;phones&#8221; and Kinect. We’ve come a long way, and the pace of change is not only still strong, but still accelerating.</p>
<p>The industry turn to parallelism that has begun with multicore CPUs (for the reasons I outlined a few years ago in my essay &#8220;The Free Lunch Is Over&#8221;) will continue to be accelerated by GPGPU computing, elastic cloud computing, and other new and fundamentally parallel trends that deliver vast amounts of new computational power in forms that will become increasingly available to us through our mainstream programming languages. At Microsoft, we’re very happy to be able to be part of delivering this and future generations of tools for mainstream parallel computing across the industry. With PPL in particular, I’m very pleased to see how well the final product has turned out and look forward to seeing its capabilities continue to grow as we re-enable the new Free Lunch applications—scalable parallel applications ready for our next 20 years.</p>
<p>Herb Sutter<br />
Principal Architect, Microsoft<br />
Bellevue, WA, USA</p>
<p>February 2011</p>
<p>&nbsp;</p></blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2011/03/24/book-on-ppl-is-now-available/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Interview on Channel 9</title>
		<link>https://herbsutter.com/2011/01/14/interview-on-channel-9/</link>
				<comments>https://herbsutter.com/2011/01/14/interview-on-channel-9/#comments</comments>
				<pubDate>Sat, 15 Jan 2011 04:08:24 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C# / .NET]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Java]]></category>

		<guid isPermaLink="false">http://herbsutter.com/?p=516</guid>
				<description><![CDATA[Over the holidays, Erik Meijer interviewed me on Channel 9. We covered a wide variety of topics, mostly centered on C++ with some straying into C#/Java/Haskell/Clojure/Erlang, but ranging from auto and closures to why (not?) derive future&#60;T&#62; from T, and from what the two most important problems in parallelism are in 2011 to why and how [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Over the holidays, Erik Meijer <a href="http://channel9.msdn.com/Shows/Going+Deep/E2E-Herb-Sutter-and-Erik-Meijer-Perspectives-on-C">interviewed me on Channel 9</a>. We covered a wide variety of topics, mostly centered on C++ with some straying into C#/Java/Haskell/Clojure/Erlang, but ranging from auto and closures to why (not?) derive future&lt;T&gt; from T, and from what the two most important problems in parallelism are in 2011 to why and how to taste new programming languages regularly. I think it turned out well. Enjoy!</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2011/01/14/interview-on-channel-9/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Know When to Use an Active Object Instead of a Mutex</title>
		<link>https://herbsutter.com/2010/09/24/effective-concurrency-know-when-to-use-an-active-object-instead-of-a-mutex/</link>
				<comments>https://herbsutter.com/2010/09/24/effective-concurrency-know-when-to-use-an-active-object-instead-of-a-mutex/#comments</comments>
				<pubDate>Fri, 24 Sep 2010 18:50:39 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/09/24/effective-concurrency-know-when-to-use-an-active-object-instead-of-a-mutex/</guid>
				<description><![CDATA[This month&#8217;s Effective Concurrency column, &#8220;Know When to Use an Active Object Instead of a Mutex,&#8221; is now live on DDJ&#8217;s website. From the article: Let&#8217;s say that your program has a shared log file object. The log file is likely to be a popular object; lots of different threads must be able to write [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month&#8217;s <em>Effective Concurrency</em> column, <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=227500074">&#8220;Know When to Use an Active Object Instead of a Mutex,&#8221;</a> is now live on DDJ&#8217;s website.
</p>
<p>From the article:
</p>
<blockquote>
<p>Let&#8217;s say that your program has a shared log file object. The log file is likely to be a popular object; lots of different threads must be able to write to the file; and to avoid corruption, we need to ensure that only one thread may be writing to the file at any given time.</p>
<p>Quick: How would you serialize access to the log file?</p>
<p>Before reading on, please think about the question and pencil in some pseudocode to vet your design. More importantly, especially if you think this is an easy question with an easy answer, try to think of at least two completely different ways to satisfy the problem requirements, and jot down a bullet list of the advantages and disadvantages they trade off.</p>
<p>Ready? Then let&#8217;s begin.
</p>
</blockquote>
<p><span style="color:#333333;">I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:<br />
</span></p>
<p><span style="color:#7f7f7f;">1 <a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">2 <a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">3 <a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">4 <a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">5 <a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">6 <a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">7 <a href="http://www.ddj.com/cpp/205900309">Break Amdahl&#8217;s Law!</a> (Feb 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">8 <a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">9 <a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">10 <a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">11 <a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">12 <a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">13 <a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">14 <a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">15 <a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">16 <a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">17 <a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">18 <a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a>(Jan 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">19 <a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">20 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">21 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">22 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use Thread Pools Correctly: Keep Tasks Short and Nonblocking</a>(Apr 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">23 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate False Sharing</a> (May 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">24 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">25 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The Power of &#8220;In Progress&#8221;</a> (Jul 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">26 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=219200099">Design for Manycore Systems</a> (Aug 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">27 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=220600388">Avoid Exposing Concurrency – Hide It Inside Synchronous Methods</a> (Oct 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">28 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=221601309">Prefer structured lifetimes – local, nested, bounded, deterministic</a>(Nov 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">29 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=222301165">Prefer Futures to Baked-In &#8220;Async APIs&#8221;</a> (Jan 2010)<br />
</span></p>
<p><span style="color:#7f7f7f;">30 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=224701827">Associate Mutexes with Data to Prevent Races</a> (May 2010)<br />
</span></p>
<p><span style="color:#7f7f7f;">31 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml;jsessionid=JM3XD1KM22SCRQE1GHPSKH4ATMY32JVN?articleID=225700095">Prefer Using Active Objects Instead of Naked Threads</a> (June 2010)<br />
</span></p>
<p><span style="color:#7f7f7f;">32 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=226700179">Prefer Using Futures or Callbacks to Communicate Asynchronous Results</a> (August 2010)<br />
</span></p>
<p><span style="color:#7f7f7f;">33 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=227500074">Know When to Use an Active Object Instead of a Mutex</a> (September 2010)<br />
</span></p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/09/24/effective-concurrency-know-when-to-use-an-active-object-instead-of-a-mutex/feed/</wfw:commentRss>
		<slash:comments>10</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Prefer Using Futures or Callbacks to Communicate Asynchronous Results</title>
		<link>https://herbsutter.com/2010/08/27/effective-concurrency-prefer-using-futures-or-callbacks-to-communicate-asynchronous-results/</link>
				<comments>https://herbsutter.com/2010/08/27/effective-concurrency-prefer-using-futures-or-callbacks-to-communicate-asynchronous-results/#comments</comments>
				<pubDate>Fri, 27 Aug 2010 16:47:10 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/08/27/effective-concurrency-prefer-using-futures-or-callbacks-to-communicate-asynchronous-results/</guid>
				<description><![CDATA[This month&#8217;s Effective Concurrency column, &#8220;Prefer Using Futures or Callbacks to Communicate Asynchronous Results,&#8221; is now live on DDJ&#8217;s website. From the article: This time, we&#8217;ll answer the following questions: How should we express return values and out parameters from an asynchronous function, including an active object method? How should we give back multiple partial [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month&#8217;s <em>Effective Concurrency</em> column, <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=226700179">&#8220;Prefer Using Futures or Callbacks to Communicate Asynchronous Results,&#8221;</a> is now live on DDJ&#8217;s website.
</p>
<p>From the article:
</p>
<blockquote>
<p>This time, we&#8217;ll answer the following questions: How should we express return values and out parameters from an asynchronous function, including an active object method? How should we give back multiple partial results, such as partial computations or even just &#8220;percent done&#8221; progress information? Which mechanisms are suited to callers that want to &#8220;pull&#8221; results, as opposed to having the callee &#8220;push&#8221; the results back proactively? And how can &#8220;pull&#8221; be converted to &#8220;push&#8221; when we need it? Let&#8217;s dig in…
</p>
</blockquote>
<p><span style="color:#333333;">I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:<br />
</span></p>
<p><span style="color:#7f7f7f;">1 <a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">2 <a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">3 <a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">4 <a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">5 <a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007)<br />
</span></p>
<p><span style="color:#7f7f7f;">6 <a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">7 <a href="http://www.ddj.com/cpp/205900309">Break Amdahl&#8217;s Law!</a> (Feb 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">8 <a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">9 <a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">10 <a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">11 <a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">12 <a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">13 <a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">14 <a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">15 <a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">16 <a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">17 <a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)<br />
</span></p>
<p><span style="color:#7f7f7f;">18 <a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a>(Jan 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">19 <a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">20 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">21 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">22 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use Thread Pools Correctly: Keep Tasks Short and Nonblocking</a>(Apr 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">23 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate False Sharing</a> (May 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">24 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">25 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The Power of &#8220;In Progress&#8221;</a> (Jul 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">26 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=219200099">Design for Manycore Systems</a> (Aug 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">27 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=220600388">Avoid Exposing Concurrency – Hide It Inside Synchronous Methods</a> (Oct 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">28 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=221601309">Prefer structured lifetimes – local, nested, bounded, deterministic</a>(Nov 2009)<br />
</span></p>
<p><span style="color:#7f7f7f;">29 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=222301165">Prefer Futures to Baked-In &#8220;Async APIs&#8221;</a> (Jan 2010)<br />
</span></p>
<p><span style="color:#7f7f7f;">30 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=224701827">Associate Mutexes with Data to Prevent Races</a> (May 2010)<br />
</span></p>
<p><span style="color:#7f7f7f;">31 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml;jsessionid=JM3XD1KM22SCRQE1GHPSKH4ATMY32JVN?articleID=225700095">Prefer Using Active Objects Instead of Naked Threads</a> (June 2010)<br />
</span></p>
<p><span style="color:#7f7f7f;">32 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=226700179">Prefer Using Futures or Callbacks to Communicate Asynchronous Results</a> (August 2010)<br />
</span></p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/08/27/effective-concurrency-prefer-using-futures-or-callbacks-to-communicate-asynchronous-results/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Prefer Using Active Objects Instead of Naked Threads</title>
		<link>https://herbsutter.com/2010/07/12/effective-concurrency-prefer-using-active-objects-instead-of-naked-threads/</link>
				<comments>https://herbsutter.com/2010/07/12/effective-concurrency-prefer-using-active-objects-instead-of-naked-threads/#comments</comments>
				<pubDate>Mon, 12 Jul 2010 20:22:50 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C# / .NET]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/07/12/effective-concurrency-prefer-using-active-objects-instead-of-naked-threads/</guid>
				<description><![CDATA[This month’s Effective Concurrency column, “Prefer Using Active Objects Instead of Naked Threads,” is now live on DDJ’s website. From the article: … Active objects dramatically improve our ability to reason about our thread&#8217;s code and operation by giving us higher-level abstractions and idioms that raise the semantic level of our program and let us [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, “<a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml;jsessionid=JM3XD1KM22SCRQE1GHPSKH4ATMY32JVN?articleID=225700095">Prefer Using Active Objects Instead of Naked Threads</a>,” is now live on DDJ’s website.</p>
<p>From the article:</p>
<blockquote>
<p>… Active objects dramatically improve our ability to reason about our thread&#8217;s code and operation by giving us higher-level abstractions and idioms that raise the semantic level of our program and let us express our intent more directly. As with all good patterns, we also get better vocabulary to talk about our design. Note that active objects aren&#8217;t a novelty: UML and various libraries have provided support for active classes. Some actor-based languages already have variations of this pattern baked into the language itself; but fortunately, we aren&#8217;t limited to using only such languages to get the benefits of active objects. </p>
<p>This article will show how to implement the pattern, including a reusable helper to automate the common parts, in any of the popular mainstream languages and threading environments, including C++, C#/.NET, Java, and C/Pthreads.</p>
</p>
</blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:</p>
<blockquote>
<p>1 <a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007) </p>
<p>2 <a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007) </p>
<p>3 <a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007) </p>
<p>4 <a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007) </p>
<p>5 <a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007) </p>
<p>6 <a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008) </p>
<p>7 <a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008) </p>
<p>8 <a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008) </p>
<p>9 <a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008) </p>
<p>10 <a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008) </p>
<p>11 <a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008) </p>
<p>12 <a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008) </p>
<p>13 <a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008) </p>
<p>14 <a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008) </p>
<p>15 <a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008) </p>
<p>16 <a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008) </p>
<p>17 <a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)</p>
<p>18 <a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p>19 <a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)</p>
<p>20 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)</p>
<p>21 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p>22 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use Thread Pools Correctly: Keep Tasks Short and Nonblocking</a> (Apr 2009)</p>
<p>23 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate False Sharing</a> (May 2009)</p>
<p>24 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)</p>
<p>25 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The Power of “In Progress”</a> (Jul 2009)</p>
<p>26 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=219200099">Design for Manycore Systems</a> (Aug 2009)</p>
<p>27 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=220600388">Avoid Exposing Concurrency – Hide It Inside Synchronous Methods</a> (Oct 2009)</p>
<p>28 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=221601309">Prefer structured lifetimes – local, nested, bounded, deterministic</a> (Nov 2009)</p>
<p>29 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=222301165">Prefer Futures to Baked-In “Async APIs”</a> (Jan 2010)</p>
<p>30 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=224701827">Associate Mutexes with Data to Prevent Races</a> (May 2010)</p>
<p>31 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml;jsessionid=JM3XD1KM22SCRQE1GHPSKH4ATMY32JVN?articleID=225700095">Prefer Using Active Objects Instead of Naked Threads</a> (June 2010)</p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/07/12/effective-concurrency-prefer-using-active-objects-instead-of-naked-threads/feed/</wfw:commentRss>
		<slash:comments>8</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency Course: June and (Not) October</title>
		<link>https://herbsutter.com/2010/06/10/effective-concurrency-course-june-and-october/</link>
				<comments>https://herbsutter.com/2010/06/10/effective-concurrency-course-june-and-october/#comments</comments>
				<pubDate>Thu, 10 Jun 2010 12:48:53 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/06/10/effective-concurrency-course-june-and-october/</guid>
				<description><![CDATA[I forgot to blog about this until now because of focusing on the Effective Concurrency course in Stockholm a few weeks ago, but to answer those who wonder if I’ll be giving it again in North America too: Yes, I’m also giving the public Effective Concurrency course again at the end of this month at [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>I forgot to blog about this until now because of focusing on the Effective Concurrency course in Stockholm a few weeks ago, but to answer those who wonder if I’ll be giving it again in North America too: Yes, I’m also giving the public <a href="http://www.construx.com/Page.aspx?nid=17&amp;id=108"><strong>Effective Concurrency course</strong></a> again at the end of this month at the Construx facility in Bellevue, WA, USA. This will be the full four-day version of the course. Spaces are still available.</p>
<p>I’ll cover the following topics:</p>
<ul>
<li><strong>Fundamentals: </strong>Define basic concurrency goals and requirements • Understand applications’ scalability needs • Key concurrency patterns</li>
<li><strong>Isolation — Keep work separate: </strong>Running tasks in isolation and communicate via async messages • Integrating multiple messaging systems, including GUIs and sockets • Building responsive applications using background workers • Threads vs. thread pools</li>
<li><strong>Scalability — Re-enable the Free Lunch:</strong> When and how to use more cores • Exploiting parallelism in algorithms • Exploiting parallelism in data structures • Breaking the scalability barrier</li>
<li><strong>Consistency — Don’t Corrupt Shared State:</strong> The many pitfalls of locks–deadlock, convoys, etc. • Locking best practices • Reducing the need for locking shared data • Safe lock-free coding patterns • Avoiding the pitfalls of general lock-free coding • Races and race-related effects</li>
<li><strong>High Performance Concurrency:</strong> Machine architecture and concurrency • Costs of fundamental operations, including locks, context switches, and system calls • Memory and cache effects • Data structures that support and undermine concurrency • Enabling linear and superlinear scaling</li>
<li><strong>Migrating Existing Code Bases to Use Concurrency </strong></li>
<li><strong>Near-Future Tools and Features </strong></li>
</ul>
<p>I hope to see some of you there!</p>
<p><strong>Update 8/19:</strong> I had planned to do the EC course again in October (hence the post title) but that now has to be deferred to sometime in the new year. Sorry for any inconvenience to those of you who had already registered, or were planning to. I&#8217;ll blog about it here when it&#8217;s rescheduled.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/06/10/effective-concurrency-course-june-and-october/feed/</wfw:commentRss>
		<slash:comments>8</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Webinar Now Available On Demand</title>
		<link>https://herbsutter.com/2010/06/03/webinar-now-available-on-demand/</link>
				<comments>https://herbsutter.com/2010/06/03/webinar-now-available-on-demand/#comments</comments>
				<pubDate>Thu, 03 Jun 2010 20:56:16 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/06/03/webinar-now-available-on-demand/</guid>
				<description><![CDATA[The webinar I did with James Reinders three weeks ago is now online for on-demand viewing. The link is the same as before: Five Years Since Free Lunches: Making Use of Multicore Parallelism Reflecting on the five years since &#34;The Free Lunch is Over&#34; article and the arrival of multicore processors, Sutter and Reinders will [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>The <a href="https://herbsutter.com/2010/05/06/may-12-webinar-on-multicore-parallelism/">webinar</a> I did with James Reinders three weeks ago is now online for on-demand viewing. The link is the same as before:</p>
<blockquote>
<p><strong><a href="https://event.on24.com/event/36/88/3/rt/1/index.html?&amp;eventid=36883&amp;sessionid=1&amp;key=D76A2FD29D7444AEC06765011A2D4953&amp;tab=1&amp;sourcepage=register">Five Years Since Free Lunches: Making Use of Multicore Parallelism</a></strong></p>
<p>Reflecting on the five years since &quot;The Free Lunch is Over&quot; article and the arrival of multicore processors, Sutter and Reinders will talk about the keys to making effective use of multicore parallelism. Programmers are in the midst of an evolution that takes time, and we are still in the early days. Sutter and Reinders share expert advice on how to view this transition, and the keys to getting it right—including a three-pillar model for concurrency, the need to maximize the number of tasks expressed in a program, and how abstractions encourage &quot;many task&quot; programming, while allowing overheads to be driven down under-the-covers.</p>
</blockquote>
<p>Intel wants you to register (which is free), then you can watch the video and listen to the live (and sometimes quite lively) Q&amp;A we held at the end. I hope you enjoy it!</p>
<p>Note: When we did it live, the audio was missing for part of the presentation. I’m told the glitch has been fixed, and the complete video, soundtrack and all, is available in the on-demand version.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/06/03/webinar-now-available-on-demand/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Associate Mutexes with Data to Prevent Races</title>
		<link>https://herbsutter.com/2010/05/24/effective-concurrency-associate-mutexes-with-data-to-prevent-races/</link>
				<comments>https://herbsutter.com/2010/05/24/effective-concurrency-associate-mutexes-with-data-to-prevent-races/#comments</comments>
				<pubDate>Mon, 24 May 2010 20:36:57 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/05/24/effective-concurrency-associate-mutexes-with-data-to-prevent-races/</guid>
				<description><![CDATA[This month’s Effective Concurrency column, Associate Mutexes with Data to Prevent Races”, is now live on DDJ’s website. From the article: Come together: Associate mutexes with the data they protect, and you can make your code race-free by construction Race conditions are one of the worst plagues of concurrent code: They can cause disastrous effects [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=224701827">Associate Mutexes with Data to Prevent Races”</a>, is now live on DDJ’s website.</p>
<p>From the article:</p>
<blockquote>
<p><em>Come together: Associate mutexes with the data they protect, and you can make your code race-free by construction</em></p>
<p>Race conditions are one of the worst plagues of concurrent code: They can cause disastrous effects all the way up to undefined behavior and random code execution, yet they&#8217;re hard to discover reliably during testing, hard to reproduce when they do occur, and the icing on the cake is that we have immature and inadequate race detection and prevention tool support available today.</p>
<p>The holy grail of the Consistency pillar is to make a concurrent program race-free and deadlock-free by construction. … This article shows how to achieve the &quot;race-free by construction&quot; grail via sound engineering, with automatic and deterministic race identification at test time based on code coverage alone.</p>
</blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:</p>
<blockquote>
<p>1 <a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007) </p>
<p>2 <a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007) </p>
<p>3 <a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007) </p>
<p>4 <a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007) </p>
<p>5 <a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007) </p>
<p>6 <a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008) </p>
<p>7 <a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008) </p>
<p>8 <a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008) </p>
<p>9 <a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008) </p>
<p>10 <a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008) </p>
<p>11 <a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008) </p>
<p>12 <a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008) </p>
<p>13 <a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008) </p>
<p>14 <a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008) </p>
<p>15 <a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008) </p>
<p>16 <a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008) </p>
<p>17 <a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)</p>
<p>18 <a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p>19 <a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)</p>
<p>20 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)</p>
<p>21 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p>22 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use Thread Pools Correctly: Keep Tasks Short and Nonblocking</a> (Apr 2009)</p>
<p>23 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate False Sharing</a> (May 2009)</p>
<p>24 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)</p>
<p>25 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The Power of “In Progress”</a> (Jul 2009)</p>
<p>26 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=219200099">Design for Manycore Systems</a> (Aug 2009)</p>
<p>27 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=220600388">Avoid Exposing Concurrency – Hide It Inside Synchronous Methods</a> (Oct 2009)</p>
<p>28 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=221601309">Prefer structured lifetimes – local, nested, bounded, deterministic</a> (Nov 2009)</p>
<p>29 <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=222301165">Prefer Futures to Baked-In “Async APIs”</a> (Jan 2010)</p>
<p>30 <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=224701827">Associate Mutexes with Data to Prevent Races</a> (May 2010)</p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/05/24/effective-concurrency-associate-mutexes-with-data-to-prevent-races/feed/</wfw:commentRss>
		<slash:comments>10</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>May 12 Webinar on Multicore Parallelism</title>
		<link>https://herbsutter.com/2010/05/06/may-12-webinar-on-multicore-parallelism/</link>
				<comments>https://herbsutter.com/2010/05/06/may-12-webinar-on-multicore-parallelism/#comments</comments>
				<pubDate>Fri, 07 May 2010 06:32:37 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/05/06/may-12-webinar-on-multicore-parallelism/</guid>
				<description><![CDATA[Next week, I’m giving a webinar with Intel’s James Reinders, and we’ll be available for a live Q&#38;A session with you at the end: Five Years Since Free Lunches: Making Use of Multicore Parallelism May 12, 2010 at 8 a.m. PT/11 a.m. ET. Reflecting on the five years since &#34;The Free Lunch is Over&#34; article [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Next week, I’m giving a webinar with Intel’s James Reinders, and we’ll be available for a live Q&amp;A session with you at the end:</p>
<blockquote>
<p align="left"><strong><a href="https://event.on24.com/event/36/88/3/rt/1/index.html?&amp;eventid=36883&amp;sessionid=1&amp;key=D76A2FD29D7444AEC06765011A2D4953&amp;tab=1&amp;sourcepage=register">Five Years Since Free Lunches: Making Use of Multicore Parallelism</a></strong></p>
<p align="left"><strong>May 12, 2010 at 8 a.m. PT/11 a.m. ET.</strong></p>
<p align="left">Reflecting on the five years since &quot;The Free Lunch is Over&quot; article and the arrival of multicore processors, Sutter and Reinders will talk about the keys to making effective use of multicore parallelism. Programmers are in the midst of an evolution that takes time, and we are still in the early days. Sutter and Reinders share expert advice on how to view this transition, and the keys to getting it right—including a three-pillar model for concurrency, the need to maximize the number of tasks expressed in a program, and how abstractions encourage &quot;many task&quot; programming, while allowing overheads to be driven down under-the-covers.</p>
</blockquote>
<p>James and I had a lot of fun recording the video portion about a month ago, and I hope you enjoy it. We touched on everything from the three basic pillars I’ve written about <a href="http://www.drdobbs.com/high-performance-computing/200001985">before</a> but that bear repeating, to whether functional languages will take the world by storm (perhaps surprisingly, yes… but why and how?), to the perennial question of “how finely should I decompose my work to run it well in parallel” (and I really must write an EC article about this).</p>
<p>Afterwards, James and I will be on the phone to take your questions. If you have a particular point you want to ask about, why not take the time now to prepare a well-crafted and concise question in advance? I’m looking forward to hearing from many of you.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/05/06/may-12-webinar-on-multicore-parallelism/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Links I enjoyed reading this week</title>
		<link>https://herbsutter.com/2010/03/13/links-i-enjoyed-reading-this-week/</link>
				<comments>https://herbsutter.com/2010/03/13/links-i-enjoyed-reading-this-week/#comments</comments>
				<pubDate>Sat, 13 Mar 2010 15:50:34 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/03/13/links-i-enjoyed-reading-this-week/</guid>
				<description><![CDATA[Concurrency-related (more or less directly) Samples updated for ConcRT, PPL and Agents (Microsoft Parallel Programming blog) Update to the samples for the Visual Studio 2010 Release Candidate. Hmm, I suppose I should include a link to that too: Visual Studio 2010 and .NET Framework 4 Release Candidate (Microsoft) Freely downloadable, includes C++0x features like auto [&#8230;]]]></description>
								<content:encoded><![CDATA[<h3>Concurrency-related (more or less directly)</h3>
<p><a href="http://blogs.msdn.com/nativeconcurrency/archive/2010/03/10/samples-updated-for-concrt-ppl-and-agents.aspx"><strong>Samples updated for ConcRT, PPL and Agents</strong></a><strong> (Microsoft Parallel Programming blog)</strong>     <br />Update to the samples for the Visual Studio 2010 Release Candidate. Hmm, I suppose I should include a link to that too:</p>
<ul>
<li><strong><a href="http://msdn.microsoft.com/en-us/vstudio/dd582936.aspx">Visual Studio 2010 and .NET Framework 4 Release Candidate</a> (Microsoft)</strong>       <br />Freely downloadable, includes C++0x features like auto and lambdas and rvalue references (move semantics), nifty parallel programming libraries, and more. </li>
</ul>
<p><a href="http://techreport.com/articles.x/18581"><strong>Intel&#8217;s Core i7-980X Extreme processor</strong></a><strong> (The Tech Report)      <br /></strong>Desktop part with 12 hardware threads (6 cores x 2 threads/core), 32nm process, &gt;1.1B transistors.</p>
<h3>General information/amusement</h3>
<h3></h3>
<h3></h3>
<p><a href="http://blogs.msdn.com/oldnewthing/archive/2010/03/11/9976571.aspx"><strong>Application compatibility layers are there for the customer, not for the program</strong></a><strong> (Raymond Chen)      <br /></strong>You wouldn’t believe the backward-compatibility hoops we all need to <strike><em>jump through</em></strike> hold in the right place for older apps to jump through, and then the app developer asks for more…</p>
<p><strong><a href="http://www.gizmag.com/first-commercially-available-jetpack/14423/">Jetpack to be commercially available soon?</a> (Gizmag)       <br /></strong>Yes, we see a story like this every few years. This one actually gets the flight time beyond just one minute. Now if we could only take the expected price down by one order of magnitude, and safety up by an order of magnitude or three…</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/03/13/links-i-enjoyed-reading-this-week/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency Europe 2010</title>
		<link>https://herbsutter.com/2010/03/01/effective-concurrency-europe-2010/</link>
				<comments>https://herbsutter.com/2010/03/01/effective-concurrency-europe-2010/#comments</comments>
				<pubDate>Tue, 02 Mar 2010 03:04:35 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/03/01/effective-concurrency-europe-2010/</guid>
				<description><![CDATA[Last May, I gave a public Effective Concurrency course in Stockholm. It was well-attended, and a number of people have asked if it will be offered again. The answer is yes. I’m happy to report that Effective Concurrency Europe 2010 will be held on May 5-7, 2010, in Stockholm, Sweden. There’s an early-bird rate available [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Last May, I gave a public Effective Concurrency course in Stockholm. It was well-attended, and a number of people have asked if it will be offered again. The answer is yes.</p>
<p>I’m happy to report that <a href="http://www.pc-ware.com/pcw/se/se/services/trainings/kursomraden/programutveckling/files/effective_concurrency.pdf"><strong>Effective Concurrency Europe 2010</strong></a> will be held on May 5-7, 2010, in Stockholm, Sweden. There’s an early-bird rate available for those who register <span style="color:#000000;">before March 15</span>.</p>
<p>I’ll cover the following topics:</p>
<ul>
<li><strong>Fundamentals: </strong>Define basic concurrency goals and requirements • Understand applications’ scalability needs • Key concurrency patterns</li>
<li><strong>Isolation — Keep work separate: </strong>Running tasks in isolation and communicate via async messages • Integrating multiple messaging systems, including GUIs and sockets • Building responsive applications using background workers • Threads vs. thread pools</li>
<li><strong>Scalability — Re-enable the Free Lunch:</strong> When and how to use more cores • Exploiting parallelism in algorithms • Exploiting parallelism in data structures • Breaking the scalability barrier</li>
<li><strong>Consistency — Don’t Corrupt Shared State:</strong> The many pitfalls of locks–deadlock, convoys, etc. • Locking best practices • Reducing the need for locking shared data • Safe lock-free coding patterns • Avoiding the pitfalls of general lock-free coding • Races and race-related effects</li>
<li><strong>High Performance Concurrency:</strong> Machine architecture and concurrency • Costs of fundamental operations, including locks, context switches, and system calls • Memory and cache effects • Data structures that support and undermine concurrency • Enabling linear and superlinear scaling</li>
<li><strong>Migrating Existing Code Bases to Use Concurrency </strong></li>
<li><strong>Near-Future Tools and Features </strong></li>
</ul>
<p>I hope to see some of you there!</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/03/01/effective-concurrency-europe-2010/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Machine Architecture slides back online</title>
		<link>https://herbsutter.com/2010/02/22/machine-architecture-slides-back-online/</link>
				<comments>https://herbsutter.com/2010/02/22/machine-architecture-slides-back-online/#comments</comments>
				<pubDate>Mon, 22 Feb 2010 21:47:01 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/02/22/machine-architecture-slides-back-online/</guid>
				<description><![CDATA[A number of people reported that the PDF slides for my Machine Architecture talk were offline. It turns out that the NWCPP servers were recently moved and the link temporarily broken, but it’s now been restored. Links: Google video PDF slides (back again)]]></description>
								<content:encoded><![CDATA[<p>A number of people reported that the PDF slides for my Machine Architecture talk were offline. It turns out that the NWCPP servers were recently moved and the link temporarily broken, but it’s now been restored.</p>
<p>Links:</p>
<ul>
<li><a href="http://video.google.com/videoplay?docid=-4714369049736584770">Google video</a></li>
<li><a href="http://www.nwcpp.org/Downloads/2007/Machine_Architecture_-_NWCPP.pdf">PDF slides</a> (back again)</li>
</ul>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/02/22/machine-architecture-slides-back-online/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Igor Ostrovsky and the Seven Cache Effects</title>
		<link>https://herbsutter.com/2010/02/15/igor-ostrovsky-and-the-seven-cache-effects/</link>
				<comments>https://herbsutter.com/2010/02/15/igor-ostrovsky-and-the-seven-cache-effects/#comments</comments>
				<pubDate>Mon, 15 Feb 2010 15:44:26 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/02/15/igor-ostrovsky-and-the-seven-cache-effects/</guid>
				<description><![CDATA[My colleague Igor Ostrovsky has written a useful summary of seven cache memory effects that every advanced developer should know about because of their performance impact, particularly as we strive to keep invisible bottlenecks out of parallel code. I’ve covered variations of Igor’s examples #1, #2, #3, and #6 in my Machine Architecture talk and [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>My colleague Igor Ostrovsky has written a useful <a href="http://igoro.com/archive/gallery-of-processor-cache-effects/">summary of seven cache memory effects</a> that every advanced developer should know about because of their performance impact, particularly as we strive to keep invisible bottlenecks out of parallel code.</p>
<p>I’ve covered variations of Igor’s examples #1, #2, #3, and #6 in my <a href="http://video.google.com/videoplay?docid=-4714369049736584770#">Machine Architecture talk</a> and <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=214100002">several</a> <a href="http://www.drdobbs.com/cpp/211800538">of my</a> <a href="http://www.drdobbs.com/go-parallel/article/showArticle.jhtml?articleID=217500206">articles</a>. His article provides a crisp and concise summary of these and three more kinds of cache effects along with simple and clear sample code and intriguing measurements (for example, see the detail in the graph for #5 and its analysis).</p>
<p>Recommended.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/02/15/igor-ostrovsky-and-the-seven-cache-effects/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Prefer Futures to Baked-In &#8220;Async APIs&#8221;</title>
		<link>https://herbsutter.com/2010/01/17/effective-concurrency-prefer-futures-to-baked-in-async-apis/</link>
				<comments>https://herbsutter.com/2010/01/17/effective-concurrency-prefer-futures-to-baked-in-async-apis/#comments</comments>
				<pubDate>Mon, 18 Jan 2010 02:25:00 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C# / .NET]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2010/01/18/effective-concurrency-prefer-futures-to-baked-in-async-apis/</guid>
				<description><![CDATA[This month’s Effective Concurrency column, Prefer Futures to Baked-In “Async APIs”, is now live on DDJ’s website. From the article: When designing concurrent APIs, separate &#34;what&#34; from &#34;how&#34; Let&#8217;s say you have an existing synchronous API function [called DoSomething]… Because DoSomething could take a long time to execute (whether it keeps a CPU core busy [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=222301165">Prefer Futures to Baked-In “Async APIs”</a>, is now live on DDJ’s website.</p>
<p>From the article:</p>
<blockquote>
<p><em>When designing concurrent APIs, separate &quot;what&quot; from &quot;how&quot;</em></p>
<p>Let&#8217;s say you have an existing synchronous API function [called <strong>DoSomething</strong>]… Because <strong>DoSomething </strong>could take a long time to execute (whether it keeps a CPU core busy or not), and might be independent of other work the caller is doing, naturally the caller might want to execute <strong>DoSomething </strong>asynchronously. … </p>
<p>The question is, how should we enable that? There is a simple and correct answer, but because many interfaces have opted for a more complex answer let&#8217;s consider that one first. </p>
</blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:</p>
<blockquote>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007) </p>
<p><a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007) </p>
<p><a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008) </p>
<p><a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008) </p>
<p><a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008) </p>
<p><a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008) </p>
<p><a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008) </p>
<p><a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008) </p>
<p><a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use Thread Pools Correctly: Keep Tasks Short and Nonblocking</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate False Sharing</a> (May 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The Power of “In Progress”</a> (Jul 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=219200099">Design for Manycore Systems</a> (Aug 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=220600388">Avoid Exposing Concurrency – Hide It Inside Synchronous Methods</a> (Oct 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=221601309">Prefer structured lifetimes – local, nested, bounded, deterministic</a> (Nov 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=222301165">Prefer Futures to Baked-In “Async APIs”</a> (Jan 2010)</p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/01/17/effective-concurrency-prefer-futures-to-baked-in-async-apis/feed/</wfw:commentRss>
		<slash:comments>11</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>C++ and Beyond:  Summer 2010, Vote the Date</title>
		<link>https://herbsutter.com/2010/01/11/c-and-beyond-summer-2010-vote-the-date/</link>
				<comments>https://herbsutter.com/2010/01/11/c-and-beyond-summer-2010-vote-the-date/#comments</comments>
				<pubDate>Mon, 11 Jan 2010 11:14:00 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=324</guid>
				<description><![CDATA[I always enjoy teaching together with Scott Meyers and Andrei Alexandrescu, not only because it means I get to work with good friends, but also because I get to listen to them speak. Scott and Andrei always have interesting and useful things to say and say them well. We occasionally speak at the same big [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>I always enjoy teaching together with <a href="http://www.aristeia.com">Scott Meyers</a> and <a href="http://www.erdani.org">Andrei Alexandrescu</a>, not only because it means I get to work with good friends, but also because I get to listen to them speak. Scott and Andrei always have interesting and useful things to say and say them well. We occasionally speak at the same big conferences, but at those we’re often scheduled at the same time and so we don’t get to hear each other’s sessions (and attendees likewise have to choose one competing session or the other for that time slot), and presenting in large rooms to hundreds of people makes it hard to get much quality face time with the individual audience members.</p>
<p>So I’m really looking forward to spending three days together with Scott and Andrei and a limited number of attendees at a new event called <strong><a href="http://cppandbeyond.com/">C++ and Beyond</a></strong>:</p>
<blockquote>
<p>What do C++ programmers think about these days? Perhaps the new features from C++0x that are becoming commonly available and that introduce fundamental changes in how C++ software is designed. Perhaps the increasing importance of developing effective concurrent systems. Perhaps the continuing pressure to create high-performance software. Possibly the impact of new systems programming languages such as D. Most likely, all of the above, and more. </p>
<p>C++ legends Scott Meyers, Herb Sutter, and Andrei Alexandrescu think about these things, too — all the time. Scott and Herb are neck-deep in C++0x, while Andrei is literally writing the book on D (<em>The D Programming Language</em>). Herb and Andrei put the pedal to the metal on applied concurrency and parallelism; Herb is writing the book on that topic (<em>Effective Concurrency</em>). All three focus on the development of high-performance systems, a topic Scott’s writing a book about (<em>Fastware!</em>).</p>
<p>This summer, Scott, Herb, and Andrei will host an intensive three-day technical event focusing on “<strong>C++ and Beyond</strong>” — an examination of issues related to C++ and its application in high-performance (typically highly concurrent) systems, as well as related technologies of likely interest to C++ programmers.</p>
</blockquote>
<p>We know it’ll be in the Seattle area. We know it’ll be this summer. What we don’t know is which of the two candidate dates (in June or August) works best for you, so we thought we’d let you decide: If you’re potentially interested in attending, please <a href="http://cppandbeyond.com/2010/01/07/vote-for-the-date/">vote for your preferred date</a>. At that page you can also let us know what kinds of topics you’d like to see covered.</p>
<p>Once we finalize the details we’ll post them and open registration. You can subscribe to follow announcements via <a href="http://cppandbeyond.com/feed/">this feed</a>.</p>
<p>We hope to see you in the beautiful Pacific Northwest this summer.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2010/01/11/c-and-beyond-summer-2010-vote-the-date/feed/</wfw:commentRss>
		<slash:comments>6</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Prefer structured lifetimes – local, nested, bounded, deterministic.</title>
		<link>https://herbsutter.com/2009/11/11/effective-concurrency-prefer-structured-lifetimes-%e2%80%93-local-nested-bounded-deterministic/</link>
				<comments>https://herbsutter.com/2009/11/11/effective-concurrency-prefer-structured-lifetimes-%e2%80%93-local-nested-bounded-deterministic/#comments</comments>
				<pubDate>Wed, 11 Nov 2009 18:33:15 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Effective Concurrency]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=313</guid>
				<description><![CDATA[This month’s Effective Concurrency column, Prefer structured lifetimes – local, nested, bounded, deterministic, is now live on DDJ’s website. From the article: Where possible, prefer structured lifetimes: ones that are local, nested, bounded, and deterministic. This is true no matter what kind of lifetime we’re considering, including object lifetimes, thread or task lifetimes, lock lifetimes, [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=221601309">Prefer  structured lifetimes – local, nested, bounded, deterministic</a>, is now live on  DDJ’s website.</p>
<p>From the article:</p>
<blockquote><p>Where possible, prefer structured lifetimes: ones that are local, nested,  bounded, and deterministic. This is true no matter what kind of lifetime we’re  considering, including object lifetimes, thread or task lifetimes, lock  lifetimes, or any other kind. …</p></blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective  Concurrency columns:</p>
<blockquote><p><a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The  Pillars of Concurrency</a> (Aug 2007)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How  Much Scalability Do You Have or Need?</a> (Sep 2007)</p>
<p><a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably  Locks) to Eliminate Races</a> (Oct 2007)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply  Critical Sections Consistently</a> (Nov 2007)</p>
<p><a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While  Inside a Critical Section</a> (Dec 2007)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use  Lock Hierarchies to Avoid Deadlock</a> (Jan 2008)</p>
<p><a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going  Superlinear</a> (Mar 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super  Linearity and the Bigger Machine</a> (Apr 2008)</p>
<p><a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May  2008)</p>
<p><a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize  Contention</a> (Jun 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose  Concurrency-Friendly Data Structures</a> (Jul 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The  Many Faces of Deadlock</a> (Aug 2008)</p>
<p><a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of  Security</a> (Sep 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing  Lock-Free Code: A Corrected Queue</a> (Oct 2008)</p>
<p><a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent  Queue</a> (Nov 2008)</p>
<p><a href="http://www.ddj.com/cpp/211800538">Understanding Parallel  Performance</a> (Dec 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring  Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs.  volatile</a> (Feb 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing  Is the Root of All Contention</a> (Mar 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use  Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use  Thread Pools Correctly: Keep Tasks Short and Nonblocking</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate  False Sharing</a> (May 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break  Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The  Power of “In Progress”</a> (Jul 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=219200099">Design  for Manycore Systems</a> (Aug 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=220600388">Avoid  Exposing Concurrency – Hide It Inside Synchronous Methods</a> (Oct 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=221601309">Prefer  structured lifetimes – local, nested, bounded, deterministic</a> (Nov  2009)</p></blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/11/11/effective-concurrency-prefer-structured-lifetimes-%e2%80%93-local-nested-bounded-deterministic/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Other Concurrency Sessions at PDC&#8217;09</title>
		<link>https://herbsutter.com/2009/11/04/other-concurrency-sessions-at-pdc09/</link>
				<pubDate>Wed, 04 Nov 2009 15:08:07 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/11/04/other-concurrency-sessions-at-pdc09/</guid>
				<description><![CDATA[&#160; I mentioned yesterday that I’ll be involved in two sessions at PDC09, including a parallel patterns tutorial. I know many of you are interested in concurrency in general and on Microsoft platforms in particular, so I thought I’d share this more complete list of concurrency-related sessions at PDC, put together by my colleague Stephen [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>&nbsp;</p>
<p>I mentioned yesterday that I’ll be involved in two sessions at <a href="http://microsoftpdc.com/">PDC09</a>, including a parallel patterns tutorial. I know many of you are interested in concurrency in general and on Microsoft platforms in particular, so I thought I’d share this more complete list of concurrency-related sessions at PDC, put together by my colleague Stephen Toub.</p>
<p>Overview:</p>
<ul>
<li><a href="http://microsoftpdc.com/Sessions/P09-17">The State of Parallel Programming</a></li>
<li><a href="http://microsoftpdc.com/Sessions/Patterns-of-Parallel-Programming">Patterns of Parallel Programming: A Tutorial on Fundamental Patterns and Practices for Parallelism</a></li>
</ul>
<p>Native code in Visual Studio 2010:</p>
<ul>
<li><a href="http://microsoftpdc.com/Sessions/SVR30">A Computing Platform That Scales</a></li>
<li><a href="http://microsoftpdc.com/Sessions/SVR10">Lighting up Windows Server 2008 R2 Using the ConcRT on UMS</a></li>
<li><a href="http://microsoftpdc.com/Sessions/FT19">C++ Forever: Interactive Applications in the Age of Manycore</a></li>
</ul>
<p>Managed code in Visual Studio 2010:</p>
<ul>
<li><a href="http://microsoftpdc.com/Sessions/P09-09">Manycore and the Microsoft .NET Framework 4: A Match Made in Microsoft Visual Studio 2010</a></li>
<li><a href="http://microsoftpdc.com/Sessions/FT21">PLINQ: LINQ, but Faster!</a></li>
<li><a href="http://microsoftpdc.com/Sessions/FT20">F# for Parallel and Asynchronous Programming</a></li>
</ul>
<p>HPC Server:</p>
<ul>
<li><a href="http://microsoftpdc.com/Sessions/P09-01">Accelerating Applications Using Windows HPC Server 2008</a></li>
</ul>
<p>Research and Incubation:</p>
<ul>
<li><a href="http://microsoftpdc.com/Sessions/VTL02">Axum: A .NET Language for Safe and Scalable Concurrency</a></li>
<li><a href="http://microsoftpdc.com/Sessions/VTL32">Concurrency Fuzzing &amp; Data Races</a></li>
<li><a href="http://microsoftpdc.com/Sessions/SVR17">Data-Intensive Computing on Windows HPC Server with the DryadLINQ Framework</a></li>
<li><a href="http://microsoftpdc.com/Sessions/VTL04">Rx: Reactive Extensions for .NET</a></li>
<li><a href="http://microsoftpdc.com/Sessions/FT51">Future of Garbage Collection</a></li>
</ul>
]]></content:encoded>
									
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>PDC&#8217;09: Tutorial &#038; Panel</title>
		<link>https://herbsutter.com/2009/11/03/pdc09-tutorial-panel/</link>
				<comments>https://herbsutter.com/2009/11/03/pdc09-tutorial-panel/#comments</comments>
				<pubDate>Wed, 04 Nov 2009 01:13:21 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Talks & Events]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/11/03/pdc09-tutorial-panel/</guid>
				<description><![CDATA[For those of you coming to PDC’09 in Los Angeles a couple of weeks from now, I’ll be there for a few hours on Monday and Wednesday participating in two events: Patterns of Parallel Programming: A Tutorial on Fundamental Patterns and Practices for Parallelism. The full-day tutorial is full of useful information. I’ll be giving [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>For those of you coming to <a href="http://microsoftpdc.com/">PDC’09 in Los Angeles</a> a couple of weeks from now, I’ll be there for a few hours on Monday and Wednesday participating in two events:</p>
<ul>
<li><a href="http://microsoftpdc.com/Sessions/Patterns-of-Parallel-Programming"><strong>Patterns of Parallel Programming: A Tutorial on Fundamental Patterns and Practices for Parallelism.</strong></a> The full-day tutorial is full of useful information. I’ll be giving the first hour or so as an intro/overview; if you’ve seen my high-level concurrency talks you’ll recognize much of it, but it’ll also have a slant toward patterns of course to set up the day. The rest of the tutorial will be presented by my colleagues <a href="http://microsoftpdc.com/Speakers/Richard-Ciapala">Richard Ciapata</a>, <a href="http://microsoftpdc.com/Speakers/Ade-Miller">Ade Miller</a>, and <a href="http://microsoftpdc.com/Speakers/Stephen-Toub">Stephen Toub</a>.</li>
<li><a href="http://microsoftpdc.com/Sessions/FT52"><strong>Panel: Microsoft Perspectives on the Future of Programming.</strong></a> This one’s going to be a blast. You can judge just from the names of my heavyweight fellow panelists: <a href="http://research.microsoft.com/en-us/um/people/blampson/">Butler Lampson</a>, <a href="http://www.microsoft.com/presspass/exec/techfellow/Smith/default.mspx">Burton Smith</a>, <a href="http://www.microsoft.com/presspass/exec/de/Box/default.mspx">Don Box</a>, <a href="http://research.microsoft.com/en-us/um/people/emeijer/">Erik Meijer</a>, and <a href="http://www.microsoft.com/presspass/exec/de/snover/default.mspx">Jeffrey Snover</a>. Anytime you get a chance to watch or attend a talk by any of these, do. If you get a chance to come to this panel when they’re all on one stage, <em>definitely </em>do. As Bill Shatner might put it: “Do. Not Miss!”</li>
</ul>
<p>See you at PDC!</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/11/03/pdc09-tutorial-panel/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>A Concurrency Poll</title>
		<link>https://herbsutter.com/2009/10/21/a-concurrency-poll/</link>
				<comments>https://herbsutter.com/2009/10/21/a-concurrency-poll/#comments</comments>
				<pubDate>Wed, 21 Oct 2009 12:33:00 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/10/21/a-concurrency-poll/</guid>
				<description><![CDATA[I’ve opened up a short concurrency poll to get a sense of what concurrency issues are top-of-mind for programmers, and I’d appreciate it if you could take a few minutes to participate. Some questions are about what you want to learn more about, others about your tools of choice in specific areas, and a few [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>I’ve opened up <a href="http://www.surveygizmo.com/s/193214/apw36">a short concurrency poll</a> to get a sense of what concurrency issues are top-of-mind for programmers, and I’d appreciate it if you could take a few minutes to participate. Some questions are about what you want to learn more about, others about your tools of choice in specific areas, and a few are slightly whimsical. I plan to use the results as input to topics to cover in future Effective Concurrency articles and talks, so by participating you&#8217;ll help influence the direction of future EC topics.</p>
<p>There are about 28 questions, each asking for just a word or a phrase in answer. Here again is the link: <a href="http://www.surveygizmo.com/s/193214/apw36">http://www.surveygizmo.com/s/193214/apw36</a></p>
<p>Thank you in advance for taking a few minutes to participate. If you&#8217;re interested in receiving a summary of the survey results, please leave your email address at the end of the survey and I&#8217;ll send you a copy (your email will not be used for any other purpose).</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/10/21/a-concurrency-poll/feed/</wfw:commentRss>
		<slash:comments>7</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>whois terry.crowley</title>
		<link>https://herbsutter.com/2009/10/14/whois-terry-crowley/</link>
				<pubDate>Wed, 14 Oct 2009 20:25:33 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Opinion & Editorial]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/10/14/whois-terry-crowley/</guid>
				<description><![CDATA[Astute readers may have noticed that Terry Crowley’s name frequently crops up in the Acknowledgments section of my Effective Concurrency columns. Who is Terry? To answer, Mary-Jo Foley profiles him this week.]]></description>
								<content:encoded><![CDATA[<p>Astute readers may have noticed that Terry Crowley’s name frequently crops up in the Acknowledgments section of my Effective Concurrency columns. Who is Terry? To answer, Mary-Jo Foley <a href="http://blogs.zdnet.com/microsoft/?p=4240">profiles him</a> this week.</p>
]]></content:encoded>
									
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Avoid Exposing Concurrency &#8211; Hide It Inside Synchronous Methods</title>
		<link>https://herbsutter.com/2009/10/12/effective-concurrency-avoid-exposing-concurrency-hide-it-inside-synchronous-methods/</link>
				<comments>https://herbsutter.com/2009/10/12/effective-concurrency-avoid-exposing-concurrency-hide-it-inside-synchronous-methods/#comments</comments>
				<pubDate>Mon, 12 Oct 2009 23:59:53 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C# / .NET]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Effective Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/10/12/effective-concurrency-avoid-exposing-concurrency-hide-it-inside-synchronous-methods/</guid>
				<description><![CDATA[This month’s Effective Concurrency column, Avoid Exposing Concurrency – Hide It Inside Synchronous Methods, is now live on DDJ’s website. From the article: You have a mass of existing code and want to add concurrency. Where do you start? Let’s say you need to migrate existing code to take advantage of concurrent execution or scale [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=220600388">Avoid Exposing Concurrency – Hide It Inside Synchronous Methods</a>, is now live on DDJ’s website.</p>
<p>From the article:</p>
<blockquote>
<p><em>You have a mass of existing code and want to add concurrency. Where do you start?</em></p>
<p>Let’s say you need to migrate existing code to take advantage of concurrent execution or scale on parallel hardware. In that case, you’ll probably find yourself in one of these two common situations, which are actually more similar than different:</p>
<ul>
<li>Migrating an application: You’re an application developer, and you want to migrate your existing synchronous application to be able to benefit from concurrency.</li>
<li>Migrating a library or framework: You’re a developer on a team that produces a library or framework used by other teams or external customers, and you want to let the library take advantage of concurrency on behalf of the application without requiring application code rewrites.</li>
</ul>
<p>You have a mountain of opportunities and obstacles before you. Where do you start?</p>
</blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:</p>
<blockquote>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007) </p>
<p><a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007) </p>
<p><a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008) </p>
<p><a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008) </p>
<p><a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008) </p>
<p><a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008) </p>
<p><a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008) </p>
<p><a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008) </p>
<p><a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use Thread Pools Correctly: Keep Tasks Short and Nonblocking</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate False Sharing</a> (May 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The Power of “In Progress”</a> (Jul 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=219200099">Design for Manycore Systems</a> (Aug 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=220600388">Avoid Exposing Concurrency – Hide It Inside Synchronous Methods</a> (Oct 2009)</p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/10/12/effective-concurrency-avoid-exposing-concurrency-hide-it-inside-synchronous-methods/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>&#8220;What&#8217;s the Best Way To Process a Pool of Work?&#8221;</title>
		<link>https://herbsutter.com/2009/09/28/whats-the-best-way-to-process-a-pool-of-work/</link>
				<comments>https://herbsutter.com/2009/09/28/whats-the-best-way-to-process-a-pool-of-work/#comments</comments>
				<pubDate>Mon, 28 Sep 2009 22:34:16 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/09/28/whats-the-best-way-to-process-a-pool-of-work/</guid>
				<description><![CDATA[“What’s the best way to process a pool of work?” is a recurring question. As usual, the answer is “it depends” because the optimal answer often depends on both the characteristics of the work itself and the constraints imposed by run-time system resources. For example, I recently received the following email from reader Sören Meyer-Eppler, [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>“What’s the best way to process a pool of work?” is a recurring question. As usual, the answer is “it depends” because the optimal answer often depends on both the characteristics of the work itself and the constraints imposed by run-time system resources.</p>
<p>For example, I recently received the following email from reader Sören Meyer-Eppler, where the key was to avoid oversubscribing system resources (in this case, memory):</p>
<blockquote>
<p>I have an application that has multiple threads processing work from a todo queue. I have no influence over what gets into the queue and in what order (it is fed externally by the user). A single work item from the queue may take anywhere between a couple of seconds to several hours of runtime and should not be interrupted while processing. Also, a single work item may consume between a couple of megabytes to around 2GBs of memory. The memory consumption is my problem. I&#8217;m running as a 64bit process on a 8GB machine with 8 parallel threads. If each of them hits a worst case work item at the same time I run out of memory. I&#8217;m wondering about the best way to work around this.</p>
<p>1. plan conservatively and run 4 threads only. The worst case shouldn&#8217;t be a problem anymore, but we waste a lot of parallelism, making the average case a lot slower.</p>
<p>2. make each thread check available memory (or rather total allocated memory by all threads) before starting with a new item. Only start when more than 2GB memory are left. Recheck periodically, hoping that other threads will finish their memory hogs and we may start eventually. Still dangerous if the check happens when all threads are just starting out with their allocations.</p>
<p>3. try to predict how much memory items from the queue will need (hard) and plan accordingly. We could reorder the queue (overriding user choice) or simply adjust the number of running worker threads.</p>
<p>4. more ideas?</p>
<p>I&#8217;m currently tending towards number 2 because it seems simple to implement and solve most cases. However, I&#8217;m still wondering what standard ways of handling situations like this exist? The operating system must do something very similar on a process level after all&#8230;</p>
</blockquote>
<p>I replied:</p>
<blockquote>
<p>I don&#8217;t have time to write a detailed answer right now, but also consider two queues (one for big tasks and one for small tasks), or having work items give a rough size estimate (possibly by doing an extra lightweight pass over the data up front).</p>
<p>May I post an extract of your mail on my blog? Then others may comment and provide useful hints.</p>
</blockquote>
<p>He said yes, and so here it is for your consideration.</p>
<p>Note also <a href="http://groups.google.com/group/comp.programming.threads/browse_thread/thread/ea1bc898bbc103e0">this similar question</a> that came up a few days ago on comp.programming threads, but with different constraints &#8212; in that case, it was about avoiding idleness rather than avoiding oversubscription.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/09/28/whats-the-best-way-to-process-a-pool-of-work/feed/</wfw:commentRss>
		<slash:comments>15</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Design for Manycore Systems</title>
		<link>https://herbsutter.com/2009/08/11/effective-concurrency-design-for-manycore-systems/</link>
				<comments>https://herbsutter.com/2009/08/11/effective-concurrency-design-for-manycore-systems/#comments</comments>
				<pubDate>Tue, 11 Aug 2009 17:50:19 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Opinion & Editorial]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/08/11/effective-concurrency-design-for-manycore-systems/</guid>
				<description><![CDATA[This month’s Effective Concurrency column, Design for Manycore Systems, is now live on DDJ’s website. From the article: Why worry about “manycore” today? Dual- and quad-core computers are obviously here to stay for mainstream desktops and notebooks. But do we really need to think about &#34;many-core&#34; systems if we&#8217;re building a typical mainstream application right [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=219200099">Design for Manycore Systems</a>, is now live on DDJ’s website.</p>
<p>From the article:</p>
<blockquote>
<p><em>Why worry about “manycore” today?</em></p>
<p>Dual- and quad-core computers are obviously here to stay for mainstream desktops and notebooks. But do we really need to think about &quot;many-core&quot; systems if we&#8217;re building a typical mainstream application right now? I find that, to many developers, &quot;many-core&quot; systems still feel fairly remote, and not an immediate issue to think about as they&#8217;re working on their current product.</p>
<p>This column is about why it&#8217;s time right now for most of us to think about systems with lots of cores. In short: Software is the (only) gating factor; as that gate falls, hardware parallelism is coming more and sooner than many people yet believe. …</p>
</blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:</p>
<blockquote>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007) </p>
<p><a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007) </p>
<p><a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008) </p>
<p><a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008) </p>
<p><a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008) </p>
<p><a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008) </p>
<p><a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008) </p>
<p><a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008) </p>
<p><a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use Thread Pools Correctly: Keep Tasks Short and Nonblocking</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate False Sharing</a> (May 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The Power of “In Progress”</a> (Jul 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=219200099">Design for Manycore Systems</a> (Aug 2009)</p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/08/11/effective-concurrency-design-for-manycore-systems/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: The Power of &#8220;In Progress&#8221;</title>
		<link>https://herbsutter.com/2009/07/15/effective-concurrency/</link>
				<comments>https://herbsutter.com/2009/07/15/effective-concurrency/#comments</comments>
				<pubDate>Wed, 15 Jul 2009 23:08:59 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/07/15/effective-concurrency/</guid>
				<description><![CDATA[This month’s Effective Concurrency column, The Power of “In Progress”, is now live on DDJ’s website. From the article: Don&#8217;t let a long-running operation take hostages. When some work that takes a long time to complete holds exclusive access to one or more popular shared resources, such as a thread or a mutex that controls [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The Power of “In Progress”</a>, is now live on DDJ’s website.</p>
<p>From the article:</p>
<blockquote>
<p>Don&#8217;t let a long-running operation take hostages. When some work that takes a long time to complete holds exclusive access to one or more popular shared resources, such as a thread or a mutex that controls access to some popular shared data, it can block other work that needs the same resource. Forcing that other work to wait its turn hurts both throughput and responsiveness.</p>
<p>…</p>
<p>Let&#8217;s look at the question from another angle, suggested by my colleague Terry Crowley: Instead of viewing partially-updated state with in-progress work as an &#8216;unfortunate&#8217; special case to remember and recover from, what if we simply embrace it as the normal case? …</p>
</blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:</p>
<blockquote>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007) </p>
<p><a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007) </p>
<p><a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008) </p>
<p><a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008) </p>
<p><a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008) </p>
<p><a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008) </p>
<p><a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008) </p>
<p><a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008) </p>
<p><a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use Thread Pools Correctly: Keep Tasks Short and Nonblocking</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate False Sharing</a> (May 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=218401447">The Power of “In Progress”</a> (Jul 2009)</p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/07/15/effective-concurrency/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Answering email about error handling in concurrent code</title>
		<link>https://herbsutter.com/2009/06/23/answering-email-about-error-handling-in-concurrent-code/</link>
				<comments>https://herbsutter.com/2009/06/23/answering-email-about-error-handling-in-concurrent-code/#comments</comments>
				<pubDate>Wed, 24 Jun 2009 00:27:47 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/06/23/answering-email-about-error-handling-in-concurrent-code/</guid>
				<description><![CDATA[Someone emailed me today asking: I&#8217;m writing because I&#8217;m somewhat conscious of what I would consider a rather large hole in the parallel programming literature. … What if one or more of your tasks throws an exception? Should the thread that runs the task swallow it? Should the caught exceptions get stashed somewhere so that [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Someone emailed me today asking:</p>
<blockquote>
<p>I&#8217;m writing because I&#8217;m somewhat conscious of what I would consider a rather large hole in the parallel programming literature.</p>
<p>… What if one or more of your tasks throws an exception? Should the thread that runs the task swallow it? Should the caught exceptions get stashed somewhere so that the &quot;parent&quot; thread can deal with them once the tasks are complete? (This is somewhat tricky currently in a language such as C++(98) where one cannot store an exception caught with the &quot;catch(&#8230;)&quot; construct). Perhaps all tasks should have a no-throw guarantee? Perhaps some kind of asynchronous error handlers might be installed, somewhat like POSIX signals? The options are many, but choosing a strategy is hard for those of us with little parallel programming experience.</p>
</blockquote>
<p>I thought I’d share my response here:</p>
<p>That&#8217;s an excellent question. Someone asked that very question in Stockholm last month at my Effective Concurrency course, and my answer started out somewhat dismissive: &quot;Well, it&#8217;s about the same as you do in sequential code, and all the same guarantees apply; nothrow/nofail is only for a few key functions used for commit/rollback operations, and you’d usually target the basic guarantee unless adding the strong guarantee comes along naturally for near-free. So it’s pretty much the same as always. Although, well, of course futures may transport exceptions across threads, but that&#8217;s still the same because they manifest on .get(). And of course for parallel loops you may get multiple concurrent exceptions from multiple concurrent loop bodies that get aggregated into a single exception; and then there&#8217;s the question of whether you start new loop bodies that haven’t started yet (usually no) but do you interrupt loop bodies that are in progress (probably not), and&#8230; oh, hmm, yeah, I guess it would be good to write an article about that.&quot;</p>
<p>So the above is now adding to my notes of things to write about. :-) Maybe some of that stream-of-consciousness may be helpful until I can get to writing it up in more detail.</p>
<p>I pointed him to Doug Lea&#8217;s <a href="http://www.amazon.com/Concurrent-Programming-Java-TM-Principles/dp/0201310090">Concurrent Programming in Java</a> pages 161-176, &quot;Dealing with Failure&quot;, adding that I haven&#8217;t read it in detail but the subtopics look right. Also Joe Duffy’s <a href="http://www.amazon.com/Concurrent-Programming-Windows-Microsoft-Development/dp/032143482X">Concurrent Programming on Windows</a>, pages 721-733.</p>
<p>If you know of a good standalone treatise focused on error handling in concurrent code, please mention it in the comments.</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/06/23/answering-email-about-error-handling-in-concurrent-code/feed/</wfw:commentRss>
		<slash:comments>9</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Break Up and Interleave Work to Keep Threads Responsive</title>
		<link>https://herbsutter.com/2009/06/16/effective-concurrency-break-up-and-interleave-work-to-keep-threads-responsive/</link>
				<comments>https://herbsutter.com/2009/06/16/effective-concurrency-break-up-and-interleave-work-to-keep-threads-responsive/#comments</comments>
				<pubDate>Tue, 16 Jun 2009 18:09:16 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/06/16/effective-concurrency-break-up-and-interleave-work-to-keep-threads-responsive/</guid>
				<description><![CDATA[This month’s Effective Concurrency column, “Break Up and Interleave Work to Keep Threads Responsive”, is now live on DDJ’s website. Sorry for the long title; suggestions welcome. I always try to word the title to make it (a) short, (b) active, and (c) advice, but sometimes I’ll settle for two of those, or just one, [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">“Break Up and Interleave Work to Keep Threads Responsive”</a><strong></strong>, is now live on DDJ’s website.</p>
<p>Sorry for the long title; suggestions welcome. I always try to word the title to make it (a) short, (b) active, and (c) advice, but sometimes I’ll settle for two of those, or just one, until a better suggestion comes along.</p>
<p>From the article:</p>
<blockquote>
<p>What happens when this thread must remain responsive to new incoming messages that have to be handled quickly, even when we&#8217;re in the middle of servicing an earlier lower-priority message that may take a long time to process?</p>
<p>If all the messages must be handled on this same thread, then we have a problem. Fortunately, we also have two good solutions, both of which follow the same basic strategy: Somehow break apart the large piece of work to allow the thread to perform other work in between, interleaved between the chunks of the large item. Let&#8217;s consider the two major ways to implement that interleaving, and their respective tradeoffs in the areas of fairness and performance.</p>
</p>
</blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:</p>
<blockquote>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007) </p>
<p><a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007) </p>
<p><a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008) </p>
<p><a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008) </p>
<p><a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008) </p>
<p><a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008) </p>
<p><a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008) </p>
<p><a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008) </p>
<p><a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">Use Thread Pools Correctly: Keep Tasks Short and Nonblocking</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">Eliminate False Sharing</a> (May 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217801299">Break Up and Interleave Work to Keep Threads Responsive</a> (Jun 2009)</p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/06/16/effective-concurrency-break-up-and-interleave-work-to-keep-threads-responsive/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>VS2010 Beta 1 Now Available</title>
		<link>https://herbsutter.com/2009/05/20/vs2010-beta-1-now-available/</link>
				<comments>https://herbsutter.com/2009/05/20/vs2010-beta-1-now-available/#comments</comments>
				<pubDate>Thu, 21 May 2009 00:43:20 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C# / .NET]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/05/20/vs2010-beta-1-now-available/</guid>
				<description><![CDATA[For those of you who are interested in using or trying Microsoft development tools, I’m happy to report that Visual Studio 2010 Beta 1 is now available. If you’re interested in: concurrency and parallel computing, check out the new concurrency runtime (ConcRT) that implements efficient work stealing for scalable code, the Asynchronous Agents Library and [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>For those of you who are interested in using or trying Microsoft development tools, I’m happy to report that <a href="http://msdn.microsoft.com/en-us/netframework/dd582936.aspx">Visual Studio 2010 Beta 1</a> is now available.</p>
<p>If you’re interested in:</p>
<ul>
<li><a href="http://msdn.microsoft.com/en-us/library/dd504870(VS.100).aspx"><strong>concurrency and parallel computing</strong></a>, check out the new concurrency runtime (ConcRT) that implements efficient work stealing for scalable code, the <a href="http://msdn.microsoft.com/en-us/library/dd492627(VS.100).aspx">Asynchronous Agents Library</a> and the <a href="http://msdn.microsoft.com/en-us/library/dd492418(VS.100).aspx">Parallel Patterns Library (PPL)</a> for C++, and the <a href="http://msdn.microsoft.com/en-us/library/dd460717(VS.100).aspx">Task Parallel Library (TPL)</a> and <a href="http://msdn.microsoft.com/en-us/library/dd460688(VS.100).aspx">Parallel LINQ (PLINQ)</a> for .NET. And some nifty concurrency debugging and profiling tools, too. </li>
<li><strong><a href="http://msdn.microsoft.com/en-us/library/dd465215(VS.100).aspx">C++0x features</a></strong>, check out the <a href="http://msdn.microsoft.com/en-us/library/dd293608(VS.100).aspx">lambda functions</a> (my fave), move-semantic <a href="http://msdn.microsoft.com/en-us/library/dd293668(VS.100).aspx">rvalue references</a>, the new <a href="http://msdn.microsoft.com/en-us/library/6k3ybftz(VS.100).aspx">auto</a>, its good friend <a href="http://msdn.microsoft.com/en-us/library/dd537655(VS.100).aspx">decltype</a>, and the ever-helpful <a href="http://msdn.microsoft.com/en-us/library/dd293588(VS.100).aspx">static_assert</a>. </li>
<li><strong>functional programming in VS</strong>, enjoy the <a href="http://msdn.microsoft.com/en-us/library/dd553242(VS.100).aspx">F# programming language</a>. </li>
</ul>
<p>Remember this is just a beta and not intended for production use, but there’s a lot of cool stuff to play around with and it should run fine side-by-side with VS2008. Feedback via <a href="http://social.msdn.microsoft.com/Forums/en-US/category/VSPreRelease,netdevelopmentprerelease,visualstudioprerelease,vstsprerelease">forums</a> or <a href="http://go.microsoft.com/fwlink/?LinkID=151484">filing a bug/suggestion</a> is always appreciated. Enjoy!</p>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/05/20/vs2010-beta-1-now-available/feed/</wfw:commentRss>
		<slash:comments>17</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Eliminate False Sharing</title>
		<link>https://herbsutter.com/2009/05/15/effective-concurrency-eliminate-false-sharing/</link>
				<comments>https://herbsutter.com/2009/05/15/effective-concurrency-eliminate-false-sharing/#comments</comments>
				<pubDate>Fri, 15 May 2009 18:51:38 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[C# / .NET]]></category>
		<category><![CDATA[C++]]></category>
		<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/05/15/effective-concurrency-eliminate-false-sharing/</guid>
				<description><![CDATA[This month’s Effective Concurrency column, “Eliminate False Sharing”, is now live on DDJ’s website. People keep writing asking me about my previous mentions of false sharing, even debating whether it’s really a problem. So this month I decided to treat it in depth, including: A compelling and realistic example where just changing a couple of [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">“Eliminate False Sharing”</a><strong></strong>, is now live on DDJ’s website.</p>
<p>People keep writing asking me about my previous mentions of false sharing, even debating whether it’s really a problem. So this month I decided to treat it in depth, including:</p>
<ul>
<li>A compelling and realistic example where just changing a couple of lines to remove false sharing takes an algorithm from zero scaling to perfect scaling – even when many threads are merely doing reads. Hopefully after this nobody will argue that false sharing isn’t a problem. :-)</li>
<li>How your performance monitoring and analysis tools do and/or don’t help you uncover the problem, and how to use them effectively to identify the culprit. Short answer: CPU activity monitors aren’t very helpful, but cycles-per-instruction (CPI) and cache miss rate measurements attributed to specific lines of source code are your friend.</li>
<li>The two ways to correct the code: Reduce the frequency of writes to the too-popular cache line, or add padding to move other data off the line.</li>
<li>Reusable code in C++ and C#, and a note about Java, that you can use to use padding (and alignment if available) to put frequently-updated objects on their own cache lines.</li>
</ul>
<p>From the article:</p>
<blockquote>
<p>In two previous articles I pointed out the performance issue of false sharing (aka cache line ping-ponging), where threads use different objects but those objects happen to be close enough in memory that they fall on the same cache line, and the cache system treats them as a single lump that is effectively protected by a hardware write lock that only one core can hold at a time. … It’s easy to see why the problem arises when multiple cores are writing to different parts of the same cache line… In practice, however, it can be even more common to encounter a reader thread using what it thinks is read-only data still getting throttled by a writer thread updating a different but nearby memory location…</p>
<p>A number of readers have asked for more information and examples on where false sharing arises and how to deal with it. … This month, let’s consider a concrete example that shows an algorithm <em>in extremis </em>due to false sharing distress, how to use tools to analyze the problem, and the two coding techniques we can use to eliminate false sharing trouble. …</p>
</blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:</p>
<blockquote>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007) </p>
<p><a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007) </p>
<p><a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008) </p>
<p><a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008) </p>
<p><a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008) </p>
<p><a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008) </p>
<p><a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008) </p>
<p><a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008) </p>
<p><a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">“Use Thread Pools Correctly: Keep Tasks Short and Nonblocking”</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=217500206">“Eliminate False Sharing”</a> (May 2009)</p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/05/15/effective-concurrency-eliminate-false-sharing/feed/</wfw:commentRss>
		<slash:comments>10</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
		<item>
		<title>Effective Concurrency: Use Thread Pools Correctly &#8211; Keep Tasks Short and Nonblocking</title>
		<link>https://herbsutter.com/2009/04/20/effective-concurrency-use-thread-pools-correctly-keep-tasks-short-and-nonblocking/</link>
				<comments>https://herbsutter.com/2009/04/20/effective-concurrency-use-thread-pools-correctly-keep-tasks-short-and-nonblocking/#comments</comments>
				<pubDate>Tue, 21 Apr 2009 00:39:00 +0000</pubDate>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
				<category><![CDATA[Concurrency]]></category>
		<category><![CDATA[Software Development]]></category>

		<guid isPermaLink="false">http://herbsutter.wordpress.com/2009/04/20/effective-concurrency-use-thread-pools-correctly-keep-tasks-short-and-nonblocking/</guid>
				<description><![CDATA[This month’s Effective Concurrency column, “Use Thread Pools Correctly: Keep Tasks Short and Nonblocking”, is now live on DDJ’s website. From the article: … But the thread pool is a leaky abstraction. That is, the pool hides a lot of details from us, but to use it effectively we do need to be aware of [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>This month’s <strong>Effective Concurrency</strong> column, <a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">“Use Thread Pools Correctly: Keep Tasks Short and Nonblocking”</a><strong></strong>, is now live on DDJ’s website.</p>
<p>From the article:</p>
<blockquote>
<p>… But the thread pool is a leaky abstraction. That is, the pool hides a lot of details from us, but to use it effectively we do need to be aware of some things a pool does under the covers so that we can avoid inadvertently hitting performance and correctness pitfalls. Here&#8217;s the summary up front: </p>
<p>1. Tasks should be small, but not too small, otherwise performance overheads will dominate. </p>
<p>2. Tasks should avoid blocking (waiting idly for other events, including inbound messages or contested locks), otherwise the pool won&#8217;t consistently utilize the hardware well &#8212; and, in the extreme worst case, the pool could even deadlock. </p>
<p>Let&#8217;s see why. …</p>
</blockquote>
<p>I hope you enjoy it. Finally, here are links to previous Effective Concurrency columns:</p>
<blockquote>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/200001985">The Pillars of Concurrency</a> (Aug 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/201202924">How Much Scalability Do You Have or Need?</a> (Sep 2007) </p>
<p><a href="http://ddj.com/cpp/201804238">Use Critical Sections (Preferably Locks) to Eliminate Races</a> (Oct 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/202401098">Apply Critical Sections Consistently</a> (Nov 2007) </p>
<p><a href="http://ddj.com/architect/202802983">Avoid Calling Unknown Code While Inside a Critical Section</a> (Dec 2007) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/204801163">Use Lock Hierarchies to Avoid Deadlock</a> (Jan 2008) </p>
<p><a href="http://www.ddj.com/cpp/205900309">Break Amdahl’s Law!</a> (Feb 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206100542">Going Superlinear</a> (Mar 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/206903306">Super Linearity and the Bigger Machine</a> (Apr 2008) </p>
<p><a href="http://ddj.com/architect/207100682">Interrupt Politely</a> (May 2008) </p>
<p><a href="http://ddj.com/architect/208200273">Maximize Locality, Minimize Contention</a> (Jun 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/208801371">Choose Concurrency-Friendly Data Structures</a> (Jul 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/209900973">The Many Faces of Deadlock</a> (Aug 2008) </p>
<p><a href="http://www.ddj.com/cpp/210600279">Lock-Free Code: A False Sense of Security</a> (Sep 2008) </p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/210604448">Writing Lock-Free Code: A Corrected Queue</a> (Oct 2008) </p>
<p><a href="http://www.ddj.com/cpp/211601363">Writing a Generalized Concurrent Queue</a> (Nov 2008) </p>
<p><a href="http://www.ddj.com/cpp/211800538">Understanding Parallel Performance</a> (Dec 2008)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212201163">Measuring Parallel Performance: Optimizing a Concurrent Queue</a> (Jan 2009)</p>
<p><a href="http://www.ddj.com/hpc-high-performance-computing/212701484">volatile vs. volatile</a> (Feb 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=214100002">Sharing Is the Root of All Contention</a> (Mar 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=215900465">Use Threads Correctly = Isolation + Asynchronous Messages</a> (Apr 2009)</p>
<p><a href="http://www.ddj.com/go-parallel/article/showArticle.jhtml?articleID=216500409">“Use Thread Pools Correctly: Keep Tasks Short and Nonblocking”</a> (Apr 2009)</p>
</blockquote>
]]></content:encoded>
							<wfw:commentRss>https://herbsutter.com/2009/04/20/effective-concurrency-use-thread-pools-correctly-keep-tasks-short-and-nonblocking/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
						
		<media:content url="https://0.gravatar.com/avatar/c0ba56bfd231f8f04feb057728975181?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">Herb Sutter</media:title>
		</media:content>
	</item>
	</channel>
</rss>
