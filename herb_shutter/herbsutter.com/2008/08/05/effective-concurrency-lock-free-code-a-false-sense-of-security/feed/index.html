<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Effective Concurrency: Lock-Free Code &#8212; A False Sense of Security	</title>
	<atom:link href="https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/feed/" rel="self" type="application/rss+xml" />
	<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/</link>
	<description>Herb Sutter on software development</description>
	<lastBuildDate>
	Mon, 19 Nov 2018 23:08:15 +0000	</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
			<item>
				<title>
				By: There&#8217;s No Substitute for Experience with Threads &#171; Steve Huston&#8217;s Networked Programming Blog				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-978</link>
		<dc:creator><![CDATA[There&#8217;s No Substitute for Experience with Threads &#171; Steve Huston&#8217;s Networked Programming Blog]]></dc:creator>
		<pubDate>Mon, 05 Jan 2009 15:04:44 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-978</guid>
					<description><![CDATA[[...] Code: A False Sense of Security&#8221; by Herb Sutter (his blog entry related to the article is here). His &#8220;Effective Concurrency&#8221; column is a regular favorite of mine. The article is a [...]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;] Code: A False Sense of Security&#8221; by Herb Sutter (his blog entry related to the article is here). His &#8220;Effective Concurrency&#8221; column is a regular favorite of mine. The article is a [&#8230;]</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Interesting Concurrency Articles &#171; Roman&#8217;s Blog				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-836</link>
		<dc:creator><![CDATA[Interesting Concurrency Articles &#171; Roman&#8217;s Blog]]></dc:creator>
		<pubDate>Tue, 14 Oct 2008 16:09:30 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-836</guid>
					<description><![CDATA[[...] info  By Roman Hnatiuk   Categories: Software Development                     Effective Concurrency: Lock-Free Code - A False Sense of Security by Herb Sutter talks about lock-free code and its pitfalls. Also it contains pointers to many other [...]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;] info  By Roman Hnatiuk   Categories: Software Development                     Effective Concurrency: Lock-Free Code &#8211; A False Sense of Security by Herb Sutter talks about lock-free code and its pitfalls. Also it contains pointers to many other [&#8230;]</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Majkara				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-802</link>
		<dc:creator><![CDATA[Majkara]]></dc:creator>
		<pubDate>Thu, 25 Sep 2008 20:14:42 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-802</guid>
					<description><![CDATA[Hi Herb,

Critique is good. Not long ago, I remember when you and Alexandrescu, and friends got pretty much slaughtered on a C++ list for not figuring out atomic semantics and barriers and ordering problems, in a very similar fashion.

It all kicked off with a reference counted string implementation or similiar. Even source was provided and compilers could have adopted to support it in fact. And no one ever did anything about that?

It is common knowledge these days a few barriers eliminate the problem of single consumer, single producer scenarios. I guess that is what is taking over a month to publish as people eagerly await a common and trivial solution. At least it has been common since 2001.

So, critique is good, and no you are no different than anyone else out there regarding parallel programming.

It is all trickery against moving target that is hardware. Hence working on VMs and C++/CLI is a waste of time really. They even go against stack as the main culprit, which is symptomatic of going the bloated, slow, framework route (ie. doomed, in terms of performance and time it will be adopted for ).

Regards,
Majka]]></description>
		<content:encoded><![CDATA[<p>Hi Herb,</p>
<p>Critique is good. Not long ago, I remember when you and Alexandrescu, and friends got pretty much slaughtered on a C++ list for not figuring out atomic semantics and barriers and ordering problems, in a very similar fashion.</p>
<p>It all kicked off with a reference counted string implementation or similiar. Even source was provided and compilers could have adopted to support it in fact. And no one ever did anything about that?</p>
<p>It is common knowledge these days a few barriers eliminate the problem of single consumer, single producer scenarios. I guess that is what is taking over a month to publish as people eagerly await a common and trivial solution. At least it has been common since 2001.</p>
<p>So, critique is good, and no you are no different than anyone else out there regarding parallel programming.</p>
<p>It is all trickery against moving target that is hardware. Hence working on VMs and C++/CLI is a waste of time really. They even go against stack as the main culprit, which is symptomatic of going the bloated, slow, framework route (ie. doomed, in terms of performance and time it will be adopted for ).</p>
<p>Regards,<br />
Majka</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Passion is like genius; a miracle. - 흥미롭게 읽은, 읽을 concurrency 글들				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-792</link>
		<dc:creator><![CDATA[Passion is like genius; a miracle. - 흥미롭게 읽은, 읽을 concurrency 글들]]></dc:creator>
		<pubDate>Sat, 30 Aug 2008 07:34:20 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-792</guid>
					<description><![CDATA[[...] 제대로 구현한 lock-free queue 일 듯. 이 글은 그 유명하신 Herb Sutter가 쓴 글로 시리즈 물로 ddj 에서 [...]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;] 제대로 구현한 lock-free queue 일 듯. 이 글은 그 유명하신 Herb Sutter가 쓴 글로 시리즈 물로 ddj 에서 [&#8230;]</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Rainer Koppler				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-785</link>
		<dc:creator><![CDATA[Rainer Koppler]]></dc:creator>
		<pubDate>Sun, 17 Aug 2008 16:53:45 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-785</guid>
					<description><![CDATA[I think that the topic of this month&#039;s column has already been covered by an enlightening paper by Scott Meyers and Andrei Alexandrescu, which appeared in Dr. Dobb&#039;s Journal four years ago:

C++ and the Perils of Double-Checked Locking
http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf
http://www.nwcpp.org/Downloads/2004/DCLP_notes.pdf

In a nutshell, all concurrent software we have written in C++98 up to now that does not rely on threading libraries with operating system support (which includes numerous beloved non-blocking algorithms employing volatile) works by accident. In fact, volatile with its optimization-prevention semantics is often sufficient for single-processor parallelism (by accident, however), but that does not mean that optimization prevention using volatile is the key to thread safety under all circumstances, including multi-processor parallelism with weak memory consistency. The following part of the Linux kernel documentation offers a good treatment of volatile and its abuse for achieving thread safety:

Why the &quot;volatile&quot; type class should not be used
http://www.mjmwired.net/kernel/Documentation/volatile-considered-harmful.txt

Following Scott and Andrei, the only way to guarantee thread safety using C++98 is the use of platform-specific memory barriers (in other words: there is no portable solution in C++98), which are essentially also used in platform-specific implementations of threading libraries. So if you roll your own data structures, there&#039;s no way around these operations.

However, in the realm of embedded systems the world can look quite different: Many low-cost controllers do not confront the programmer with topics like memory consistency, so you mostly get along without barriers or the like. Your code works, but -- from the language lawyers&#039;s perspective -- by accident.

Regarding Fred&#039;s ring implementation: When we assume that reading and writing the index variables is done atomically, the protocols described in Scott&#039;s slides (DCLP_notes, slide 29-32) can be employed: ring_get needs an Acquire between reading write_index and accessing buffer, and ring_put needs a Release between writing to buffe and updating write_index.

By the way: During my lectures I discovered Petru Marginean&#039;s name in the Acknowledgements section of Scott&#039;s and Andrei&#039;s paper. Now the circle closes...]]></description>
		<content:encoded><![CDATA[<p>I think that the topic of this month&#8217;s column has already been covered by an enlightening paper by Scott Meyers and Andrei Alexandrescu, which appeared in Dr. Dobb&#8217;s Journal four years ago:</p>
<p>C++ and the Perils of Double-Checked Locking<br />
<a href="http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf" rel="nofollow">http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf</a><br />
<a href="http://www.nwcpp.org/Downloads/2004/DCLP_notes.pdf" rel="nofollow">http://www.nwcpp.org/Downloads/2004/DCLP_notes.pdf</a></p>
<p>In a nutshell, all concurrent software we have written in C++98 up to now that does not rely on threading libraries with operating system support (which includes numerous beloved non-blocking algorithms employing volatile) works by accident. In fact, volatile with its optimization-prevention semantics is often sufficient for single-processor parallelism (by accident, however), but that does not mean that optimization prevention using volatile is the key to thread safety under all circumstances, including multi-processor parallelism with weak memory consistency. The following part of the Linux kernel documentation offers a good treatment of volatile and its abuse for achieving thread safety:</p>
<p>Why the &#8220;volatile&#8221; type class should not be used<br />
<a href="http://www.mjmwired.net/kernel/Documentation/volatile-considered-harmful.txt" rel="nofollow">http://www.mjmwired.net/kernel/Documentation/volatile-considered-harmful.txt</a></p>
<p>Following Scott and Andrei, the only way to guarantee thread safety using C++98 is the use of platform-specific memory barriers (in other words: there is no portable solution in C++98), which are essentially also used in platform-specific implementations of threading libraries. So if you roll your own data structures, there&#8217;s no way around these operations.</p>
<p>However, in the realm of embedded systems the world can look quite different: Many low-cost controllers do not confront the programmer with topics like memory consistency, so you mostly get along without barriers or the like. Your code works, but &#8212; from the language lawyers&#8217;s perspective &#8212; by accident.</p>
<p>Regarding Fred&#8217;s ring implementation: When we assume that reading and writing the index variables is done atomically, the protocols described in Scott&#8217;s slides (DCLP_notes, slide 29-32) can be employed: ring_get needs an Acquire between reading write_index and accessing buffer, and ring_put needs a Release between writing to buffe and updating write_index.</p>
<p>By the way: During my lectures I discovered Petru Marginean&#8217;s name in the Acknowledgements section of Scott&#8217;s and Andrei&#8217;s paper. Now the circle closes&#8230;</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Fred Roeber				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-784</link>
		<dc:creator><![CDATA[Fred Roeber]]></dc:creator>
		<pubDate>Sat, 16 Aug 2008 14:16:04 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-784</guid>
					<description><![CDATA[As others have mentioned, I have a hard time believing that we have to worry about some of the transformations and reorderings mentioned near the end of the article. Or, stated a different way I have trouble believing it&#039;s possible to write any valid lock free program if such transformations and reorderings are really possible. This bothers me a lot because I&#039;ve worked with a lot of embedded system&#039;s code (including the source code for more than a few of the proprietary and very popular embedded operating systems). I&#039;ve had to verify and correct the operation of a lot of this code for some pretty safety critical applications. I now wonder, &quot;is the code I thought was safe really safe&quot;.

I&#039;d sort of like to get an opinion about one bit of C code that I have seen used over and over to do &quot;lock free&quot; &quot;single reader - single writer&quot; communication. I&#039;ve seen this used on many of the processors out there with lots of compilers and never known there to be a problem. But if processors can insert false writes and totally ignore sequential consistency then maybe this code isn&#039;t valid.  

typedef struct {
    volatile size_t read_index;  /* index of next data to get/read */
    volatile size_t write_index; /* index of next place to put/write data */
    size_t          buffer_size; /* size of ring &#039;buffer&#039; in bytes */
    uint8_t        *buffer;      /* pointer to start of buffer */
} RING_T;

typedef RING_T *RING_ID;

/**
 * Get one byte from a ring buffer.
 *
 * @Param ring_id   Ring buffer to manipulate
 * @Param byte_ptr  Where to store returned byte
 *
 * @Return true if there was a byte to return, false otherwise
 */
bool
ring_get(RING_ID ring_id, uint8_t *byte_ptr)
{
    size_t read_index;

    read_index = ring_id-&#062;read_index;
    if (read_index == ring_id-&#062;write_index) {
        /* Ring is empty */
        return false;
    } else {
        /* Pull byte out of ring and advance ring index */
        *byte_ptr = ring_id-&#062;buffer[read_index];
        if (++read_index == ring_id-&#062;buffer_size) {
            read_index = 0;
        }
        ring_id-&#062;read_index = read_index;
        return true;
    }
}

/**
 * Initialize ring buffer to be empty.
 *
 * Create a ring buffer of size &#039;nbytes&#039;, and initialize
 * it. Note, a ring buffer can store a
 * maximum of one byte less than &#039;nbytes&#039;.
 *
 * @Param  ring_id  Preallocated ring buffer control structure to initialize
 * @Param  buffer   Buffer that ring buffer data to be stored in
 * @Param  nbytes   Size of &#039;buffer&#039; in bytes
 */
void
ring_init(RING_ID ring_id, uint8_t *buffer, size_t nbytes)
{
    /* Save the buffer info in the ring control structure. */
    ring_id-&#062;buffer      = buffer;
    ring_id-&#062;buffer_size = nbytes;

    /* Make sure ring buffer starts out empty */
    ring_id-&#062;read_index  = 0;
    ring_id-&#062;write_index = 0;
}

/**
 * Put one byte into a ring buffer.
 *
 * @Param ring_id  Ring buffer to manipulate
 * @Param byte     Byte to put into ring
 *
 * @Return true if there was space for byte, false otherwise
 */
bool
ring_put(RING_ID ring_id, uint8_t byte)
{
    size_t write_index;

    write_index = ring_id-&#062;write_index;
    if (write_index == ring_id-&#062;read_index - 1) {
        /* Ring is full so can&#039;t write any more */
        return false;
    } else {
        if (write_index == ring_id-&#062;buffer_size - 1) {
            if (ring_id-&#062;read_index == 0) {
                /* Ring is full so can&#039;t write any more */
                return false;
            } else {
                ring_id-&#062;buffer[write_index] = byte;
                ring_id-&#062;write_index = 0;
                return true;
            }
        } else {
            ring_id-&#062;buffer[write_index] = byte;
            ring_id-&#062;write_index = write_index + 1;
            return true;
        }
    }
}]]></description>
		<content:encoded><![CDATA[<p>As others have mentioned, I have a hard time believing that we have to worry about some of the transformations and reorderings mentioned near the end of the article. Or, stated a different way I have trouble believing it&#8217;s possible to write any valid lock free program if such transformations and reorderings are really possible. This bothers me a lot because I&#8217;ve worked with a lot of embedded system&#8217;s code (including the source code for more than a few of the proprietary and very popular embedded operating systems). I&#8217;ve had to verify and correct the operation of a lot of this code for some pretty safety critical applications. I now wonder, &#8220;is the code I thought was safe really safe&#8221;.</p>
<p>I&#8217;d sort of like to get an opinion about one bit of C code that I have seen used over and over to do &#8220;lock free&#8221; &#8220;single reader &#8211; single writer&#8221; communication. I&#8217;ve seen this used on many of the processors out there with lots of compilers and never known there to be a problem. But if processors can insert false writes and totally ignore sequential consistency then maybe this code isn&#8217;t valid.  </p>
<p>typedef struct {<br />
    volatile size_t read_index;  /* index of next data to get/read */<br />
    volatile size_t write_index; /* index of next place to put/write data */<br />
    size_t          buffer_size; /* size of ring &#8216;buffer&#8217; in bytes */<br />
    uint8_t        *buffer;      /* pointer to start of buffer */<br />
} RING_T;</p>
<p>typedef RING_T *RING_ID;</p>
<p>/**<br />
 * Get one byte from a ring buffer.<br />
 *<br />
 * @Param ring_id   Ring buffer to manipulate<br />
 * @Param byte_ptr  Where to store returned byte<br />
 *<br />
 * @Return true if there was a byte to return, false otherwise<br />
 */<br />
bool<br />
ring_get(RING_ID ring_id, uint8_t *byte_ptr)<br />
{<br />
    size_t read_index;</p>
<p>    read_index = ring_id-&gt;read_index;<br />
    if (read_index == ring_id-&gt;write_index) {<br />
        /* Ring is empty */<br />
        return false;<br />
    } else {<br />
        /* Pull byte out of ring and advance ring index */<br />
        *byte_ptr = ring_id-&gt;buffer[read_index];<br />
        if (++read_index == ring_id-&gt;buffer_size) {<br />
            read_index = 0;<br />
        }<br />
        ring_id-&gt;read_index = read_index;<br />
        return true;<br />
    }<br />
}</p>
<p>/**<br />
 * Initialize ring buffer to be empty.<br />
 *<br />
 * Create a ring buffer of size &#8216;nbytes&#8217;, and initialize<br />
 * it. Note, a ring buffer can store a<br />
 * maximum of one byte less than &#8216;nbytes&#8217;.<br />
 *<br />
 * @Param  ring_id  Preallocated ring buffer control structure to initialize<br />
 * @Param  buffer   Buffer that ring buffer data to be stored in<br />
 * @Param  nbytes   Size of &#8216;buffer&#8217; in bytes<br />
 */<br />
void<br />
ring_init(RING_ID ring_id, uint8_t *buffer, size_t nbytes)<br />
{<br />
    /* Save the buffer info in the ring control structure. */<br />
    ring_id-&gt;buffer      = buffer;<br />
    ring_id-&gt;buffer_size = nbytes;</p>
<p>    /* Make sure ring buffer starts out empty */<br />
    ring_id-&gt;read_index  = 0;<br />
    ring_id-&gt;write_index = 0;<br />
}</p>
<p>/**<br />
 * Put one byte into a ring buffer.<br />
 *<br />
 * @Param ring_id  Ring buffer to manipulate<br />
 * @Param byte     Byte to put into ring<br />
 *<br />
 * @Return true if there was space for byte, false otherwise<br />
 */<br />
bool<br />
ring_put(RING_ID ring_id, uint8_t byte)<br />
{<br />
    size_t write_index;</p>
<p>    write_index = ring_id-&gt;write_index;<br />
    if (write_index == ring_id-&gt;read_index &#8211; 1) {<br />
        /* Ring is full so can&#8217;t write any more */<br />
        return false;<br />
    } else {<br />
        if (write_index == ring_id-&gt;buffer_size &#8211; 1) {<br />
            if (ring_id-&gt;read_index == 0) {<br />
                /* Ring is full so can&#8217;t write any more */<br />
                return false;<br />
            } else {<br />
                ring_id-&gt;buffer[write_index] = byte;<br />
                ring_id-&gt;write_index = 0;<br />
                return true;<br />
            }<br />
        } else {<br />
            ring_id-&gt;buffer[write_index] = byte;<br />
            ring_id-&gt;write_index = write_index + 1;<br />
            return true;<br />
        }<br />
    }<br />
}</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Brooks Moses				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-772</link>
		<dc:creator><![CDATA[Brooks Moses]]></dc:creator>
		<pubDate>Tue, 12 Aug 2008 02:45:20 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-772</guid>
					<description><![CDATA[To Jaroslav Sevcik:

Thanks for the explanation!  And I see the larger issue underlying the &quot;why not make &quot;data&quot; volatile&quot; part of it, too; it may only be at very specific points in a program that one cares about the volatility of a variable, and prohibitively expensive to make it volatile throughout.

I would have thought that it would generally be possible to encapsulate the relevant portions of the code in a function and only declare data to be volatile within that function, though.  I gather that that isn&#039;t as general as I think?]]></description>
		<content:encoded><![CDATA[<p>To Jaroslav Sevcik:</p>
<p>Thanks for the explanation!  And I see the larger issue underlying the &#8220;why not make &#8220;data&#8221; volatile&#8221; part of it, too; it may only be at very specific points in a program that one cares about the volatility of a variable, and prohibitively expensive to make it volatile throughout.</p>
<p>I would have thought that it would generally be possible to encapsulate the relevant portions of the code in a function and only declare data to be volatile within that function, though.  I gather that that isn&#8217;t as general as I think?</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Jaroslav Sevcik				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-768</link>
		<dc:creator><![CDATA[Jaroslav Sevcik]]></dc:creator>
		<pubDate>Fri, 08 Aug 2008 11:13:11 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-768</guid>
					<description><![CDATA[To Brooks Moses:

The problem with the C++ volatile is that it is too weak for safe multi-threading, because it only prevents optimizations on the volatile variable itself, but it does not prevent interfering optimization on other variables, such as the &#039;payload&#039; data in the queue.

While I do not have an example showing where real compiler does something wrong with this particular implementation of queue, I can show you an example, where C++ volatile is just not enough:

int data = 0;

volatile bool requestReady = false;
volatile bool responseReady = false;

void thread1() {
  data = 1;
  requestReady = true;
  
  if (responseReady)
    std::cout &#060;&#060; data;
}

void thread2() {
  if (requestReady) {
    data = 2;
    responseReady = true;
  }
}

Note this program can never print 1. However, compilers will happily replace &#039;std::cout &#060;&#060; data&#039; by &#039;std::cout &#060;&#060; 1&#039;. Suddenly, your program can print 1! 

In Java, this program is data race free (because data races can only happen on volatile variables). In C++0x the program would be data race free, if requestReady and ResponseReady were atomic variables. Both Java and C++0x guarantee sequentially consistent behaviours for data race free program. That means that Java and C++0x guarantee sane behaviours, i.e., the program can only print 2.

You might suggest that programmers should make the &#039;data&#039; variable volatile, too. However, the &#039;data&#039; variable might be a pointer to some big data structure that is defined in a library, so you cannot make all fields of the data structure volatile. And you certainly do not want create a &#039;volatile&#039; copy of the entire structure just because you want to send a pointer...

Below is the real example that prints 1 (compile with gcc -O and pthreads):

#include 
#include 

int data = 0;

volatile bool requestReady = false;
volatile bool responseReady = false;

void *thread_proc(void *arg) {
  //Wait for request
  for(volatile int i = 0; i &#060; 500000000; i++) ; 

  if (requestReady) {
    data = 2;
    responseReady = true;
  }
  return NULL;
}

int main() {
  pthread_t t1;
  pthread_create(&#038;t1, NULL, thread_proc, NULL);

  data = 1;
  requestReady = true;

  // Wait for response
  for(volatile int i = 0; i &#060; 1000000000; i++) ; 

  if (responseReady)
    std::cout &#060;&#060; data &#060;&#060; std::endl;
  return 0;
}]]></description>
		<content:encoded><![CDATA[<p>To Brooks Moses:</p>
<p>The problem with the C++ volatile is that it is too weak for safe multi-threading, because it only prevents optimizations on the volatile variable itself, but it does not prevent interfering optimization on other variables, such as the &#8216;payload&#8217; data in the queue.</p>
<p>While I do not have an example showing where real compiler does something wrong with this particular implementation of queue, I can show you an example, where C++ volatile is just not enough:</p>
<p>int data = 0;</p>
<p>volatile bool requestReady = false;<br />
volatile bool responseReady = false;</p>
<p>void thread1() {<br />
  data = 1;<br />
  requestReady = true;</p>
<p>  if (responseReady)<br />
    std::cout &lt;&lt; data;<br />
}</p>
<p>void thread2() {<br />
  if (requestReady) {<br />
    data = 2;<br />
    responseReady = true;<br />
  }<br />
}</p>
<p>Note this program can never print 1. However, compilers will happily replace &#8216;std::cout &lt;&lt; data&#8217; by &#8216;std::cout &lt;&lt; 1&#8217;. Suddenly, your program can print 1! </p>
<p>In Java, this program is data race free (because data races can only happen on volatile variables). In C++0x the program would be data race free, if requestReady and ResponseReady were atomic variables. Both Java and C++0x guarantee sequentially consistent behaviours for data race free program. That means that Java and C++0x guarantee sane behaviours, i.e., the program can only print 2.</p>
<p>You might suggest that programmers should make the &#8216;data&#8217; variable volatile, too. However, the &#8216;data&#8217; variable might be a pointer to some big data structure that is defined in a library, so you cannot make all fields of the data structure volatile. And you certainly do not want create a &#8216;volatile&#8217; copy of the entire structure just because you want to send a pointer&#8230;</p>
<p>Below is the real example that prints 1 (compile with gcc -O and pthreads):</p>
<p>#include<br />
#include </p>
<p>int data = 0;</p>
<p>volatile bool requestReady = false;<br />
volatile bool responseReady = false;</p>
<p>void *thread_proc(void *arg) {<br />
  //Wait for request<br />
  for(volatile int i = 0; i &lt; 500000000; i++) ; </p>
<p>  if (requestReady) {<br />
    data = 2;<br />
    responseReady = true;<br />
  }<br />
  return NULL;<br />
}</p>
<p>int main() {<br />
  pthread_t t1;<br />
  pthread_create(&amp;t1, NULL, thread_proc, NULL);</p>
<p>  data = 1;<br />
  requestReady = true;</p>
<p>  // Wait for response<br />
  for(volatile int i = 0; i &lt; 1000000000; i++) ; </p>
<p>  if (responseReady)<br />
    std::cout &lt;&lt; data &lt;&lt; std::endl;<br />
  return 0;<br />
}</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Brooks Moses				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-767</link>
		<dc:creator><![CDATA[Brooks Moses]]></dc:creator>
		<pubDate>Thu, 07 Aug 2008 19:46:33 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-767</guid>
					<description><![CDATA[I&#039;m curious about some of the compiler code-reorganization that you refer to in the article -- why isn&#039;t the solution to this problem to declare the relevant variables as &quot;volatile&quot;?  After all, the whole point of volatile is to tell the compiler that the variable in question may be changed or read by things outside the scope of the code being compiled, while that code is running, and thus that optimizations which would be broken by that (such as reordering the reads to be after other function calls, or inserting additional writes) should be avoided.

(See, for example, this DDJ article about the subject: http://www.ddj.com/cpp/184403766.)]]></description>
		<content:encoded><![CDATA[<p>I&#8217;m curious about some of the compiler code-reorganization that you refer to in the article &#8212; why isn&#8217;t the solution to this problem to declare the relevant variables as &#8220;volatile&#8221;?  After all, the whole point of volatile is to tell the compiler that the variable in question may be changed or read by things outside the scope of the code being compiled, while that code is running, and thus that optimizations which would be broken by that (such as reordering the reads to be after other function calls, or inserting additional writes) should be avoided.</p>
<p>(See, for example, this DDJ article about the subject: <a href="http://www.ddj.com/cpp/184403766" rel="nofollow">http://www.ddj.com/cpp/184403766</a>.)</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Maxim Yegorushkin				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-763</link>
		<dc:creator><![CDATA[Maxim Yegorushkin]]></dc:creator>
		<pubDate>Wed, 06 Aug 2008 14:40:41 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-763</guid>
					<description><![CDATA[If we look closely at the queue constructor and Produce code:

 LockFreeQueue() {
    list.push_back(T());
    iHead = list.begin();
    iTail = list.end(); // &#060;--- here
  }

  void Produce(const T&#038; t) {
    list.push_back(t);
    iTail = list.end(); // &#060;--- and here
    list.erase(list.begin(), iHead);
  }

In a typical list implementation list::end() always returns the very same iterator regardless of prior insertion and removals. It is no surprise, because a straigt forward implemenation would use a dummy list node to maintain the list. dummy_node.next is the return value of list::begin(), &#038;dummy_node is the return value of list::end() and dummy_node.prev is the last node (if any) of the list. When the list is empty &#038;dummy_node == dummy_node.next, so that list::begin() == list::end().

In other words, the necessity of iTail member is implementation defined and is rather questionable.]]></description>
		<content:encoded><![CDATA[<p>If we look closely at the queue constructor and Produce code:</p>
<p> LockFreeQueue() {<br />
    list.push_back(T());<br />
    iHead = list.begin();<br />
    iTail = list.end(); // &lt;&#8212; here<br />
  }</p>
<p>  void Produce(const T&amp; t) {<br />
    list.push_back(t);<br />
    iTail = list.end(); // &lt;&#8212; and here<br />
    list.erase(list.begin(), iHead);<br />
  }</p>
<p>In a typical list implementation list::end() always returns the very same iterator regardless of prior insertion and removals. It is no surprise, because a straigt forward implemenation would use a dummy list node to maintain the list. dummy_node.next is the return value of list::begin(), &amp;dummy_node is the return value of list::end() and dummy_node.prev is the last node (if any) of the list. When the list is empty &amp;dummy_node == dummy_node.next, so that list::begin() == list::end().</p>
<p>In other words, the necessity of iTail member is implementation defined and is rather questionable.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Jaroslav Sevcik				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-761</link>
		<dc:creator><![CDATA[Jaroslav Sevcik]]></dc:creator>
		<pubDate>Wed, 06 Aug 2008 11:09:24 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-761</guid>
					<description><![CDATA[Thanks for the nice article. While I agree that the code you show is flawed, I am somewhat skeptical that compilers/processors perform the transformations you show on the last page. 

As for the insertion of write: Is there any processor that can introduce new writes of a different value from the ones that are already in the execution? As far as I know, Intel IA-32, AMD and Sun TSO cannot introduce new writes. Intel Itanium sort of can but only with the same value as the existing ones. As for compilers, .NET cannot introduce writes at all, and Java cannot introduce writes out-of-thin-air, which is the case you show. C++0x could insert the write you show, but I am somewhat doubtful that any implementation would do that.

The speculation on the outcome of if-statement seems to be even more suspicious, because it violates sequential consistency for correctly synchronized programs.

For example, consider this program:

LockFreeQueue q;
main() {start_thread(t2); int r; if (q.Consume(r)) printf(&quot;!&quot;);}
t2() {int r; if (q.Consume(r)) printf(&quot;!&quot;);}

The program does not have any data races, because after initialization it only reads. Moreover, it cannot print in any sequentially consistent execution, because  q is always an empty queue. However, after your speculation transformation, there is an interleaving where the program can print in a sequentially consistent execution (e.g., if first thread performs iNext=iHead;iNext++;__temp=iHead;iHead=iNext; then the second thread goes iNext=iHead;iNext++;__temp=iHead;iHead=iNext;if (iNext==iTail) ... {t=*Head;return true;}). This implies that neither Java, nor C#, nor C++ can perform such transformation, because they guarantee that you only get sequentially consistent behaviors from data race free programs.

Am I wrong somewhere? Do you know any compiler/hardware that performs these transformations? I am sorry for the long comment.]]></description>
		<content:encoded><![CDATA[<p>Thanks for the nice article. While I agree that the code you show is flawed, I am somewhat skeptical that compilers/processors perform the transformations you show on the last page. </p>
<p>As for the insertion of write: Is there any processor that can introduce new writes of a different value from the ones that are already in the execution? As far as I know, Intel IA-32, AMD and Sun TSO cannot introduce new writes. Intel Itanium sort of can but only with the same value as the existing ones. As for compilers, .NET cannot introduce writes at all, and Java cannot introduce writes out-of-thin-air, which is the case you show. C++0x could insert the write you show, but I am somewhat doubtful that any implementation would do that.</p>
<p>The speculation on the outcome of if-statement seems to be even more suspicious, because it violates sequential consistency for correctly synchronized programs.</p>
<p>For example, consider this program:</p>
<p>LockFreeQueue q;<br />
main() {start_thread(t2); int r; if (q.Consume(r)) printf(&#8220;!&#8221;);}<br />
t2() {int r; if (q.Consume(r)) printf(&#8220;!&#8221;);}</p>
<p>The program does not have any data races, because after initialization it only reads. Moreover, it cannot print in any sequentially consistent execution, because  q is always an empty queue. However, after your speculation transformation, there is an interleaving where the program can print in a sequentially consistent execution (e.g., if first thread performs iNext=iHead;iNext++;__temp=iHead;iHead=iNext; then the second thread goes iNext=iHead;iNext++;__temp=iHead;iHead=iNext;if (iNext==iTail) &#8230; {t=*Head;return true;}). This implies that neither Java, nor C#, nor C++ can perform such transformation, because they guarantee that you only get sequentially consistent behaviors from data race free programs.</p>
<p>Am I wrong somewhere? Do you know any compiler/hardware that performs these transformations? I am sorry for the long comment.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Joshua Haberman				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-760</link>
		<dc:creator><![CDATA[Joshua Haberman]]></dc:creator>
		<pubDate>Wed, 06 Aug 2008 04:22:39 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-760</guid>
					<description><![CDATA[I suppose I should have scanned your recent articles and read the one about deadlock before posting -- I am sure you will correct me and explain that deadlock *can* exist in lock-free designs.  :)  I think it&#039;s still the case that lock-based designs do force programmers to contend with lots of error-prone issues like lock granularity, ordering, etc.   Maybe lock-free approaches will have lots of issues of their own, but I think they&#039;re at least worth a shot, and I think people should understand that lock-free data structures are analogous to mutexes themselves.]]></description>
		<content:encoded><![CDATA[<p>I suppose I should have scanned your recent articles and read the one about deadlock before posting &#8212; I am sure you will correct me and explain that deadlock *can* exist in lock-free designs.  :)  I think it&#8217;s still the case that lock-based designs do force programmers to contend with lots of error-prone issues like lock granularity, ordering, etc.   Maybe lock-free approaches will have lots of issues of their own, but I think they&#8217;re at least worth a shot, and I think people should understand that lock-free data structures are analogous to mutexes themselves.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Joshua Haberman				</title>
				<link>https://herbsutter.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-759</link>
		<dc:creator><![CDATA[Joshua Haberman]]></dc:creator>
		<pubDate>Wed, 06 Aug 2008 04:08:27 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/2008/08/05/effective-concurrency-lock-free-code-a-false-sense-of-security/#comment-759</guid>
					<description><![CDATA[There&#039;s no doubt that lock-free data structures are extremely difficult to write and get right.  But I disagree with the subtext that I perceive from this blog entry and your article that says &quot;lock-free == risky, locks == safe.&quot;  To me that seems like the wrong message to be sending.

There&#039;s no doubt that only the experts should be writing lock-free data structures.  But the same is true of locks themselves: only experts who are familiar with the architecture (memory visibility model, barriers, etc) should be writing them.  Everyone else just uses the work that the experts do.  For example, it doesn&#039;t take an expert to *use* a lock-free queue to coordinate a bunch of threads that are acting in a producer/consumer relationship.

From the perspective of the average programmer, *using* lock-free data structures shouldn&#039;t be significantly more error-prone than using locks.  In fact it could be less so: lock-based programming forces you to deal with deadlock, priority inversion, etc. none of which arise in lock-free designs.

Good, robust lock-free data structures aren&#039;t ubiquitous like locks are today, but to me that just means that the field is immature, not that lock-free approaches are inherently risky.]]></description>
		<content:encoded><![CDATA[<p>There&#8217;s no doubt that lock-free data structures are extremely difficult to write and get right.  But I disagree with the subtext that I perceive from this blog entry and your article that says &#8220;lock-free == risky, locks == safe.&#8221;  To me that seems like the wrong message to be sending.</p>
<p>There&#8217;s no doubt that only the experts should be writing lock-free data structures.  But the same is true of locks themselves: only experts who are familiar with the architecture (memory visibility model, barriers, etc) should be writing them.  Everyone else just uses the work that the experts do.  For example, it doesn&#8217;t take an expert to *use* a lock-free queue to coordinate a bunch of threads that are acting in a producer/consumer relationship.</p>
<p>From the perspective of the average programmer, *using* lock-free data structures shouldn&#8217;t be significantly more error-prone than using locks.  In fact it could be less so: lock-based programming forces you to deal with deadlock, priority inversion, etc. none of which arise in lock-free designs.</p>
<p>Good, robust lock-free data structures aren&#8217;t ubiquitous like locks are today, but to me that just means that the field is immature, not that lock-free approaches are inherently risky.</p>
]]></content:encoded>
					</item>
			</channel>
</rss>
