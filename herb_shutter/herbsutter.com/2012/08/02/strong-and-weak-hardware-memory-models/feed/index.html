<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: &#8220;Strong&#8221; and &#8220;weak&#8221; hardware memory models	</title>
	<atom:link href="https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/feed/" rel="self" type="application/rss+xml" />
	<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/</link>
	<description>Herb Sutter on software development</description>
	<lastBuildDate>
	Mon, 19 Nov 2018 23:08:15 +0000	</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
			<item>
				<title>
				By: Herb Sutter				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-13232</link>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
		<pubDate>Thu, 14 Nov 2013 21:09:53 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-13232</guid>
					<description><![CDATA[@Ragavendra: If I wrote a formal reference on a paper it would be: &quot;Jem Davies and Richard Grisenthwaite, personal communication, June 2012.&quot; Jem and Richard are The Guys -- the primary ARM processor and memory model architects -- and what I wrote and presented in the talk was the summary of the ARM v8 CPU and GPU memory models that ARM approved for me to report publicly at that time for this talk. Specifically, as of that writing, ARM GPUs had no equivalent of load-acquire store-release instructions because they didn&#039;t need them.]]></description>
		<content:encoded><![CDATA[<p>@Ragavendra: If I wrote a formal reference on a paper it would be: &#8220;Jem Davies and Richard Grisenthwaite, personal communication, June 2012.&#8221; Jem and Richard are The Guys &#8212; the primary ARM processor and memory model architects &#8212; and what I wrote and presented in the talk was the summary of the ARM v8 CPU and GPU memory models that ARM approved for me to report publicly at that time for this talk. Specifically, as of that writing, ARM GPUs had no equivalent of load-acquire store-release instructions because they didn&#8217;t need them.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Ragavendra Natarajan				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-13229</link>
		<dc:creator><![CDATA[Ragavendra Natarajan]]></dc:creator>
		<pubDate>Thu, 14 Nov 2013 17:35:01 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-13229</guid>
					<description><![CDATA[&quot;ARM GPUs currently have a stronger memory model, namely fully SC&quot;.

I&#039;ve been reading about ARM GPU memory models and cannot find a reference that states they have SC model. Can you please provide a reference for this?]]></description>
		<content:encoded><![CDATA[<p>&#8220;ARM GPUs currently have a stronger memory model, namely fully SC&#8221;.</p>
<p>I&#8217;ve been reading about ARM GPU memory models and cannot find a reference that states they have SC model. Can you please provide a reference for this?</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Herb Sutter				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5904</link>
		<dc:creator><![CDATA[Herb Sutter]]></dc:creator>
		<pubDate>Sat, 04 Aug 2012 15:30:21 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-5904</guid>
					<description><![CDATA[@Jon: This was the terminology we used during the C++ and C memory model discussions (and Java, which I wasn&#039;t involved with but did involve many of the same people): We talked about x86 as the poster child for strong because it has the strongest guarantees of mainstream hardware (not all of which guarantees are necessary or desirable, as I&#039;ll mention in my talk on Tuesday) and especially it efficiently supports SC program semantics, whereas ARM(v7) and POWER require heavy sync operations to get SC program semantics. I say &quot;SC program semantics&quot; because it&#039;s not only about atomics, though that is part of it.

Of course, no mainstream hardware is truly SC any more and will never be again, so &quot;pure SC hardware&quot; is of historical interest only. However, giving programs SC semantics is a very strong guarantee, even with the C++11/C11/Java qualifier &quot;if you don&#039;t write races,&quot; and it&#039;s important because it&#039;s the only thing that anyone has been able to show mainstream developers can reason about successfully.

@Dave: Synchronizing using mutexes/cvs is what we prefer to teach people to use by default. Programming using SC atomics is indeed experts-only difficulty, but unfortunately it&#039;s also justified more often than I would like (e.g., DCL, reference counting, and several other common patterns some of which should be wrapped in types but can&#039;t always be) and so it turns out that we still have to teach SC atomics techniques to advanced-but-mainstream C++ programmers. However, programming using weaker-than-SC atomics is yet another major level of difficulty beyond that, and I don&#039;t know if there are 100 people in the world who can reliably use those directly; I&#039;m still trying to discourage resorting to them, although there currently are performance reasons to reach for them on ARMv7 and POWER. There is a difference of opinion among experts as to whether weaker-than-SC atomics are fully going away or not (e.g., they are lingering in 1000+ core count supercomputing applications), but with ARMv8 in particular the industry momentum in mainstream processors is going in the direction of seeing the performance carrot shrinking and disappearing for resorting to weaker-than-SC models.]]></description>
		<content:encoded><![CDATA[<p>@Jon: This was the terminology we used during the C++ and C memory model discussions (and Java, which I wasn&#8217;t involved with but did involve many of the same people): We talked about x86 as the poster child for strong because it has the strongest guarantees of mainstream hardware (not all of which guarantees are necessary or desirable, as I&#8217;ll mention in my talk on Tuesday) and especially it efficiently supports SC program semantics, whereas ARM(v7) and POWER require heavy sync operations to get SC program semantics. I say &#8220;SC program semantics&#8221; because it&#8217;s not only about atomics, though that is part of it.</p>
<p>Of course, no mainstream hardware is truly SC any more and will never be again, so &#8220;pure SC hardware&#8221; is of historical interest only. However, giving programs SC semantics is a very strong guarantee, even with the C++11/C11/Java qualifier &#8220;if you don&#8217;t write races,&#8221; and it&#8217;s important because it&#8217;s the only thing that anyone has been able to show mainstream developers can reason about successfully.</p>
<p>@Dave: Synchronizing using mutexes/cvs is what we prefer to teach people to use by default. Programming using SC atomics is indeed experts-only difficulty, but unfortunately it&#8217;s also justified more often than I would like (e.g., DCL, reference counting, and several other common patterns some of which should be wrapped in types but can&#8217;t always be) and so it turns out that we still have to teach SC atomics techniques to advanced-but-mainstream C++ programmers. However, programming using weaker-than-SC atomics is yet another major level of difficulty beyond that, and I don&#8217;t know if there are 100 people in the world who can reliably use those directly; I&#8217;m still trying to discourage resorting to them, although there currently are performance reasons to reach for them on ARMv7 and POWER. There is a difference of opinion among experts as to whether weaker-than-SC atomics are fully going away or not (e.g., they are lingering in 1000+ core count supercomputing applications), but with ARMv8 in particular the industry momentum in mainstream processors is going in the direction of seeing the performance carrot shrinking and disappearing for resorting to weaker-than-SC models.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Jon Harrop				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5903</link>
		<dc:creator><![CDATA[Jon Harrop]]></dc:creator>
		<pubDate>Sat, 04 Aug 2012 11:11:20 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-5903</guid>
					<description><![CDATA[&quot;x86 has always been the poster child for a strong (hardware) memory model&quot;

FWIW, memory model researchers at the University of Cambridge regard x86 as having a weak memory model:

http://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf

And memory model researchers at the University of Oxford also regard x86 as having a weak memory model:

http://www.cs.ox.ac.uk/people/jade.alglave/papers/aplas11.pdf

The reason is that they regard a strong model as one where all memory operations are sequentially consistent. That is obviously not true of x86 because it reorders independent reads so x86 is a weak memory model by that definition.

I had never seen your definitions before but your previous statements make sense in their context. You were saying that only atomics will be sequentially consistent in future architectures.]]></description>
		<content:encoded><![CDATA[<p>&#8220;x86 has always been the poster child for a strong (hardware) memory model&#8221;</p>
<p>FWIW, memory model researchers at the University of Cambridge regard x86 as having a weak memory model:</p>
<p><a href="http://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf" rel="nofollow">http://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf</a></p>
<p>And memory model researchers at the University of Oxford also regard x86 as having a weak memory model:</p>
<p><a href="http://www.cs.ox.ac.uk/people/jade.alglave/papers/aplas11.pdf" rel="nofollow">http://www.cs.ox.ac.uk/people/jade.alglave/papers/aplas11.pdf</a></p>
<p>The reason is that they regard a strong model as one where all memory operations are sequentially consistent. That is obviously not true of x86 because it reorders independent reads so x86 is a weak memory model by that definition.</p>
<p>I had never seen your definitions before but your previous statements make sense in their context. You were saying that only atomics will be sequentially consistent in future architectures.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Dave Abrahams				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5896</link>
		<dc:creator><![CDATA[Dave Abrahams]]></dc:creator>
		<pubDate>Fri, 03 Aug 2012 16:17:35 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-5896</guid>
					<description><![CDATA[I&#039;m still not pretending to be an expert in this area, but to the best of my understanding (and please correct me if I&#039;m wrong), 

• SC-DRF has been efficiently implemented on PowerPC for higher-level threading primitives like mutexes, locks, and condition variables.
• PowerPC&#039;s weaker atomics are also sometimes less expensive
• In some lock-free algorithms you don&#039;t need sequential consistency for every operation, and at those times, the PPC model can be more efficient
• It can be a lot harder to write some lock-free algorithms without SC-DRF atomics.
 
If that&#039;s the case, I don&#039;t understand the evolutionary pressure you imply exists toward SC-DRF atomics.  After all, lock-free programming is still (and probably always will be) considered an experts-only domain, and everybody else is supposed to use the higher-level primitives, which all have the SC-DRF property.]]></description>
		<content:encoded><![CDATA[<p>I&#8217;m still not pretending to be an expert in this area, but to the best of my understanding (and please correct me if I&#8217;m wrong), </p>
<p>• SC-DRF has been efficiently implemented on PowerPC for higher-level threading primitives like mutexes, locks, and condition variables.<br />
• PowerPC&#8217;s weaker atomics are also sometimes less expensive<br />
• In some lock-free algorithms you don&#8217;t need sequential consistency for every operation, and at those times, the PPC model can be more efficient<br />
• It can be a lot harder to write some lock-free algorithms without SC-DRF atomics.</p>
<p>If that&#8217;s the case, I don&#8217;t understand the evolutionary pressure you imply exists toward SC-DRF atomics.  After all, lock-free programming is still (and probably always will be) considered an experts-only domain, and everybody else is supposed to use the higher-level primitives, which all have the SC-DRF property.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Sumant Tambe				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5890</link>
		<dc:creator><![CDATA[Sumant Tambe]]></dc:creator>
		<pubDate>Fri, 03 Aug 2012 00:45:09 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-5890</guid>
					<description><![CDATA[I&#039;m happy to know that &quot;strong&quot; memory models are taking a stronghold! The definitions of &quot;weak&quot; and &quot;strong&quot; make sense to me for a single core but for many-core processors I think the memory models should be defined more broadly. For instance, Intel SCC (http://communities.intel.com/community/marc) has 48 Pentium P54C cores but it provides no mechanism for cache coherence between the cores (http://communities.intel.com/docs/DOC-5512). I believe the individial cores provide sequential consistency but I would not call the chip&#039;s overall memory model &quot;strong&quot; due to the lack of hardware supported cache coherence. Perhaps it is further evidence that &quot;weak&quot; and &quot;strong&quot; is not the right way of thinking about it. Is cache coherence between cores orthogonal to the &quot;weak&quot; and &quot;strong&quot; models you are talking about? More importatnly, do you think such cache incoherent architectures would be common in future?]]></description>
		<content:encoded><![CDATA[<p>I&#8217;m happy to know that &#8220;strong&#8221; memory models are taking a stronghold! The definitions of &#8220;weak&#8221; and &#8220;strong&#8221; make sense to me for a single core but for many-core processors I think the memory models should be defined more broadly. For instance, Intel SCC (<a href="http://communities.intel.com/community/marc" rel="nofollow">http://communities.intel.com/community/marc</a>) has 48 Pentium P54C cores but it provides no mechanism for cache coherence between the cores (<a href="http://communities.intel.com/docs/DOC-5512" rel="nofollow">http://communities.intel.com/docs/DOC-5512</a>). I believe the individial cores provide sequential consistency but I would not call the chip&#8217;s overall memory model &#8220;strong&#8221; due to the lack of hardware supported cache coherence. Perhaps it is further evidence that &#8220;weak&#8221; and &#8220;strong&#8221; is not the right way of thinking about it. Is cache coherence between cores orthogonal to the &#8220;weak&#8221; and &#8220;strong&#8221; models you are talking about? More importatnly, do you think such cache incoherent architectures would be common in future?</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Jeff Hammond				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5889</link>
		<dc:creator><![CDATA[Jeff Hammond]]></dc:creator>
		<pubDate>Thu, 02 Aug 2012 19:34:07 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-5889</guid>
					<description><![CDATA[Alex: No, I&#039;m not talking about lwarx+stwcx, which are not scalable, but certainly do not go on forever (assuming no user error).  There are special store instructions for BQC that do store-with-increment, etc. as a single instruction that is applied in the L2 itself. The documentation will be eventually at https://bgq.anl-external.org/wiki/index.php/Main_Page when we have time to upload it.]]></description>
		<content:encoded><![CDATA[<p>Alex: No, I&#8217;m not talking about lwarx+stwcx, which are not scalable, but certainly do not go on forever (assuming no user error).  There are special store instructions for BQC that do store-with-increment, etc. as a single instruction that is applied in the L2 itself. The documentation will be eventually at <a href="https://bgq.anl-external.org/wiki/index.php/Main_Page" rel="nofollow">https://bgq.anl-external.org/wiki/index.php/Main_Page</a> when we have time to upload it.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Alex Buynytskyy				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5888</link>
		<dc:creator><![CDATA[Alex Buynytskyy]]></dc:creator>
		<pubDate>Thu, 02 Aug 2012 19:14:43 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-5888</guid>
					<description><![CDATA[2Jeff Hammond:
Can you please clarify your point about hardware atomics on PowerPC?
From my knowledge to make an atomic operation you have to lock L2 cache line, then do, then check if it&#039;s OK. If it&#039;s not OK, you should do it again. So this kind of cycle can go on forever.
Potentially it&#039;s more powerful since you can do all operations you want and then try to &quot;commit&quot; all cache-line. But on practice it&#039;s very difficult to use.]]></description>
		<content:encoded><![CDATA[<p>2Jeff Hammond:<br />
Can you please clarify your point about hardware atomics on PowerPC?<br />
From my knowledge to make an atomic operation you have to lock L2 cache line, then do, then check if it&#8217;s OK. If it&#8217;s not OK, you should do it again. So this kind of cycle can go on forever.<br />
Potentially it&#8217;s more powerful since you can do all operations you want and then try to &#8220;commit&#8221; all cache-line. But on practice it&#8217;s very difficult to use.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: Jeff Hammond				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5886</link>
		<dc:creator><![CDATA[Jeff Hammond]]></dc:creator>
		<pubDate>Thu, 02 Aug 2012 18:29:05 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-5886</guid>
					<description><![CDATA[Your definition of strong and weak memory models is somewhat inconsistent with every other one I\’ve seen, which are talking about the ordering of conventional loads and stores, not presence or absence of single-instruction atomics.

The Blue Gene/Q compute chip (BQC), which PowerPC with extensions, is very much weak in the traditional sense of PowerPC, but also provides hardware atomics in the L2 cache that are probably superior to anything you can get from x86.

The BQC also has hardware transaction memory, which allows one to do far richer lock-free algorithms than x86.]]></description>
		<content:encoded><![CDATA[<p>Your definition of strong and weak memory models is somewhat inconsistent with every other one I\’ve seen, which are talking about the ordering of conventional loads and stores, not presence or absence of single-instruction atomics.</p>
<p>The Blue Gene/Q compute chip (BQC), which PowerPC with extensions, is very much weak in the traditional sense of PowerPC, but also provides hardware atomics in the L2 cache that are probably superior to anything you can get from x86.</p>
<p>The BQC also has hardware transaction memory, which allows one to do far richer lock-free algorithms than x86.</p>
]]></content:encoded>
					</item>
						<item>
				<title>
				By: mjklaim				</title>
				<link>https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5883</link>
		<dc:creator><![CDATA[mjklaim]]></dc:creator>
		<pubDate>Thu, 02 Aug 2012 16:12:03 +0000</pubDate>
		<guid isPermaLink="false">http://herbsutter.wordpress.com/?p=1590#comment-5883</guid>
					<description><![CDATA[Hi Herb, 

I didn&#039;t understand everything you explained even after having watched before the video that you mention here. However I think it&#039;s a great opportunity for me to learn about that, thanks.

By the way, here is a suggestions related to one of the GOTW (we can&#039;t comment the pages): In GOTW #100 and #101 you suggest using std::unique_ptr in the implementation of the class exposing the interface, while this pointer would hold the implementation. I think it might be very useful to add to the document the case where your class is the interface of a shared library that is supposed to be accessible by other compilers or versions of compilers or binaries with different compilation builds, because std::unique_ptr is a class template. Visual Studio compilers notify the programmer through a warning so it is obvious when you try, but it might be good to specify in such a great article that it is no use in this case. There seem to be a way to compile the specific instance of the template used, and then expose it in the interface of the shared library, but it is not very clear to me yet.]]></description>
		<content:encoded><![CDATA[<p>Hi Herb, </p>
<p>I didn&#8217;t understand everything you explained even after having watched before the video that you mention here. However I think it&#8217;s a great opportunity for me to learn about that, thanks.</p>
<p>By the way, here is a suggestions related to one of the GOTW (we can&#8217;t comment the pages): In GOTW #100 and #101 you suggest using std::unique_ptr in the implementation of the class exposing the interface, while this pointer would hold the implementation. I think it might be very useful to add to the document the case where your class is the interface of a shared library that is supposed to be accessible by other compilers or versions of compilers or binaries with different compilation builds, because std::unique_ptr is a class template. Visual Studio compilers notify the programmer through a warning so it is obvious when you try, but it might be good to specify in such a great article that it is no use in this case. There seem to be a way to compile the specific instance of the template used, and then expose it in the interface of the shared library, but it is not very clear to me yet.</p>
]]></content:encoded>
					</item>
			</channel>
</rss>
